{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3fb144-8e05-42c1-8c05-dbd6c38b9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick # https://matplotlib.org/stable/gallery/ticks_and_spines/tick-formatters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c64bc96-09dd-431f-aaad-84d9d69471a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set viewing options\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74017694-21cd-402c-a5a3-44cc47fe0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtrs = pd.read_csv('data/All_Quarter_Combos_Modeling_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33280921-d122-4655-b4b3-34991e02f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.843727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>12</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.770849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>13</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>14</td>\n",
       "      <td>BayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>11</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>12</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>13</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>14</td>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>3 Dense layers (80,60,60 nodes), 3 dropout lay...</td>\n",
       "      <td>0.406461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Clump                   Estimator                                             params  accuracy\n",
       "0             0      0           BaggingClassifier                                                NaN  0.650639\n",
       "1             1      1           BaggingClassifier                                                NaN  0.640872\n",
       "2             2      2           BaggingClassifier                                                NaN  0.619835\n",
       "3             3      3           BaggingClassifier                                                NaN  0.633358\n",
       "4             4      4           BaggingClassifier                                                NaN  0.703982\n",
       "5             5      5           BaggingClassifier                                                NaN  0.686702\n",
       "6             6      6           BaggingClassifier                                                NaN  0.709992\n",
       "7             7      7           BaggingClassifier                                                NaN  0.692712\n",
       "8             8      8           BaggingClassifier                                                NaN  0.699474\n",
       "9             9      9           BaggingClassifier                                                NaN  0.691210\n",
       "10           10     10           BaggingClassifier                                                NaN  0.756574\n",
       "11           11     11           BaggingClassifier                                                NaN  0.761082\n",
       "12           12     12           BaggingClassifier                                                NaN  0.764838\n",
       "13           13     13           BaggingClassifier                                                NaN  0.756574\n",
       "14           14     14           BaggingClassifier                                                NaN  0.843727\n",
       "15           15      0      RandomForestClassifier                                                NaN  0.650639\n",
       "16           16      1      RandomForestClassifier                                                NaN  0.640872\n",
       "17           17      2      RandomForestClassifier                                                NaN  0.619835\n",
       "18           18      3      RandomForestClassifier                                                NaN  0.633358\n",
       "19           19      4      RandomForestClassifier                                                NaN  0.704733\n",
       "20           20      5      RandomForestClassifier                                                NaN  0.685950\n",
       "21           21      6      RandomForestClassifier                                                NaN  0.709992\n",
       "22           22      7      RandomForestClassifier                                                NaN  0.694215\n",
       "23           23      8      RandomForestClassifier                                                NaN  0.697971\n",
       "24           24      9      RandomForestClassifier                                                NaN  0.691210\n",
       "25           25     10      RandomForestClassifier                                                NaN  0.742299\n",
       "26           26     11      RandomForestClassifier                                                NaN  0.764087\n",
       "27           27     12      RandomForestClassifier                                                NaN  0.763336\n",
       "28           28     13      RandomForestClassifier                                                NaN  0.754320\n",
       "29           29     14      RandomForestClassifier                                                NaN  0.851240\n",
       "30           30      0          LogisticRegression                                                NaN  0.650639\n",
       "31           31      1          LogisticRegression                                                NaN  0.640872\n",
       "32           32      2          LogisticRegression                                                NaN  0.619835\n",
       "33           33      3          LogisticRegression                                                NaN  0.633358\n",
       "34           34      4          LogisticRegression                                                NaN  0.704733\n",
       "35           35      5          LogisticRegression                                                NaN  0.686702\n",
       "36           36      6          LogisticRegression                                                NaN  0.709992\n",
       "37           37      7          LogisticRegression                                                NaN  0.703982\n",
       "38           38      8          LogisticRegression                                                NaN  0.697971\n",
       "39           39      9          LogisticRegression                                                NaN  0.691210\n",
       "40           40     10          LogisticRegression                                                NaN  0.760331\n",
       "41           41     11          LogisticRegression                                                NaN  0.776860\n",
       "42           42     12          LogisticRegression                                                NaN  0.776860\n",
       "43           43     13          LogisticRegression                                                NaN  0.767092\n",
       "44           44     14          LogisticRegression                                                NaN  0.864763\n",
       "45           45      0      DecisionTreeClassifier                                                NaN  0.650639\n",
       "46           46      1      DecisionTreeClassifier                                                NaN  0.640872\n",
       "47           47      2      DecisionTreeClassifier                                                NaN  0.619835\n",
       "48           48      3      DecisionTreeClassifier                                                NaN  0.633358\n",
       "49           49      4      DecisionTreeClassifier                                                NaN  0.704733\n",
       "50           50      5      DecisionTreeClassifier                                                NaN  0.685950\n",
       "51           51      6      DecisionTreeClassifier                                                NaN  0.709992\n",
       "52           52      7      DecisionTreeClassifier                                                NaN  0.694215\n",
       "53           53      8      DecisionTreeClassifier                                                NaN  0.694966\n",
       "54           54      9      DecisionTreeClassifier                                                NaN  0.691210\n",
       "55           55     10      DecisionTreeClassifier                                                NaN  0.744553\n",
       "56           56     11      DecisionTreeClassifier                                                NaN  0.764838\n",
       "57           57     12      DecisionTreeClassifier                                                NaN  0.767092\n",
       "58           58     13      DecisionTreeClassifier                                                NaN  0.755071\n",
       "59           59     14      DecisionTreeClassifier                                                NaN  0.852742\n",
       "60           60      0        ExtraTreesClassifier                                                NaN  0.650639\n",
       "61           61      1        ExtraTreesClassifier                                                NaN  0.640872\n",
       "62           62      2        ExtraTreesClassifier                                                NaN  0.619835\n",
       "63           63      3        ExtraTreesClassifier                                                NaN  0.633358\n",
       "64           64      4        ExtraTreesClassifier                                                NaN  0.704733\n",
       "65           65      5        ExtraTreesClassifier                                                NaN  0.685950\n",
       "66           66      6        ExtraTreesClassifier                                                NaN  0.709992\n",
       "67           67      7        ExtraTreesClassifier                                                NaN  0.694215\n",
       "68           68      8        ExtraTreesClassifier                                                NaN  0.694966\n",
       "69           69      9        ExtraTreesClassifier                                                NaN  0.691210\n",
       "70           70     10        ExtraTreesClassifier                                                NaN  0.744553\n",
       "71           71     11        ExtraTreesClassifier                                                NaN  0.766341\n",
       "72           72     12        ExtraTreesClassifier                                                NaN  0.764838\n",
       "73           73     13        ExtraTreesClassifier                                                NaN  0.755823\n",
       "74           74     14        ExtraTreesClassifier                                                NaN  0.855748\n",
       "75           75      0          AdaBoostClassifier                                                NaN  0.650639\n",
       "76           76      1          AdaBoostClassifier                                                NaN  0.640872\n",
       "77           77      2          AdaBoostClassifier                                                NaN  0.619835\n",
       "78           78      3          AdaBoostClassifier                                                NaN  0.633358\n",
       "79           79      4          AdaBoostClassifier                                                NaN  0.704733\n",
       "80           80      5          AdaBoostClassifier                                                NaN  0.686702\n",
       "81           81      6          AdaBoostClassifier                                                NaN  0.709992\n",
       "82           82      7          AdaBoostClassifier                                                NaN  0.703982\n",
       "83           83      8          AdaBoostClassifier                                                NaN  0.697971\n",
       "84           84      9          AdaBoostClassifier                                                NaN  0.691210\n",
       "85           85     10          AdaBoostClassifier                                                NaN  0.761082\n",
       "86           86     11          AdaBoostClassifier                                                NaN  0.777611\n",
       "87           87     12          AdaBoostClassifier                                                NaN  0.776860\n",
       "88           88     13          AdaBoostClassifier                                                NaN  0.766341\n",
       "89           89     14          AdaBoostClassifier                                                NaN  0.856499\n",
       "90           90      0             BayesClassifier                                                NaN  0.650639\n",
       "91           91      1             BayesClassifier                                                NaN  0.640872\n",
       "92           92      2             BayesClassifier                                                NaN  0.619835\n",
       "93           93      3             BayesClassifier                                                NaN  0.633358\n",
       "94           94      4             BayesClassifier                                                NaN  0.704733\n",
       "95           95      5             BayesClassifier                                                NaN  0.686702\n",
       "96           96      6             BayesClassifier                                                NaN  0.709992\n",
       "97           97      7             BayesClassifier                                                NaN  0.698723\n",
       "98           98      8             BayesClassifier                                                NaN  0.705485\n",
       "99           99      9             BayesClassifier                                                NaN  0.690458\n",
       "100         100     10             BayesClassifier                                                NaN  0.759579\n",
       "101         101     11             BayesClassifier                                                NaN  0.774606\n",
       "102         102     12             BayesClassifier                                                NaN  0.770849\n",
       "103         103     13             BayesClassifier                                                NaN  0.768595\n",
       "104         104     14             BayesClassifier                                                NaN  0.850488\n",
       "105         105      0  GradientBoostingClassifier                                                NaN  0.650639\n",
       "106         106      1  GradientBoostingClassifier                                                NaN  0.640872\n",
       "107         107      2  GradientBoostingClassifier                                                NaN  0.619835\n",
       "108         108      3  GradientBoostingClassifier                                                NaN  0.633358\n",
       "109         109      4  GradientBoostingClassifier                                                NaN  0.705485\n",
       "110         110      5  GradientBoostingClassifier                                                NaN  0.686702\n",
       "111         111      6  GradientBoostingClassifier                                                NaN  0.709992\n",
       "112         112      7  GradientBoostingClassifier                                                NaN  0.698723\n",
       "113         113      8  GradientBoostingClassifier                                                NaN  0.703231\n",
       "114         114      9  GradientBoostingClassifier                                                NaN  0.691210\n",
       "115         115     10  GradientBoostingClassifier                                                NaN  0.761833\n",
       "116         116     11  GradientBoostingClassifier                                                NaN  0.776108\n",
       "117         117     12  GradientBoostingClassifier                                                NaN  0.764838\n",
       "118         118     13  GradientBoostingClassifier                                                NaN  0.763336\n",
       "119         119     14  GradientBoostingClassifier                                                NaN  0.854245\n",
       "120         120      0               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "121         121      1               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "122         122      2               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "123         123      3               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "124         124      4               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "125         125      5               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "126         126      6               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "127         127      7               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "128         128      8               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "129         129      9               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "130         130     10               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "131         131     11               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "132         132     12               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "133         133     13               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "134         134     14               NeuralNetwork  3 Dense layers (80,60,60 nodes), 3 dropout lay...  0.406461\n",
       "135         135      0        KNeighborsClassifier                                                NaN  0.639369\n",
       "136         136      1        KNeighborsClassifier                                                NaN  0.591285\n",
       "137         137      2        KNeighborsClassifier                                                NaN  0.561232\n",
       "138         138      3        KNeighborsClassifier                                                NaN  0.539444\n",
       "139         139      4        KNeighborsClassifier                                                NaN  0.687453\n",
       "140         140      5        KNeighborsClassifier                                                NaN  0.674681\n",
       "141         141      6        KNeighborsClassifier                                                NaN  0.664914\n",
       "142         142      7        KNeighborsClassifier                                                NaN  0.649136\n",
       "143         143      8        KNeighborsClassifier                                                NaN  0.655898\n",
       "144         144      9        KNeighborsClassifier                                                NaN  0.631856\n",
       "145         145     10        KNeighborsClassifier                                                NaN  0.692712\n",
       "146         146     11        KNeighborsClassifier                                                NaN  0.752817\n",
       "147         147     12        KNeighborsClassifier                                                NaN  0.731029\n",
       "148         148     13        KNeighborsClassifier                                                NaN  0.725770\n",
       "149         149     14        KNeighborsClassifier                                                NaN  0.806161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed1cd86-6b33-4160-ab34-2912306a76b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ecfbda3760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scatter plot accuracy by clump\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.scatter(qtrs['Clump'], qtrs['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f0fc50-2f4e-4a7e-8783-62ae8344df73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-748608c89bb8>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  qtrs.groupby('Clump')['accuracy','Estimator'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.406461</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy           Estimator\n",
       "Clump                              \n",
       "0      0.406461  AdaBoostClassifier\n",
       "1      0.406461  AdaBoostClassifier\n",
       "2      0.406461  AdaBoostClassifier\n",
       "3      0.406461  AdaBoostClassifier\n",
       "4      0.406461  AdaBoostClassifier\n",
       "5      0.406461  AdaBoostClassifier\n",
       "6      0.406461  AdaBoostClassifier\n",
       "7      0.406461  AdaBoostClassifier\n",
       "8      0.406461  AdaBoostClassifier\n",
       "9      0.406461  AdaBoostClassifier\n",
       "10     0.406461  AdaBoostClassifier\n",
       "11     0.406461  AdaBoostClassifier\n",
       "12     0.406461  AdaBoostClassifier\n",
       "13     0.406461  AdaBoostClassifier\n",
       "14     0.406461  AdaBoostClassifier"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worst estimator - AdaBoost\n",
    "qtrs.groupby('Clump')['accuracy','Estimator'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2631569-0c18-483a-a36d-14f8e90b9a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-3df2951ebf4e>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  qtrs.groupby('Clump')['accuracy','Estimator'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650639</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640872</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.619835</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.633358</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705485</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.686702</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.709992</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.703982</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.705485</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.691210</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761833</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.777611</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.776860</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.768595</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.864763</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy               Estimator\n",
       "Clump                                  \n",
       "0      0.650639  RandomForestClassifier\n",
       "1      0.640872  RandomForestClassifier\n",
       "2      0.619835  RandomForestClassifier\n",
       "3      0.633358  RandomForestClassifier\n",
       "4      0.705485  RandomForestClassifier\n",
       "5      0.686702  RandomForestClassifier\n",
       "6      0.709992  RandomForestClassifier\n",
       "7      0.703982  RandomForestClassifier\n",
       "8      0.705485  RandomForestClassifier\n",
       "9      0.691210  RandomForestClassifier\n",
       "10     0.761833  RandomForestClassifier\n",
       "11     0.777611  RandomForestClassifier\n",
       "12     0.776860  RandomForestClassifier\n",
       "13     0.768595  RandomForestClassifier\n",
       "14     0.864763  RandomForestClassifier"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtrs.groupby('Clump')['accuracy','Estimator'].max()\n",
    "# best estimator - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5663f6b8-f474-460f-8a78-501b6fa624ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump\n",
       "0     0.625094\n",
       "1     0.612472\n",
       "2     0.592637\n",
       "3     0.601277\n",
       "4     0.673178\n",
       "5     0.657250\n",
       "6     0.675131\n",
       "7     0.663636\n",
       "8     0.665440\n",
       "9     0.656724\n",
       "10    0.712998\n",
       "11    0.732081\n",
       "12    0.728700\n",
       "13    0.721938\n",
       "14    0.804207\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy scores by clump\n",
    "qtrs.groupby('Clump')['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2e2a54-1c14-4c66-b910-83e398434f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ecfbe4d4c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(qtrs['Clump'].unique(), qtrs.groupby('Clump')['accuracy'].mean(), label = \"Average accuracy\",marker='o',\n",
    "        markersize=10)#Rforest\n",
    "plt.plot(qtrs['Clump'].unique(), qtrs.groupby('Clump')['accuracy'].max(), label = \"Maximum accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.xlabel(\"Quarter clump numbers\", fontsize=40)\n",
    "plt.ylabel(\"Accuracy in percentage\", fontsize=40)\n",
    "plt.grid()\n",
    "fig.patch.set_facecolor('aqua')\n",
    "ax.set_facecolor('palegreen')\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "        #https://www.pauldesalvo.com/convert-y-axis-labels-to-a-percentage-in-python-matplotlib/\n",
    "plt.legend(fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c241d1-1003-40fe-88ae-77355d1a02bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Week</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>156</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>212</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>214</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>230</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>233</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>252</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>275</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>279</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>283</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>312</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>313</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>352</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>353</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>354</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>355</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>363</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>370</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>372</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>374</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>403</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>417</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>425</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>427</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>428</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>429</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>434</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>436</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>439</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>440</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>443</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>444</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>445</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>446</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>447</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>457</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>461</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>468</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>469</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>476</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>514</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>515</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>516</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>517</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>519</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>520</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>521</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>522</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>523</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>526</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>527</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>528</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>537</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>538</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>539</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>541</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>542</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>543</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>544</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>545</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>547</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>548</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>549</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>550</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>551</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>552</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>558</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>559</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>560</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>561</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>562</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>563</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>574</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>575</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>576</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>577</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>580</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>581</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>582</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>587</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>588</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>590</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>593</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>594</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>601</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>611</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>612</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>614</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>616</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>617</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>618</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>619</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>620</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>621</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>622</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>623</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>624</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>626</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>627</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>629</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>632</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>633</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>640</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>642</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>648</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>649</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>650</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>651</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>652</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>654</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>658</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>659</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>663</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>664</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>666</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>668</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>669</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>671</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>672</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>673</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>680</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>681</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>683</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>690</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>692</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>693</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>694</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>695</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>696</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>697</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>698</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>699</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>701</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>703</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>704</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>706</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>707</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>710</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>711</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>712</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>717</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>720</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>721</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>722</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>723</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>724</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>726</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>727</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>728</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>729</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>730</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>731</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>732</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>733</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>734</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>735</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>736</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>738</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>744</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>745</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>746</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>747</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>748</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>751</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>752</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>753</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>754</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>755</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>756</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>759</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>760</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>761</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>762</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>763</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>764</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>765</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>767</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>769</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>770</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>776</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>777</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>779</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>780</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>781</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>782</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>783</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>784</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>785</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>786</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>787</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>788</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>789</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>790</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>791</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>792</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>793</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>794</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>801</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>802</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>803</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>804</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>805</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>806</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>807</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>809</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>814</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>815</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>816</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>817</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>818</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>819</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>820</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>822</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>823</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>824</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>825</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>826</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>827</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>830</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>831</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>832</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>834</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>838</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>839</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>843</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>844</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>845</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>846</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>847</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>848</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>849</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>850</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>851</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>854</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>856</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>857</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>858</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>859</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>861</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>862</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>863</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>864</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>865</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>866</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>867</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>868</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>872</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>874</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>875</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>876</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>877</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>878</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>879</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>880</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>881</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>882</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>883</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>884</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>891</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>892</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>893</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>894</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>895</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>896</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>897</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>899</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>901</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>902</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>903</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>904</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>906</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>907</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>908</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>909</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>910</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>911</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>919</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>922</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>937</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>943</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>947</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>948</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>949</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>950</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>951</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>954</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>956</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>957</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>958</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>959</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>961</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>962</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>963</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>964</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>965</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>966</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>967</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>968</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>969</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>983</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>984</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>985</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>986</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>987</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>988</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>989</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1008</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1009</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1010</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1011</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1012</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1013</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1015</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1016</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1017</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1023</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>1024</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1025</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1027</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1028</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1029</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1030</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>1031</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1032</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1033</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1034</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1036</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1037</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1039</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1041</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1042</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1043</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1044</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1051</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1052</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1053</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1054</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1055</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1056</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1057</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1058</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1059</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1060</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1061</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1062</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1063</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1064</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1067</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1071</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1072</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1073</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>1074</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1075</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>1076</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>1077</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1078</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>1079</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1080</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1081</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1082</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1084</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1085</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1086</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1087</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1088</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1089</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1096</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1097</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1098</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1099</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1100</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1101</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1102</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1103</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1104</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1105</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1106</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1108</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1114</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1115</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>1116</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1117</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1118</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1119</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1120</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1121</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1122</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1123</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1127</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1128</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1129</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1130</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>1131</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1132</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>1133</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1134</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1136</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1142</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>1143</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1144</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1145</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1146</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1147</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1148</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1149</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1150</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1151</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1152</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>1153</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>1154</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1156</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1157</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1158</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>1159</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1160</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1161</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1162</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1163</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1164</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1165</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1166</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1167</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1168</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>1169</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1170</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1171</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>1172</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>1173</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>1174</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1175</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1176</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1177</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1178</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1179</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1180</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1181</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1182</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>1183</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1184</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1185</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1186</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>1187</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>1188</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1189</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1190</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>1191</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1192</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>1193</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1194</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1195</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1196</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1197</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1198</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1199</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1201</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1202</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1203</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1204</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>1205</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1206</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1207</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1208</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1209</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1210</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1212</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1214</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1217</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1218</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>1219</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1220</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1227</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1228</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1229</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1232</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1234</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1235</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1236</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1237</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1238</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1239</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1240</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1241</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1242</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1243</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1244</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1250</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1252</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1255</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>1256</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1258</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1259</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1262</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1263</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1264</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1267</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1268</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1269</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1271</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1272</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1274</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1275</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1276</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>1278</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1279</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1280</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1281</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1282</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1283</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1284</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1285</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1287</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1288</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1289</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1297</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1299</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1301</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1302</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1303</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1307</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1308</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1309</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1310</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1311</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1312</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1313</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1314</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1315</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1316</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1317</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1319</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1320</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1321</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1322</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1323</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>1324</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>1325</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>1326</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1327</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1328</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1329</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1330</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1331</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1332</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>1333</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1334</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1335</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1336</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1337</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>1338</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1339</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1340</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1341</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>1342</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1343</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1344</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1345</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1346</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1347</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1348</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1350</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1351</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1352</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1353</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>1354</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1355</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1356</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>1357</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1358</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1359</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1360</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1361</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1362</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>1363</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1364</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1365</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>1366</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1367</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1368</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1369</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1370</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1371</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1372</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1373</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1374</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>1375</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>1376</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>1377</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>1379</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>1380</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1381</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>1382</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1383</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>1384</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1385</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1386</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1387</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1388</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>1389</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1391</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1392</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1393</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1394</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1396</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1397</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1398</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1399</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>1400</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>1401</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1402</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1403</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1404</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1405</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1411</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1412</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1413</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>1414</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>1415</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>1416</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>1417</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>1418</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1419</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1420</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1421</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>1422</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>1423</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>1424</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1425</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>1426</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>1427</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1428</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>1429</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>1430</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1431</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1432</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1433</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1434</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1435</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1436</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1437</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1438</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1439</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1441</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1442</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1443</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1444</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1445</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1446</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1447</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1448</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1449</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1450</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1451</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1452</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1453</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1454</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1455</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1456</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1457</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1458</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1459</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>1460</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1461</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1462</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>1463</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>1464</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1465</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1466</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1467</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1468</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1469</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1470</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1472</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1473</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>1474</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>1476</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1477</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1478</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1479</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1480</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1481</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1482</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1483</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1484</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1485</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1486</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1487</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1488</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1489</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1490</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1491</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1492</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>1493</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1494</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1495</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1496</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1497</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1498</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1499</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1501</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1502</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1503</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1504</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1505</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1506</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1507</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1508</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1509</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1510</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1511</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1512</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1513</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1514</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1515</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1516</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1517</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1518</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>1519</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1520</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1521</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1522</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1523</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1524</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1525</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1526</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1527</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1528</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1529</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1531</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1532</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1533</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>1534</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1535</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1536</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1537</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>1538</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1539</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1540</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1541</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1542</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1543</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1544</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1545</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1546</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>1547</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>1548</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1549</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1550</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>1551</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1552</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>1553</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>1554</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>1555</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1556</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>1557</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>1558</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1559</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1561</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>1562</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>1563</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1564</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>1565</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1566</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1567</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1568</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>1569</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>1570</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>1571</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1572</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>1573</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>1574</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1576</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1577</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1578</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1579</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1580</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1581</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1582</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1584</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1585</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1586</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1587</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1589</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1590</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1592</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1593</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1594</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1595</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1598</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1599</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1600</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1601</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1602</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1603</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1604</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1605</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1606</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1607</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1608</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1609</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1610</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1611</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1612</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1613</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1614</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1615</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1616</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1617</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1618</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1619</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1621</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1622</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1623</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>1624</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>1625</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1626</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1629</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1630</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1631</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1632</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1633</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1634</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1635</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1636</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1637</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1638</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>1640</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1641</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>1642</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>1643</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>1644</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1649</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1650</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>1651</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1652</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1653</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1654</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1655</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1656</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1659</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>1660</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1661</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>1662</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1663</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>1664</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1666</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1667</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>1668</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1669</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1670</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1671</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1672</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1673</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1674</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1675</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1676</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1677</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1678</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1679</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1681</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>1682</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1683</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1684</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1685</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1686</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1687</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1688</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>1689</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>1690</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>1691</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>1692</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>1693</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>1694</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1697</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1698</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>1700</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>1701</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>1702</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1703</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1704</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1705</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1706</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>1707</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>1708</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1709</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>1711</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1713</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1714</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1715</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1716</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>1717</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>1718</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>1719</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1720</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>1721</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>1722</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1723</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1724</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1725</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1726</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1727</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>1728</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>1729</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>1730</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>1731</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>1732</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>1733</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>1734</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>1735</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>1736</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1737</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1738</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1739</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1740</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1741</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1742</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1744</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1747</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>1748</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>1749</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>1750</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1751</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>1752</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>1753</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>1754</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1755</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>1756</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>1757</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>1758</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1759</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1760</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1761</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1762</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>1763</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>1764</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>1765</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1766</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1767</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1768</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>1769</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1770</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1771</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1772</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1773</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1774</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1775</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1776</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1777</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1778</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1779</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1780</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1781</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1782</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1783</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1784</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1785</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>1786</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1787</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1788</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1789</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1791</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>1792</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1793</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1794</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1795</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1796</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1797</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1798</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>1799</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1801</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>1802</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1803</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>1804</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>1805</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1806</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1807</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1808</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>1809</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>1810</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>1811</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1812</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>1813</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1814</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1815</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1816</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1817</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>1818</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>1819</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1820</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>1821</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>1822</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>1823</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>1824</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>1825</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>1826</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1827</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>1828</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>1829</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>1830</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>1831</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1832</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>1833</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1834</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>1835</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1836</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1837</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>1838</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>1839</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>1840</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1841</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>1842</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>1843</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>1844</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>1845</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>1846</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1847</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>1848</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1849</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1850</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1851</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>1852</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>1853</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>1854</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>1855</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>1856</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>1857</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>1858</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1860</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>1861</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1862</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1863</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1864</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1865</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1866</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1867</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1868</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1869</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1870</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1871</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1872</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1873</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1874</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1875</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1877</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>1878</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1879</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1880</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1881</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1882</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1883</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1884</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>1885</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1886</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>1887</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1888</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>1889</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>1892</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1894</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>1897</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>1898</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1899</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1903</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>1904</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1905</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1906</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>1907</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>1908</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>1909</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1910</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>1911</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>1912</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>1914</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>1915</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>1916</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1917</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>1918</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1919</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1920</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1921</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>1922</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>1923</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>1924</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>1925</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>1926</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>1927</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1929</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1930</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>1931</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>1932</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>1933</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1934</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1940</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>1941</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>1942</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1943</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1944</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>1945</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1946</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1947</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>1948</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1950</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1951</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>1952</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>1953</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>1954</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1955</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>1957</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1958</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>1959</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>1961</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>1962</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>1963</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>1964</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1965</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>1966</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1967</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>1968</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>1969</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>1970</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1971</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>1972</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1973</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>1975</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>1976</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1977</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1978</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1979</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1981</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1982</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1983</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1984</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1985</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1986</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1988</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1989</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1990</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1991</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1992</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1993</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1994</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2027</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>2028</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2029</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>2030</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2031</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2032</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2033</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2034</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2035</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2036</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2037</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2038</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2039</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2040</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2041</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>2042</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2043</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2044</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2045</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2046</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2047</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2048</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2049</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2050</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>2051</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>2052</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>2053</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>2054</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>2056</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>2057</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>2058</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2059</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2060</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2061</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>2062</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2063</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2064</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>2065</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2066</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2067</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2068</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>2069</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2070</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2071</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2072</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>2073</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2074</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2075</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2076</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>2077</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2078</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>2079</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>2080</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>2081</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>2082</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>2088</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>2089</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>2090</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>2091</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>2092</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>2093</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2094</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>2095</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2096</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2097</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>2098</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>2099</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2100</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>2101</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>2102</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>2103</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>2104</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2105</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2106</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2107</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2108</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>2109</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>2110</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>2111</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>2112</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>2113</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>2114</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2115</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>2116</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>2117</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>2118</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>2119</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>2120</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>2121</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2122</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>2123</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>2124</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2125</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2126</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2127</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2128</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2129</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2130</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>2131</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>2132</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>2133</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2134</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2135</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2136</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2137</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>2138</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2139</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2140</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>2141</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>2142</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>2143</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>2144</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2145</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2146</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>2147</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2148</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>2154</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>2162</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>2163</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2164</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>2165</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>2166</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>2167</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2168</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2169</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2170</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2171</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2172</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2173</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2174</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2175</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>2176</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>2177</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2178</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2179</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2180</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2181</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>2182</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>2183</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>2184</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>2185</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2186</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2187</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2188</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2189</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2191</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2192</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2193</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2194</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2195</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2196</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2197</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2198</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>2199</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2200</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2201</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2202</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2203</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2204</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>2207</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>2208</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>2209</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>2210</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>2211</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2212</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>2213</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>2214</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>2215</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>2216</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>2217</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>2218</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>2219</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2220</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2221</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>2222</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2223</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2224</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>2225</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>2226</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>2227</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2228</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>2229</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2230</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2231</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2232</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2233</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2234</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2236</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2237</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>2238</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>2239</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>2240</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>2241</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2242</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>2243</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>2244</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2245</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2246</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2247</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>2248</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>2249</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>2251</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>2252</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>2253</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>2254</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>2255</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>2256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2257</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2258</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2259</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>2260</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2261</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2262</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2263</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2264</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2265</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>2266</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>2267</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>2268</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2269</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2270</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2271</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2272</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2273</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2274</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2275</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2276</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2277</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>2278</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>2279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>2280</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>2281</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>2282</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>2283</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2284</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>2285</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>2286</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>2287</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>2288</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>2289</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2290</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2291</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>2292</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>2293</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>2294</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2295</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>2296</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>2297</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>2298</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>2299</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>2300</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>2301</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>2302</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>2303</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>2304</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2305</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>2306</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2307</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2308</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>2309</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>2310</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2311</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2312</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>2313</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>2314</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>2315</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>2316</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>2317</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>2318</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>2319</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>2320</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>2321</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>2322</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>2323</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>2324</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2325</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>2326</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>2327</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>2328</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>2329</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>2330</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>2331</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>2332</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>2333</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>2334</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>2335</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2336</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>2337</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>2338</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>2339</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2340</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>2341</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2342</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>2343</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>2344</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>2345</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>2346</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2347</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>2348</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>2349</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>2350</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>2352</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>2353</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>2354</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>2355</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>2356</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>2357</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>2358</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>2359</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>2360</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>2361</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>2363</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2364</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2365</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>2366</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>2367</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>2368</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>2369</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>2370</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>2371</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>2372</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>2373</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2374</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>2375</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>2376</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>2377</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2378</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>2379</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2380</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2381</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2382</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2383</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>2384</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2385</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2386</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2387</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2388</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>2389</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>2390</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>2391</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>2392</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>2393</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2395</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2396</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2397</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2402</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>2404</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>2405</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>2407</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>2408</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2409</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>2410</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>2411</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2412</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>2413</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>2414</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2415</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>2416</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>2417</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>2418</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2419</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>2420</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>2421</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>2422</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>2423</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>2424</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>2425</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>2426</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>2427</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2428</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>2429</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2430</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2431</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>2432</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>2433</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>2434</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>2435</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>2436</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>2437</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>2438</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>2439</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>2440</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>2441</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>2442</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>2443</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>2444</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>2445</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2446</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2447</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2448</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2449</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2450</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2451</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>2452</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2453</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>2454</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2455</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>2456</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>2457</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>2458</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>2459</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>2460</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>2461</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>2462</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>2463</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>2464</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>2465</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2466</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2467</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>2468</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>2469</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2470</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2471</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2472</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2473</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2474</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2475</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2476</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2477</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2478</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2479</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2480</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2481</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2482</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2483</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2484</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>2485</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2486</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>2487</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>2488</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>2489</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2490</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2491</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>2492</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>2493</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2494</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>2501</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>2502</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>2503</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>2504</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>2505</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>2506</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>2507</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>2508</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>2509</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>2510</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2511</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2512</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2513</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2514</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>2515</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>2516</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>2517</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>2518</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2519</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>2521</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>2523</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>2524</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2525</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>2526</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>2527</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>2528</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>2529</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>2530</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2531</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2533</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2534</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2535</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2536</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2537</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2538</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>2539</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>2540</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>2541</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2543</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>2544</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>2545</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2546</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>2547</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>2548</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>2549</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2551</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>2552</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>2553</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2554</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2555</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2556</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2557</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2558</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2559</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2560</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>2561</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>2562</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2563</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>2564</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>2565</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>2567</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>2568</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>2569</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>2570</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>2571</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>2572</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>2573</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>2574</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2575</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>2576</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2577</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>2578</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2579</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>2581</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2582</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>2583</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>2584</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>2585</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>2586</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>2587</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2588</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2589</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>2590</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2591</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2592</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>2593</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2594</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2595</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2596</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2597</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2598</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>2599</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2600</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>2601</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>2602</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2603</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>2604</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>2605</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>2606</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>2607</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>2608</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>2609</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2610</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2611</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2612</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>2613</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>2614</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>2615</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>2616</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>2617</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>2618</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>2619</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>2620</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>2621</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>2622</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>2624</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>2627</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>2628</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>2629</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>2630</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>2631</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>2632</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2633</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>2634</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>2635</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2636</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2637</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>2638</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>2639</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2640</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>2641</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>2642</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>2643</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>2644</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>2645</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>2646</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2647</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2648</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2649</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2650</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2651</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2652</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2653</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>2654</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2655</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2656</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2657</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2658</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2659</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>2660</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>2661</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>2662</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2663</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2664</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2665</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>2666</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>2667</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>2668</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>2669</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2670</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>2671</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>2672</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>2673</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>2674</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>2675</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>2676</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2677</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>2678</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>2679</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2680</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>2681</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>2682</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>2683</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>2684</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>2685</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>2686</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>2687</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>2688</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>2689</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2690</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2691</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2692</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2693</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2694</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>2695</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>2696</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>2697</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2698</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2699</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2700</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2701</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>2702</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2703</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>2704</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2705</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>2706</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>2707</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>2708</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>2709</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>2710</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>2711</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>2712</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>2713</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>2714</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>2715</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>2716</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>2717</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>2718</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>2719</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>2720</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>2721</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>2722</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>2723</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>2724</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>2725</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>2726</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>2727</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>2728</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>2729</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>2730</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>2731</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2732</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>2733</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>2734</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>2735</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>2736</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>2737</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>2738</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>2739</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>2740</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2741</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2742</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>2743</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>2744</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>2745</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>2746</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>2747</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>2748</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>2749</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>2750</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>2751</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2752</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2753</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2754</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2755</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2756</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>2757</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>2758</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>2759</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>2760</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>2761</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>2762</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>2763</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>2764</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>2765</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>2766</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>2767</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>2768</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>2769</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>2770</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>2771</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>2772</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>2773</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>2774</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2775</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2776</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2777</td>\n",
       "      <td>WC</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>2778</td>\n",
       "      <td>WC</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>2779</td>\n",
       "      <td>WC</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>2780</td>\n",
       "      <td>WC</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>2781</td>\n",
       "      <td>WC</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2782</td>\n",
       "      <td>WC</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>2783</td>\n",
       "      <td>WC</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>2784</td>\n",
       "      <td>WC</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>2785</td>\n",
       "      <td>WC</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>2786</td>\n",
       "      <td>WC</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2787</td>\n",
       "      <td>WC</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>2788</td>\n",
       "      <td>WC</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>2789</td>\n",
       "      <td>WC</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>2790</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>2791</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>2792</td>\n",
       "      <td>DV</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>DV</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>DV</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>DV</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>DV</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2797</td>\n",
       "      <td>DV</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>2798</td>\n",
       "      <td>DV</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>2799</td>\n",
       "      <td>DV</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2800</td>\n",
       "      <td>DV</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2801</td>\n",
       "      <td>DV</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2802</td>\n",
       "      <td>DV</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2803</td>\n",
       "      <td>DV</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>DV</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2805</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2806</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2807</td>\n",
       "      <td>CC</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2808</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>2809</td>\n",
       "      <td>CC</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>2810</td>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>2811</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>2812</td>\n",
       "      <td>CC</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>2813</td>\n",
       "      <td>CC</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>2814</td>\n",
       "      <td>CC</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2815</td>\n",
       "      <td>CC</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>2816</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>2817</td>\n",
       "      <td>CC</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>2818</td>\n",
       "      <td>CC</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>2819</td>\n",
       "      <td>CC</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>2820</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>2821</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>2822</td>\n",
       "      <td>SB</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>2823</td>\n",
       "      <td>SB</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>2824</td>\n",
       "      <td>SB</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>2825</td>\n",
       "      <td>SB</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2826</td>\n",
       "      <td>SB</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>2827</td>\n",
       "      <td>SB</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>2828</td>\n",
       "      <td>SB</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2829</td>\n",
       "      <td>SB</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2830</td>\n",
       "      <td>SB</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>2831</td>\n",
       "      <td>SB</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>2832</td>\n",
       "      <td>SB</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>2833</td>\n",
       "      <td>SB</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>2834</td>\n",
       "      <td>SB</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Week  Clump                   Estimator  params  accuracy\n",
       "0              0    1      0          LogisticRegression     NaN  0.612500\n",
       "1              1    1      1          LogisticRegression     NaN  0.675000\n",
       "2              2    1      2          LogisticRegression     NaN  0.762500\n",
       "3              3    1      3          LogisticRegression     NaN  0.637500\n",
       "4              4    1      4          LogisticRegression     NaN  0.687500\n",
       "5              5    1      5          LogisticRegression     NaN  0.775000\n",
       "6              6    1      6          LogisticRegression     NaN  0.762500\n",
       "7              7    1      7          LogisticRegression     NaN  0.775000\n",
       "8              8    1      8          LogisticRegression     NaN  0.662500\n",
       "9              9    1      9          LogisticRegression     NaN  0.725000\n",
       "10            10    1     10          LogisticRegression     NaN  0.787500\n",
       "11            11    1     11          LogisticRegression     NaN  0.737500\n",
       "12            12    1     12          LogisticRegression     NaN  0.737500\n",
       "13            13    1     13          LogisticRegression     NaN  0.837500\n",
       "14            14    1     14          LogisticRegression     NaN  0.875000\n",
       "15            15    2      0          LogisticRegression     NaN  0.645570\n",
       "16            16    2      1          LogisticRegression     NaN  0.569620\n",
       "17            17    2      2          LogisticRegression     NaN  0.670886\n",
       "18            18    2      3          LogisticRegression     NaN  0.620253\n",
       "19            19    2      4          LogisticRegression     NaN  0.658228\n",
       "20            20    2      5          LogisticRegression     NaN  0.696203\n",
       "21            21    2      6          LogisticRegression     NaN  0.670886\n",
       "22            22    2      7          LogisticRegression     NaN  0.632911\n",
       "23            23    2      8          LogisticRegression     NaN  0.683544\n",
       "24            24    2      9          LogisticRegression     NaN  0.670886\n",
       "25            25    2     10          LogisticRegression     NaN  0.721519\n",
       "26            26    2     11          LogisticRegression     NaN  0.810127\n",
       "27            27    2     12          LogisticRegression     NaN  0.721519\n",
       "28            28    2     13          LogisticRegression     NaN  0.772152\n",
       "29            29    2     14          LogisticRegression     NaN  0.810127\n",
       "30            30    3      0          LogisticRegression     NaN  0.571429\n",
       "31            31    3      1          LogisticRegression     NaN  0.636364\n",
       "32            32    3      2          LogisticRegression     NaN  0.623377\n",
       "33            33    3      3          LogisticRegression     NaN  0.610390\n",
       "34            34    3      4          LogisticRegression     NaN  0.714286\n",
       "35            35    3      5          LogisticRegression     NaN  0.688312\n",
       "36            36    3      6          LogisticRegression     NaN  0.766234\n",
       "37            37    3      7          LogisticRegression     NaN  0.714286\n",
       "38            38    3      8          LogisticRegression     NaN  0.727273\n",
       "39            39    3      9          LogisticRegression     NaN  0.662338\n",
       "40            40    3     10          LogisticRegression     NaN  0.766234\n",
       "41            41    3     11          LogisticRegression     NaN  0.714286\n",
       "42            42    3     12          LogisticRegression     NaN  0.779221\n",
       "43            43    3     13          LogisticRegression     NaN  0.740260\n",
       "44            44    3     14          LogisticRegression     NaN  0.805195\n",
       "45            45    4      0          LogisticRegression     NaN  0.657534\n",
       "46            46    4      1          LogisticRegression     NaN  0.671233\n",
       "47            47    4      2          LogisticRegression     NaN  0.616438\n",
       "48            48    4      3          LogisticRegression     NaN  0.452055\n",
       "49            49    4      4          LogisticRegression     NaN  0.739726\n",
       "50            50    4      5          LogisticRegression     NaN  0.684932\n",
       "51            51    4      6          LogisticRegression     NaN  0.657534\n",
       "52            52    4      7          LogisticRegression     NaN  0.698630\n",
       "53            53    4      8          LogisticRegression     NaN  0.657534\n",
       "54            54    4      9          LogisticRegression     NaN  0.698630\n",
       "55            55    4     10          LogisticRegression     NaN  0.739726\n",
       "56            56    4     11          LogisticRegression     NaN  0.739726\n",
       "57            57    4     12          LogisticRegression     NaN  0.780822\n",
       "58            58    4     13          LogisticRegression     NaN  0.739726\n",
       "59            59    4     14          LogisticRegression     NaN  0.863014\n",
       "60            60    5      0          LogisticRegression     NaN  0.563380\n",
       "61            61    5      1          LogisticRegression     NaN  0.704225\n",
       "62            62    5      2          LogisticRegression     NaN  0.718310\n",
       "63            63    5      3          LogisticRegression     NaN  0.605634\n",
       "64            64    5      4          LogisticRegression     NaN  0.647887\n",
       "65            65    5      5          LogisticRegression     NaN  0.746479\n",
       "66            66    5      6          LogisticRegression     NaN  0.732394\n",
       "67            67    5      7          LogisticRegression     NaN  0.633803\n",
       "68            68    5      8          LogisticRegression     NaN  0.690141\n",
       "69            69    5      9          LogisticRegression     NaN  0.690141\n",
       "70            70    5     10          LogisticRegression     NaN  0.760563\n",
       "71            71    5     11          LogisticRegression     NaN  0.732394\n",
       "72            72    5     12          LogisticRegression     NaN  0.732394\n",
       "73            73    5     13          LogisticRegression     NaN  0.788732\n",
       "74            74    5     14          LogisticRegression     NaN  0.887324\n",
       "75            75    6      0          LogisticRegression     NaN  0.471429\n",
       "76            76    6      1          LogisticRegression     NaN  0.614286\n",
       "77            77    6      2          LogisticRegression     NaN  0.542857\n",
       "78            78    6      3          LogisticRegression     NaN  0.571429\n",
       "79            79    6      4          LogisticRegression     NaN  0.671429\n",
       "80            80    6      5          LogisticRegression     NaN  0.657143\n",
       "81            81    6      6          LogisticRegression     NaN  0.642857\n",
       "82            82    6      7          LogisticRegression     NaN  0.671429\n",
       "83            83    6      8          LogisticRegression     NaN  0.600000\n",
       "84            84    6      9          LogisticRegression     NaN  0.585714\n",
       "85            85    6     10          LogisticRegression     NaN  0.700000\n",
       "86            86    6     11          LogisticRegression     NaN  0.657143\n",
       "87            87    6     12          LogisticRegression     NaN  0.657143\n",
       "88            88    6     13          LogisticRegression     NaN  0.714286\n",
       "89            89    6     14          LogisticRegression     NaN  0.785714\n",
       "90            90    7      0          LogisticRegression     NaN  0.785714\n",
       "91            91    7      1          LogisticRegression     NaN  0.671429\n",
       "92            92    7      2          LogisticRegression     NaN  0.757143\n",
       "93            93    7      3          LogisticRegression     NaN  0.585714\n",
       "94            94    7      4          LogisticRegression     NaN  0.700000\n",
       "95            95    7      5          LogisticRegression     NaN  0.757143\n",
       "96            96    7      6          LogisticRegression     NaN  0.742857\n",
       "97            97    7      7          LogisticRegression     NaN  0.842857\n",
       "98            98    7      8          LogisticRegression     NaN  0.728571\n",
       "99            99    7      9          LogisticRegression     NaN  0.671429\n",
       "100          100    7     10          LogisticRegression     NaN  0.857143\n",
       "101          101    7     11          LogisticRegression     NaN  0.857143\n",
       "102          102    7     12          LogisticRegression     NaN  0.785714\n",
       "103          103    7     13          LogisticRegression     NaN  0.814286\n",
       "104          104    7     14          LogisticRegression     NaN  0.871429\n",
       "105          105    8      0          LogisticRegression     NaN  0.724638\n",
       "106          106    8      1          LogisticRegression     NaN  0.623188\n",
       "107          107    8      2          LogisticRegression     NaN  0.695652\n",
       "108          108    8      3          LogisticRegression     NaN  0.623188\n",
       "109          109    8      4          LogisticRegression     NaN  0.739130\n",
       "110          110    8      5          LogisticRegression     NaN  0.739130\n",
       "111          111    8      6          LogisticRegression     NaN  0.782609\n",
       "112          112    8      7          LogisticRegression     NaN  0.739130\n",
       "113          113    8      8          LogisticRegression     NaN  0.782609\n",
       "114          114    8      9          LogisticRegression     NaN  0.753623\n",
       "115          115    8     10          LogisticRegression     NaN  0.753623\n",
       "116          116    8     11          LogisticRegression     NaN  0.826087\n",
       "117          117    8     12          LogisticRegression     NaN  0.797101\n",
       "118          118    8     13          LogisticRegression     NaN  0.768116\n",
       "119          119    8     14          LogisticRegression     NaN  0.855072\n",
       "120          120    9      0          LogisticRegression     NaN  0.608696\n",
       "121          121    9      1          LogisticRegression     NaN  0.550725\n",
       "122          122    9      2          LogisticRegression     NaN  0.652174\n",
       "123          123    9      3          LogisticRegression     NaN  0.666667\n",
       "124          124    9      4          LogisticRegression     NaN  0.666667\n",
       "125          125    9      5          LogisticRegression     NaN  0.666667\n",
       "126          126    9      6          LogisticRegression     NaN  0.695652\n",
       "127          127    9      7          LogisticRegression     NaN  0.637681\n",
       "128          128    9      8          LogisticRegression     NaN  0.652174\n",
       "129          129    9      9          LogisticRegression     NaN  0.681159\n",
       "130          130    9     10          LogisticRegression     NaN  0.695652\n",
       "131          131    9     11          LogisticRegression     NaN  0.695652\n",
       "132          132    9     12          LogisticRegression     NaN  0.710145\n",
       "133          133    9     13          LogisticRegression     NaN  0.753623\n",
       "134          134    9     14          LogisticRegression     NaN  0.840580\n",
       "135          135   10      0          LogisticRegression     NaN  0.625000\n",
       "136          136   10      1          LogisticRegression     NaN  0.638889\n",
       "137          137   10      2          LogisticRegression     NaN  0.583333\n",
       "138          138   10      3          LogisticRegression     NaN  0.625000\n",
       "139          139   10      4          LogisticRegression     NaN  0.708333\n",
       "140          140   10      5          LogisticRegression     NaN  0.680556\n",
       "141          141   10      6          LogisticRegression     NaN  0.652778\n",
       "142          142   10      7          LogisticRegression     NaN  0.722222\n",
       "143          143   10      8          LogisticRegression     NaN  0.722222\n",
       "144          144   10      9          LogisticRegression     NaN  0.722222\n",
       "145          145   10     10          LogisticRegression     NaN  0.777778\n",
       "146          146   10     11          LogisticRegression     NaN  0.777778\n",
       "147          147   10     12          LogisticRegression     NaN  0.791667\n",
       "148          148   10     13          LogisticRegression     NaN  0.763889\n",
       "149          149   10     14          LogisticRegression     NaN  0.916667\n",
       "150          150   11      0          LogisticRegression     NaN  0.693333\n",
       "151          151   11      1          LogisticRegression     NaN  0.706667\n",
       "152          152   11      2          LogisticRegression     NaN  0.693333\n",
       "153          153   11      3          LogisticRegression     NaN  0.586667\n",
       "154          154   11      4          LogisticRegression     NaN  0.800000\n",
       "155          155   11      5          LogisticRegression     NaN  0.800000\n",
       "156          156   11      6          LogisticRegression     NaN  0.733333\n",
       "157          157   11      7          LogisticRegression     NaN  0.773333\n",
       "158          158   11      8          LogisticRegression     NaN  0.773333\n",
       "159          159   11      9          LogisticRegression     NaN  0.746667\n",
       "160          160   11     10          LogisticRegression     NaN  0.826667\n",
       "161          161   11     11          LogisticRegression     NaN  0.813333\n",
       "162          162   11     12          LogisticRegression     NaN  0.853333\n",
       "163          163   11     13          LogisticRegression     NaN  0.786667\n",
       "164          164   11     14          LogisticRegression     NaN  0.906667\n",
       "165          165   12      0          LogisticRegression     NaN  0.602564\n",
       "166          166   12      1          LogisticRegression     NaN  0.551282\n",
       "167          167   12      2          LogisticRegression     NaN  0.628205\n",
       "168          168   12      3          LogisticRegression     NaN  0.589744\n",
       "169          169   12      4          LogisticRegression     NaN  0.705128\n",
       "170          170   12      5          LogisticRegression     NaN  0.756410\n",
       "171          171   12      6          LogisticRegression     NaN  0.717949\n",
       "172          172   12      7          LogisticRegression     NaN  0.653846\n",
       "173          173   12      8          LogisticRegression     NaN  0.628205\n",
       "174          174   12      9          LogisticRegression     NaN  0.679487\n",
       "175          175   12     10          LogisticRegression     NaN  0.730769\n",
       "176          176   12     11          LogisticRegression     NaN  0.730769\n",
       "177          177   12     12          LogisticRegression     NaN  0.705128\n",
       "178          178   12     13          LogisticRegression     NaN  0.807692\n",
       "179          179   12     14          LogisticRegression     NaN  0.820513\n",
       "180          180   13      0          LogisticRegression     NaN  0.575000\n",
       "181          181   13      1          LogisticRegression     NaN  0.762500\n",
       "182          182   13      2          LogisticRegression     NaN  0.612500\n",
       "183          183   13      3          LogisticRegression     NaN  0.675000\n",
       "184          184   13      4          LogisticRegression     NaN  0.750000\n",
       "185          185   13      5          LogisticRegression     NaN  0.787500\n",
       "186          186   13      6          LogisticRegression     NaN  0.700000\n",
       "187          187   13      7          LogisticRegression     NaN  0.662500\n",
       "188          188   13      8          LogisticRegression     NaN  0.687500\n",
       "189          189   13      9          LogisticRegression     NaN  0.812500\n",
       "190          190   13     10          LogisticRegression     NaN  0.775000\n",
       "191          191   13     11          LogisticRegression     NaN  0.700000\n",
       "192          192   13     12          LogisticRegression     NaN  0.825000\n",
       "193          193   13     13          LogisticRegression     NaN  0.837500\n",
       "194          194   13     14          LogisticRegression     NaN  0.812500\n",
       "195          195   14      0          LogisticRegression     NaN  0.612500\n",
       "196          196   14      1          LogisticRegression     NaN  0.762500\n",
       "197          197   14      2          LogisticRegression     NaN  0.600000\n",
       "198          198   14      3          LogisticRegression     NaN  0.637500\n",
       "199          199   14      4          LogisticRegression     NaN  0.775000\n",
       "200          200   14      5          LogisticRegression     NaN  0.837500\n",
       "201          201   14      6          LogisticRegression     NaN  0.625000\n",
       "202          202   14      7          LogisticRegression     NaN  0.762500\n",
       "203          203   14      8          LogisticRegression     NaN  0.737500\n",
       "204          204   14      9          LogisticRegression     NaN  0.775000\n",
       "205          205   14     10          LogisticRegression     NaN  0.825000\n",
       "206          206   14     11          LogisticRegression     NaN  0.725000\n",
       "207          207   14     12          LogisticRegression     NaN  0.812500\n",
       "208          208   14     13          LogisticRegression     NaN  0.850000\n",
       "209          209   14     14          LogisticRegression     NaN  0.912500\n",
       "210          210   15      0          LogisticRegression     NaN  0.662500\n",
       "211          211   15      1          LogisticRegression     NaN  0.662500\n",
       "212          212   15      2          LogisticRegression     NaN  0.625000\n",
       "213          213   15      3          LogisticRegression     NaN  0.687500\n",
       "214          214   15      4          LogisticRegression     NaN  0.837500\n",
       "215          215   15      5          LogisticRegression     NaN  0.675000\n",
       "216          216   15      6          LogisticRegression     NaN  0.637500\n",
       "217          217   15      7          LogisticRegression     NaN  0.712500\n",
       "218          218   15      8          LogisticRegression     NaN  0.762500\n",
       "219          219   15      9          LogisticRegression     NaN  0.775000\n",
       "220          220   15     10          LogisticRegression     NaN  0.775000\n",
       "221          221   15     11          LogisticRegression     NaN  0.750000\n",
       "222          222   15     12          LogisticRegression     NaN  0.862500\n",
       "223          223   15     13          LogisticRegression     NaN  0.875000\n",
       "224          224   15     14          LogisticRegression     NaN  0.875000\n",
       "225          225   16      0          LogisticRegression     NaN  0.537500\n",
       "226          226   16      1          LogisticRegression     NaN  0.612500\n",
       "227          227   16      2          LogisticRegression     NaN  0.612500\n",
       "228          228   16      3          LogisticRegression     NaN  0.612500\n",
       "229          229   16      4          LogisticRegression     NaN  0.662500\n",
       "230          230   16      5          LogisticRegression     NaN  0.650000\n",
       "231          231   16      6          LogisticRegression     NaN  0.700000\n",
       "232          232   16      7          LogisticRegression     NaN  0.550000\n",
       "233          233   16      8          LogisticRegression     NaN  0.550000\n",
       "234          234   16      9          LogisticRegression     NaN  0.725000\n",
       "235          235   16     10          LogisticRegression     NaN  0.675000\n",
       "236          236   16     11          LogisticRegression     NaN  0.687500\n",
       "237          237   16     12          LogisticRegression     NaN  0.750000\n",
       "238          238   16     13          LogisticRegression     NaN  0.750000\n",
       "239          239   16     14          LogisticRegression     NaN  0.775000\n",
       "240          240   17      0          LogisticRegression     NaN  0.675000\n",
       "241          241   17      1          LogisticRegression     NaN  0.675000\n",
       "242          242   17      2          LogisticRegression     NaN  0.687500\n",
       "243          243   17      3          LogisticRegression     NaN  0.625000\n",
       "244          244   17      4          LogisticRegression     NaN  0.662500\n",
       "245          245   17      5          LogisticRegression     NaN  0.712500\n",
       "246          246   17      6          LogisticRegression     NaN  0.737500\n",
       "247          247   17      7          LogisticRegression     NaN  0.750000\n",
       "248          248   17      8          LogisticRegression     NaN  0.725000\n",
       "249          249   17      9          LogisticRegression     NaN  0.662500\n",
       "250          250   17     10          LogisticRegression     NaN  0.787500\n",
       "251          251   17     11          LogisticRegression     NaN  0.825000\n",
       "252          252   17     12          LogisticRegression     NaN  0.750000\n",
       "253          253   17     13          LogisticRegression     NaN  0.825000\n",
       "254          254   17     14          LogisticRegression     NaN  0.837500\n",
       "255          255   WC      0          LogisticRegression     NaN  0.550000\n",
       "256          256   WC      1          LogisticRegression     NaN  0.600000\n",
       "257          257   WC      2          LogisticRegression     NaN  0.650000\n",
       "258          258   WC      3          LogisticRegression     NaN  0.500000\n",
       "259          259   WC      4          LogisticRegression     NaN  0.650000\n",
       "260          260   WC      5          LogisticRegression     NaN  0.650000\n",
       "261          261   WC      6          LogisticRegression     NaN  0.700000\n",
       "262          262   WC      7          LogisticRegression     NaN  0.800000\n",
       "263          263   WC      8          LogisticRegression     NaN  0.450000\n",
       "264          264   WC      9          LogisticRegression     NaN  0.600000\n",
       "265          265   WC     10          LogisticRegression     NaN  0.750000\n",
       "266          266   WC     11          LogisticRegression     NaN  0.800000\n",
       "267          267   WC     12          LogisticRegression     NaN  0.600000\n",
       "268          268   WC     13          LogisticRegression     NaN  0.700000\n",
       "269          269   WC     14          LogisticRegression     NaN  0.800000\n",
       "270          270   DV      0          LogisticRegression     NaN  0.700000\n",
       "271          271   DV      1          LogisticRegression     NaN  0.500000\n",
       "272          272   DV      2          LogisticRegression     NaN  0.450000\n",
       "273          273   DV      3          LogisticRegression     NaN  0.550000\n",
       "274          274   DV      4          LogisticRegression     NaN  0.650000\n",
       "275          275   DV      5          LogisticRegression     NaN  0.500000\n",
       "276          276   DV      6          LogisticRegression     NaN  0.450000\n",
       "277          277   DV      7          LogisticRegression     NaN  0.600000\n",
       "278          278   DV      8          LogisticRegression     NaN  0.650000\n",
       "279          279   DV      9          LogisticRegression     NaN  0.600000\n",
       "280          280   DV     10          LogisticRegression     NaN  0.650000\n",
       "281          281   DV     11          LogisticRegression     NaN  0.650000\n",
       "282          282   DV     12          LogisticRegression     NaN  0.650000\n",
       "283          283   DV     13          LogisticRegression     NaN  0.550000\n",
       "284          284   DV     14          LogisticRegression     NaN  0.750000\n",
       "285          285   CC      0          LogisticRegression     NaN  0.500000\n",
       "286          286   CC      1          LogisticRegression     NaN  0.500000\n",
       "287          287   CC      2          LogisticRegression     NaN  0.500000\n",
       "288          288   CC      3          LogisticRegression     NaN  0.500000\n",
       "289          289   CC      4          LogisticRegression     NaN  0.500000\n",
       "290          290   CC      5          LogisticRegression     NaN  0.600000\n",
       "291          291   CC      6          LogisticRegression     NaN  0.500000\n",
       "292          292   CC      7          LogisticRegression     NaN  0.500000\n",
       "293          293   CC      8          LogisticRegression     NaN  0.400000\n",
       "294          294   CC      9          LogisticRegression     NaN  0.600000\n",
       "295          295   CC     10          LogisticRegression     NaN  0.500000\n",
       "296          296   CC     11          LogisticRegression     NaN  0.500000\n",
       "297          297   CC     12          LogisticRegression     NaN  0.500000\n",
       "298          298   CC     13          LogisticRegression     NaN  0.500000\n",
       "299          299   CC     14          LogisticRegression     NaN  0.600000\n",
       "300          300   SB      0          LogisticRegression     NaN  0.400000\n",
       "301          301   SB      1          LogisticRegression     NaN  0.400000\n",
       "302          302   SB      2          LogisticRegression     NaN  0.400000\n",
       "303          303   SB      3          LogisticRegression     NaN  0.400000\n",
       "304          304   SB      4          LogisticRegression     NaN  0.400000\n",
       "305          305   SB      5          LogisticRegression     NaN  0.400000\n",
       "306          306   SB      6          LogisticRegression     NaN  0.400000\n",
       "307          307   SB      7          LogisticRegression     NaN  0.600000\n",
       "308          308   SB      8          LogisticRegression     NaN  0.400000\n",
       "309          309   SB      9          LogisticRegression     NaN  0.400000\n",
       "310          310   SB     10          LogisticRegression     NaN  0.400000\n",
       "311          311   SB     11          LogisticRegression     NaN  0.600000\n",
       "312          312   SB     12          LogisticRegression     NaN  0.400000\n",
       "313          313   SB     13          LogisticRegression     NaN  0.400000\n",
       "314          314   SB     14          LogisticRegression     NaN  0.400000\n",
       "315          315    1      0           BaggingClassifier     NaN  0.612500\n",
       "316          316    1      1           BaggingClassifier     NaN  0.675000\n",
       "317          317    1      2           BaggingClassifier     NaN  0.762500\n",
       "318          318    1      3           BaggingClassifier     NaN  0.637500\n",
       "319          319    1      4           BaggingClassifier     NaN  0.637500\n",
       "320          320    1      5           BaggingClassifier     NaN  0.712500\n",
       "321          321    1      6           BaggingClassifier     NaN  0.750000\n",
       "322          322    1      7           BaggingClassifier     NaN  0.725000\n",
       "323          323    1      8           BaggingClassifier     NaN  0.625000\n",
       "324          324    1      9           BaggingClassifier     NaN  0.712500\n",
       "325          325    1     10           BaggingClassifier     NaN  0.725000\n",
       "326          326    1     11           BaggingClassifier     NaN  0.675000\n",
       "327          327    1     12           BaggingClassifier     NaN  0.712500\n",
       "328          328    1     13           BaggingClassifier     NaN  0.825000\n",
       "329          329    1     14           BaggingClassifier     NaN  0.750000\n",
       "330          330    2      0           BaggingClassifier     NaN  0.645570\n",
       "331          331    2      1           BaggingClassifier     NaN  0.569620\n",
       "332          332    2      2           BaggingClassifier     NaN  0.696203\n",
       "333          333    2      3           BaggingClassifier     NaN  0.620253\n",
       "334          334    2      4           BaggingClassifier     NaN  0.696203\n",
       "335          335    2      5           BaggingClassifier     NaN  0.645570\n",
       "336          336    2      6           BaggingClassifier     NaN  0.620253\n",
       "337          337    2      7           BaggingClassifier     NaN  0.607595\n",
       "338          338    2      8           BaggingClassifier     NaN  0.645570\n",
       "339          339    2      9           BaggingClassifier     NaN  0.696203\n",
       "340          340    2     10           BaggingClassifier     NaN  0.696203\n",
       "341          341    2     11           BaggingClassifier     NaN  0.683544\n",
       "342          342    2     12           BaggingClassifier     NaN  0.670886\n",
       "343          343    2     13           BaggingClassifier     NaN  0.746835\n",
       "344          344    2     14           BaggingClassifier     NaN  0.734177\n",
       "345          345    3      0           BaggingClassifier     NaN  0.571429\n",
       "346          346    3      1           BaggingClassifier     NaN  0.636364\n",
       "347          347    3      2           BaggingClassifier     NaN  0.623377\n",
       "348          348    3      3           BaggingClassifier     NaN  0.610390\n",
       "349          349    3      4           BaggingClassifier     NaN  0.636364\n",
       "350          350    3      5           BaggingClassifier     NaN  0.662338\n",
       "351          351    3      6           BaggingClassifier     NaN  0.753247\n",
       "352          352    3      7           BaggingClassifier     NaN  0.714286\n",
       "353          353    3      8           BaggingClassifier     NaN  0.662338\n",
       "354          354    3      9           BaggingClassifier     NaN  0.623377\n",
       "355          355    3     10           BaggingClassifier     NaN  0.688312\n",
       "356          356    3     11           BaggingClassifier     NaN  0.662338\n",
       "357          357    3     12           BaggingClassifier     NaN  0.727273\n",
       "358          358    3     13           BaggingClassifier     NaN  0.688312\n",
       "359          359    3     14           BaggingClassifier     NaN  0.753247\n",
       "360          360    4      0           BaggingClassifier     NaN  0.657534\n",
       "361          361    4      1           BaggingClassifier     NaN  0.561644\n",
       "362          362    4      2           BaggingClassifier     NaN  0.630137\n",
       "363          363    4      3           BaggingClassifier     NaN  0.452055\n",
       "364          364    4      4           BaggingClassifier     NaN  0.726027\n",
       "365          365    4      5           BaggingClassifier     NaN  0.643836\n",
       "366          366    4      6           BaggingClassifier     NaN  0.589041\n",
       "367          367    4      7           BaggingClassifier     NaN  0.657534\n",
       "368          368    4      8           BaggingClassifier     NaN  0.616438\n",
       "369          369    4      9           BaggingClassifier     NaN  0.589041\n",
       "370          370    4     10           BaggingClassifier     NaN  0.726027\n",
       "371          371    4     11           BaggingClassifier     NaN  0.726027\n",
       "372          372    4     12           BaggingClassifier     NaN  0.753425\n",
       "373          373    4     13           BaggingClassifier     NaN  0.712329\n",
       "374          374    4     14           BaggingClassifier     NaN  0.808219\n",
       "375          375    5      0           BaggingClassifier     NaN  0.563380\n",
       "376          376    5      1           BaggingClassifier     NaN  0.704225\n",
       "377          377    5      2           BaggingClassifier     NaN  0.633803\n",
       "378          378    5      3           BaggingClassifier     NaN  0.605634\n",
       "379          379    5      4           BaggingClassifier     NaN  0.577465\n",
       "380          380    5      5           BaggingClassifier     NaN  0.704225\n",
       "381          381    5      6           BaggingClassifier     NaN  0.718310\n",
       "382          382    5      7           BaggingClassifier     NaN  0.661972\n",
       "383          383    5      8           BaggingClassifier     NaN  0.676056\n",
       "384          384    5      9           BaggingClassifier     NaN  0.647887\n",
       "385          385    5     10           BaggingClassifier     NaN  0.704225\n",
       "386          386    5     11           BaggingClassifier     NaN  0.732394\n",
       "387          387    5     12           BaggingClassifier     NaN  0.690141\n",
       "388          388    5     13           BaggingClassifier     NaN  0.690141\n",
       "389          389    5     14           BaggingClassifier     NaN  0.746479\n",
       "390          390    6      0           BaggingClassifier     NaN  0.471429\n",
       "391          391    6      1           BaggingClassifier     NaN  0.614286\n",
       "392          392    6      2           BaggingClassifier     NaN  0.542857\n",
       "393          393    6      3           BaggingClassifier     NaN  0.571429\n",
       "394          394    6      4           BaggingClassifier     NaN  0.671429\n",
       "395          395    6      5           BaggingClassifier     NaN  0.671429\n",
       "396          396    6      6           BaggingClassifier     NaN  0.585714\n",
       "397          397    6      7           BaggingClassifier     NaN  0.671429\n",
       "398          398    6      8           BaggingClassifier     NaN  0.571429\n",
       "399          399    6      9           BaggingClassifier     NaN  0.542857\n",
       "400          400    6     10           BaggingClassifier     NaN  0.685714\n",
       "401          401    6     11           BaggingClassifier     NaN  0.614286\n",
       "402          402    6     12           BaggingClassifier     NaN  0.642857\n",
       "403          403    6     13           BaggingClassifier     NaN  0.685714\n",
       "404          404    6     14           BaggingClassifier     NaN  0.742857\n",
       "405          405    7      0           BaggingClassifier     NaN  0.785714\n",
       "406          406    7      1           BaggingClassifier     NaN  0.671429\n",
       "407          407    7      2           BaggingClassifier     NaN  0.742857\n",
       "408          408    7      3           BaggingClassifier     NaN  0.585714\n",
       "409          409    7      4           BaggingClassifier     NaN  0.728571\n",
       "410          410    7      5           BaggingClassifier     NaN  0.700000\n",
       "411          411    7      6           BaggingClassifier     NaN  0.728571\n",
       "412          412    7      7           BaggingClassifier     NaN  0.757143\n",
       "413          413    7      8           BaggingClassifier     NaN  0.742857\n",
       "414          414    7      9           BaggingClassifier     NaN  0.657143\n",
       "415          415    7     10           BaggingClassifier     NaN  0.800000\n",
       "416          416    7     11           BaggingClassifier     NaN  0.814286\n",
       "417          417    7     12           BaggingClassifier     NaN  0.714286\n",
       "418          418    7     13           BaggingClassifier     NaN  0.657143\n",
       "419          419    7     14           BaggingClassifier     NaN  0.771429\n",
       "420          420    8      0           BaggingClassifier     NaN  0.724638\n",
       "421          421    8      1           BaggingClassifier     NaN  0.623188\n",
       "422          422    8      2           BaggingClassifier     NaN  0.724638\n",
       "423          423    8      3           BaggingClassifier     NaN  0.623188\n",
       "424          424    8      4           BaggingClassifier     NaN  0.724638\n",
       "425          425    8      5           BaggingClassifier     NaN  0.623188\n",
       "426          426    8      6           BaggingClassifier     NaN  0.768116\n",
       "427          427    8      7           BaggingClassifier     NaN  0.739130\n",
       "428          428    8      8           BaggingClassifier     NaN  0.753623\n",
       "429          429    8      9           BaggingClassifier     NaN  0.608696\n",
       "430          430    8     10           BaggingClassifier     NaN  0.695652\n",
       "431          431    8     11           BaggingClassifier     NaN  0.797101\n",
       "432          432    8     12           BaggingClassifier     NaN  0.768116\n",
       "433          433    8     13           BaggingClassifier     NaN  0.695652\n",
       "434          434    8     14           BaggingClassifier     NaN  0.739130\n",
       "435          435    9      0           BaggingClassifier     NaN  0.623188\n",
       "436          436    9      1           BaggingClassifier     NaN  0.550725\n",
       "437          437    9      2           BaggingClassifier     NaN  0.652174\n",
       "438          438    9      3           BaggingClassifier     NaN  0.637681\n",
       "439          439    9      4           BaggingClassifier     NaN  0.666667\n",
       "440          440    9      5           BaggingClassifier     NaN  0.652174\n",
       "441          441    9      6           BaggingClassifier     NaN  0.695652\n",
       "442          442    9      7           BaggingClassifier     NaN  0.652174\n",
       "443          443    9      8           BaggingClassifier     NaN  0.579710\n",
       "444          444    9      9           BaggingClassifier     NaN  0.652174\n",
       "445          445    9     10           BaggingClassifier     NaN  0.637681\n",
       "446          446    9     11           BaggingClassifier     NaN  0.594203\n",
       "447          447    9     12           BaggingClassifier     NaN  0.710145\n",
       "448          448    9     13           BaggingClassifier     NaN  0.666667\n",
       "449          449    9     14           BaggingClassifier     NaN  0.724638\n",
       "450          450   10      0           BaggingClassifier     NaN  0.666667\n",
       "451          451   10      1           BaggingClassifier     NaN  0.638889\n",
       "452          452   10      2           BaggingClassifier     NaN  0.583333\n",
       "453          453   10      3           BaggingClassifier     NaN  0.625000\n",
       "454          454   10      4           BaggingClassifier     NaN  0.666667\n",
       "455          455   10      5           BaggingClassifier     NaN  0.680556\n",
       "456          456   10      6           BaggingClassifier     NaN  0.652778\n",
       "457          457   10      7           BaggingClassifier     NaN  0.652778\n",
       "458          458   10      8           BaggingClassifier     NaN  0.652778\n",
       "459          459   10      9           BaggingClassifier     NaN  0.652778\n",
       "460          460   10     10           BaggingClassifier     NaN  0.694444\n",
       "461          461   10     11           BaggingClassifier     NaN  0.722222\n",
       "462          462   10     12           BaggingClassifier     NaN  0.680556\n",
       "463          463   10     13           BaggingClassifier     NaN  0.666667\n",
       "464          464   10     14           BaggingClassifier     NaN  0.777778\n",
       "465          465   11      0           BaggingClassifier     NaN  0.693333\n",
       "466          466   11      1           BaggingClassifier     NaN  0.706667\n",
       "467          467   11      2           BaggingClassifier     NaN  0.640000\n",
       "468          468   11      3           BaggingClassifier     NaN  0.600000\n",
       "469          469   11      4           BaggingClassifier     NaN  0.786667\n",
       "470          470   11      5           BaggingClassifier     NaN  0.760000\n",
       "471          471   11      6           BaggingClassifier     NaN  0.733333\n",
       "472          472   11      7           BaggingClassifier     NaN  0.720000\n",
       "473          473   11      8           BaggingClassifier     NaN  0.613333\n",
       "474          474   11      9           BaggingClassifier     NaN  0.760000\n",
       "475          475   11     10           BaggingClassifier     NaN  0.813333\n",
       "476          476   11     11           BaggingClassifier     NaN  0.813333\n",
       "477          477   11     12           BaggingClassifier     NaN  0.813333\n",
       "478          478   11     13           BaggingClassifier     NaN  0.706667\n",
       "479          479   11     14           BaggingClassifier     NaN  0.800000\n",
       "480          480   12      0           BaggingClassifier     NaN  0.602564\n",
       "481          481   12      1           BaggingClassifier     NaN  0.551282\n",
       "482          482   12      2           BaggingClassifier     NaN  0.628205\n",
       "483          483   12      3           BaggingClassifier     NaN  0.589744\n",
       "484          484   12      4           BaggingClassifier     NaN  0.679487\n",
       "485          485   12      5           BaggingClassifier     NaN  0.705128\n",
       "486          486   12      6           BaggingClassifier     NaN  0.756410\n",
       "487          487   12      7           BaggingClassifier     NaN  0.653846\n",
       "488          488   12      8           BaggingClassifier     NaN  0.461538\n",
       "489          489   12      9           BaggingClassifier     NaN  0.564103\n",
       "490          490   12     10           BaggingClassifier     NaN  0.730769\n",
       "491          491   12     11           BaggingClassifier     NaN  0.653846\n",
       "492          492   12     12           BaggingClassifier     NaN  0.564103\n",
       "493          493   12     13           BaggingClassifier     NaN  0.756410\n",
       "494          494   12     14           BaggingClassifier     NaN  0.756410\n",
       "495          495   13      0           BaggingClassifier     NaN  0.587500\n",
       "496          496   13      1           BaggingClassifier     NaN  0.762500\n",
       "497          497   13      2           BaggingClassifier     NaN  0.612500\n",
       "498          498   13      3           BaggingClassifier     NaN  0.675000\n",
       "499          499   13      4           BaggingClassifier     NaN  0.737500\n",
       "500          500   13      5           BaggingClassifier     NaN  0.762500\n",
       "501          501   13      6           BaggingClassifier     NaN  0.700000\n",
       "502          502   13      7           BaggingClassifier     NaN  0.525000\n",
       "503          503   13      8           BaggingClassifier     NaN  0.662500\n",
       "504          504   13      9           BaggingClassifier     NaN  0.750000\n",
       "505          505   13     10           BaggingClassifier     NaN  0.662500\n",
       "506          506   13     11           BaggingClassifier     NaN  0.587500\n",
       "507          507   13     12           BaggingClassifier     NaN  0.725000\n",
       "508          508   13     13           BaggingClassifier     NaN  0.750000\n",
       "509          509   13     14           BaggingClassifier     NaN  0.800000\n",
       "510          510   14      0           BaggingClassifier     NaN  0.612500\n",
       "511          511   14      1           BaggingClassifier     NaN  0.762500\n",
       "512          512   14      2           BaggingClassifier     NaN  0.600000\n",
       "513          513   14      3           BaggingClassifier     NaN  0.637500\n",
       "514          514   14      4           BaggingClassifier     NaN  0.737500\n",
       "515          515   14      5           BaggingClassifier     NaN  0.812500\n",
       "516          516   14      6           BaggingClassifier     NaN  0.612500\n",
       "517          517   14      7           BaggingClassifier     NaN  0.625000\n",
       "518          518   14      8           BaggingClassifier     NaN  0.625000\n",
       "519          519   14      9           BaggingClassifier     NaN  0.787500\n",
       "520          520   14     10           BaggingClassifier     NaN  0.762500\n",
       "521          521   14     11           BaggingClassifier     NaN  0.775000\n",
       "522          522   14     12           BaggingClassifier     NaN  0.775000\n",
       "523          523   14     13           BaggingClassifier     NaN  0.750000\n",
       "524          524   14     14           BaggingClassifier     NaN  0.812500\n",
       "525          525   15      0           BaggingClassifier     NaN  0.662500\n",
       "526          526   15      1           BaggingClassifier     NaN  0.662500\n",
       "527          527   15      2           BaggingClassifier     NaN  0.625000\n",
       "528          528   15      3           BaggingClassifier     NaN  0.687500\n",
       "529          529   15      4           BaggingClassifier     NaN  0.675000\n",
       "530          530   15      5           BaggingClassifier     NaN  0.687500\n",
       "531          531   15      6           BaggingClassifier     NaN  0.600000\n",
       "532          532   15      7           BaggingClassifier     NaN  0.725000\n",
       "533          533   15      8           BaggingClassifier     NaN  0.737500\n",
       "534          534   15      9           BaggingClassifier     NaN  0.737500\n",
       "535          535   15     10           BaggingClassifier     NaN  0.737500\n",
       "536          536   15     11           BaggingClassifier     NaN  0.687500\n",
       "537          537   15     12           BaggingClassifier     NaN  0.787500\n",
       "538          538   15     13           BaggingClassifier     NaN  0.825000\n",
       "539          539   15     14           BaggingClassifier     NaN  0.812500\n",
       "540          540   16      0           BaggingClassifier     NaN  0.537500\n",
       "541          541   16      1           BaggingClassifier     NaN  0.612500\n",
       "542          542   16      2           BaggingClassifier     NaN  0.612500\n",
       "543          543   16      3           BaggingClassifier     NaN  0.612500\n",
       "544          544   16      4           BaggingClassifier     NaN  0.637500\n",
       "545          545   16      5           BaggingClassifier     NaN  0.675000\n",
       "546          546   16      6           BaggingClassifier     NaN  0.662500\n",
       "547          547   16      7           BaggingClassifier     NaN  0.550000\n",
       "548          548   16      8           BaggingClassifier     NaN  0.537500\n",
       "549          549   16      9           BaggingClassifier     NaN  0.750000\n",
       "550          550   16     10           BaggingClassifier     NaN  0.637500\n",
       "551          551   16     11           BaggingClassifier     NaN  0.562500\n",
       "552          552   16     12           BaggingClassifier     NaN  0.725000\n",
       "553          553   16     13           BaggingClassifier     NaN  0.750000\n",
       "554          554   16     14           BaggingClassifier     NaN  0.750000\n",
       "555          555   17      0           BaggingClassifier     NaN  0.675000\n",
       "556          556   17      1           BaggingClassifier     NaN  0.675000\n",
       "557          557   17      2           BaggingClassifier     NaN  0.687500\n",
       "558          558   17      3           BaggingClassifier     NaN  0.700000\n",
       "559          559   17      4           BaggingClassifier     NaN  0.650000\n",
       "560          560   17      5           BaggingClassifier     NaN  0.737500\n",
       "561          561   17      6           BaggingClassifier     NaN  0.775000\n",
       "562          562   17      7           BaggingClassifier     NaN  0.725000\n",
       "563          563   17      8           BaggingClassifier     NaN  0.725000\n",
       "564          564   17      9           BaggingClassifier     NaN  0.675000\n",
       "565          565   17     10           BaggingClassifier     NaN  0.725000\n",
       "566          566   17     11           BaggingClassifier     NaN  0.750000\n",
       "567          567   17     12           BaggingClassifier     NaN  0.675000\n",
       "568          568   17     13           BaggingClassifier     NaN  0.687500\n",
       "569          569   17     14           BaggingClassifier     NaN  0.750000\n",
       "570          570   WC      0           BaggingClassifier     NaN  0.550000\n",
       "571          571   WC      1           BaggingClassifier     NaN  0.600000\n",
       "572          572   WC      2           BaggingClassifier     NaN  0.650000\n",
       "573          573   WC      3           BaggingClassifier     NaN  0.500000\n",
       "574          574   WC      4           BaggingClassifier     NaN  0.550000\n",
       "575          575   WC      5           BaggingClassifier     NaN  0.650000\n",
       "576          576   WC      6           BaggingClassifier     NaN  0.750000\n",
       "577          577   WC      7           BaggingClassifier     NaN  0.700000\n",
       "578          578   WC      8           BaggingClassifier     NaN  0.450000\n",
       "579          579   WC      9           BaggingClassifier     NaN  0.550000\n",
       "580          580   WC     10           BaggingClassifier     NaN  0.800000\n",
       "581          581   WC     11           BaggingClassifier     NaN  0.750000\n",
       "582          582   WC     12           BaggingClassifier     NaN  0.650000\n",
       "583          583   WC     13           BaggingClassifier     NaN  0.650000\n",
       "584          584   WC     14           BaggingClassifier     NaN  0.800000\n",
       "585          585   DV      0           BaggingClassifier     NaN  0.700000\n",
       "586          586   DV      1           BaggingClassifier     NaN  0.500000\n",
       "587          587   DV      2           BaggingClassifier     NaN  0.450000\n",
       "588          588   DV      3           BaggingClassifier     NaN  0.550000\n",
       "589          589   DV      4           BaggingClassifier     NaN  0.600000\n",
       "590          590   DV      5           BaggingClassifier     NaN  0.550000\n",
       "591          591   DV      6           BaggingClassifier     NaN  0.400000\n",
       "592          592   DV      7           BaggingClassifier     NaN  0.600000\n",
       "593          593   DV      8           BaggingClassifier     NaN  0.600000\n",
       "594          594   DV      9           BaggingClassifier     NaN  0.400000\n",
       "595          595   DV     10           BaggingClassifier     NaN  0.450000\n",
       "596          596   DV     11           BaggingClassifier     NaN  0.550000\n",
       "597          597   DV     12           BaggingClassifier     NaN  0.500000\n",
       "598          598   DV     13           BaggingClassifier     NaN  0.500000\n",
       "599          599   DV     14           BaggingClassifier     NaN  0.600000\n",
       "600          600   CC      0           BaggingClassifier     NaN  0.400000\n",
       "601          601   CC      1           BaggingClassifier     NaN  0.500000\n",
       "602          602   CC      2           BaggingClassifier     NaN  0.500000\n",
       "603          603   CC      3           BaggingClassifier     NaN  0.500000\n",
       "604          604   CC      4           BaggingClassifier     NaN  0.600000\n",
       "605          605   CC      5           BaggingClassifier     NaN  0.600000\n",
       "606          606   CC      6           BaggingClassifier     NaN  0.400000\n",
       "607          607   CC      7           BaggingClassifier     NaN  0.500000\n",
       "608          608   CC      8           BaggingClassifier     NaN  0.400000\n",
       "609          609   CC      9           BaggingClassifier     NaN  0.500000\n",
       "610          610   CC     10           BaggingClassifier     NaN  0.600000\n",
       "611          611   CC     11           BaggingClassifier     NaN  0.500000\n",
       "612          612   CC     12           BaggingClassifier     NaN  0.500000\n",
       "613          613   CC     13           BaggingClassifier     NaN  0.400000\n",
       "614          614   CC     14           BaggingClassifier     NaN  0.500000\n",
       "615          615   SB      0           BaggingClassifier     NaN  0.400000\n",
       "616          616   SB      1           BaggingClassifier     NaN  0.600000\n",
       "617          617   SB      2           BaggingClassifier     NaN  0.600000\n",
       "618          618   SB      3           BaggingClassifier     NaN  0.600000\n",
       "619          619   SB      4           BaggingClassifier     NaN  0.400000\n",
       "620          620   SB      5           BaggingClassifier     NaN  0.400000\n",
       "621          621   SB      6           BaggingClassifier     NaN  0.400000\n",
       "622          622   SB      7           BaggingClassifier     NaN  0.600000\n",
       "623          623   SB      8           BaggingClassifier     NaN  0.600000\n",
       "624          624   SB      9           BaggingClassifier     NaN  0.400000\n",
       "625          625   SB     10           BaggingClassifier     NaN  0.400000\n",
       "626          626   SB     11           BaggingClassifier     NaN  0.800000\n",
       "627          627   SB     12           BaggingClassifier     NaN  0.600000\n",
       "628          628   SB     13           BaggingClassifier     NaN  0.400000\n",
       "629          629   SB     14           BaggingClassifier     NaN  0.400000\n",
       "630          630    1      0      RandomForestClassifier     NaN  0.612500\n",
       "631          631    1      1      RandomForestClassifier     NaN  0.675000\n",
       "632          632    1      2      RandomForestClassifier     NaN  0.762500\n",
       "633          633    1      3      RandomForestClassifier     NaN  0.637500\n",
       "634          634    1      4      RandomForestClassifier     NaN  0.637500\n",
       "635          635    1      5      RandomForestClassifier     NaN  0.762500\n",
       "636          636    1      6      RandomForestClassifier     NaN  0.750000\n",
       "637          637    1      7      RandomForestClassifier     NaN  0.750000\n",
       "638          638    1      8      RandomForestClassifier     NaN  0.612500\n",
       "639          639    1      9      RandomForestClassifier     NaN  0.687500\n",
       "640          640    1     10      RandomForestClassifier     NaN  0.700000\n",
       "641          641    1     11      RandomForestClassifier     NaN  0.712500\n",
       "642          642    1     12      RandomForestClassifier     NaN  0.725000\n",
       "643          643    1     13      RandomForestClassifier     NaN  0.800000\n",
       "644          644    1     14      RandomForestClassifier     NaN  0.825000\n",
       "645          645    2      0      RandomForestClassifier     NaN  0.645570\n",
       "646          646    2      1      RandomForestClassifier     NaN  0.569620\n",
       "647          647    2      2      RandomForestClassifier     NaN  0.670886\n",
       "648          648    2      3      RandomForestClassifier     NaN  0.620253\n",
       "649          649    2      4      RandomForestClassifier     NaN  0.620253\n",
       "650          650    2      5      RandomForestClassifier     NaN  0.632911\n",
       "651          651    2      6      RandomForestClassifier     NaN  0.620253\n",
       "652          652    2      7      RandomForestClassifier     NaN  0.607595\n",
       "653          653    2      8      RandomForestClassifier     NaN  0.594937\n",
       "654          654    2      9      RandomForestClassifier     NaN  0.670886\n",
       "655          655    2     10      RandomForestClassifier     NaN  0.670886\n",
       "656          656    2     11      RandomForestClassifier     NaN  0.734177\n",
       "657          657    2     12      RandomForestClassifier     NaN  0.696203\n",
       "658          658    2     13      RandomForestClassifier     NaN  0.734177\n",
       "659          659    2     14      RandomForestClassifier     NaN  0.759494\n",
       "660          660    3      0      RandomForestClassifier     NaN  0.571429\n",
       "661          661    3      1      RandomForestClassifier     NaN  0.636364\n",
       "662          662    3      2      RandomForestClassifier     NaN  0.571429\n",
       "663          663    3      3      RandomForestClassifier     NaN  0.610390\n",
       "664          664    3      4      RandomForestClassifier     NaN  0.636364\n",
       "665          665    3      5      RandomForestClassifier     NaN  0.675325\n",
       "666          666    3      6      RandomForestClassifier     NaN  0.740260\n",
       "667          667    3      7      RandomForestClassifier     NaN  0.727273\n",
       "668          668    3      8      RandomForestClassifier     NaN  0.701299\n",
       "669          669    3      9      RandomForestClassifier     NaN  0.649351\n",
       "670          670    3     10      RandomForestClassifier     NaN  0.701299\n",
       "671          671    3     11      RandomForestClassifier     NaN  0.662338\n",
       "672          672    3     12      RandomForestClassifier     NaN  0.753247\n",
       "673          673    3     13      RandomForestClassifier     NaN  0.727273\n",
       "674          674    3     14      RandomForestClassifier     NaN  0.766234\n",
       "675          675    4      0      RandomForestClassifier     NaN  0.657534\n",
       "676          676    4      1      RandomForestClassifier     NaN  0.671233\n",
       "677          677    4      2      RandomForestClassifier     NaN  0.616438\n",
       "678          678    4      3      RandomForestClassifier     NaN  0.452055\n",
       "679          679    4      4      RandomForestClassifier     NaN  0.726027\n",
       "680          680    4      5      RandomForestClassifier     NaN  0.684932\n",
       "681          681    4      6      RandomForestClassifier     NaN  0.630137\n",
       "682          682    4      7      RandomForestClassifier     NaN  0.671233\n",
       "683          683    4      8      RandomForestClassifier     NaN  0.684932\n",
       "684          684    4      9      RandomForestClassifier     NaN  0.589041\n",
       "685          685    4     10      RandomForestClassifier     NaN  0.767123\n",
       "686          686    4     11      RandomForestClassifier     NaN  0.698630\n",
       "687          687    4     12      RandomForestClassifier     NaN  0.767123\n",
       "688          688    4     13      RandomForestClassifier     NaN  0.712329\n",
       "689          689    4     14      RandomForestClassifier     NaN  0.835616\n",
       "690          690    5      0      RandomForestClassifier     NaN  0.563380\n",
       "691          691    5      1      RandomForestClassifier     NaN  0.704225\n",
       "692          692    5      2      RandomForestClassifier     NaN  0.633803\n",
       "693          693    5      3      RandomForestClassifier     NaN  0.605634\n",
       "694          694    5      4      RandomForestClassifier     NaN  0.661972\n",
       "695          695    5      5      RandomForestClassifier     NaN  0.690141\n",
       "696          696    5      6      RandomForestClassifier     NaN  0.732394\n",
       "697          697    5      7      RandomForestClassifier     NaN  0.647887\n",
       "698          698    5      8      RandomForestClassifier     NaN  0.661972\n",
       "699          699    5      9      RandomForestClassifier     NaN  0.647887\n",
       "700          700    5     10      RandomForestClassifier     NaN  0.704225\n",
       "701          701    5     11      RandomForestClassifier     NaN  0.690141\n",
       "702          702    5     12      RandomForestClassifier     NaN  0.690141\n",
       "703          703    5     13      RandomForestClassifier     NaN  0.732394\n",
       "704          704    5     14      RandomForestClassifier     NaN  0.788732\n",
       "705          705    6      0      RandomForestClassifier     NaN  0.485714\n",
       "706          706    6      1      RandomForestClassifier     NaN  0.614286\n",
       "707          707    6      2      RandomForestClassifier     NaN  0.542857\n",
       "708          708    6      3      RandomForestClassifier     NaN  0.571429\n",
       "709          709    6      4      RandomForestClassifier     NaN  0.671429\n",
       "710          710    6      5      RandomForestClassifier     NaN  0.671429\n",
       "711          711    6      6      RandomForestClassifier     NaN  0.614286\n",
       "712          712    6      7      RandomForestClassifier     NaN  0.642857\n",
       "713          713    6      8      RandomForestClassifier     NaN  0.571429\n",
       "714          714    6      9      RandomForestClassifier     NaN  0.557143\n",
       "715          715    6     10      RandomForestClassifier     NaN  0.714286\n",
       "716          716    6     11      RandomForestClassifier     NaN  0.700000\n",
       "717          717    6     12      RandomForestClassifier     NaN  0.642857\n",
       "718          718    6     13      RandomForestClassifier     NaN  0.671429\n",
       "719          719    6     14      RandomForestClassifier     NaN  0.728571\n",
       "720          720    7      0      RandomForestClassifier     NaN  0.785714\n",
       "721          721    7      1      RandomForestClassifier     NaN  0.671429\n",
       "722          722    7      2      RandomForestClassifier     NaN  0.742857\n",
       "723          723    7      3      RandomForestClassifier     NaN  0.585714\n",
       "724          724    7      4      RandomForestClassifier     NaN  0.757143\n",
       "725          725    7      5      RandomForestClassifier     NaN  0.742857\n",
       "726          726    7      6      RandomForestClassifier     NaN  0.728571\n",
       "727          727    7      7      RandomForestClassifier     NaN  0.757143\n",
       "728          728    7      8      RandomForestClassifier     NaN  0.742857\n",
       "729          729    7      9      RandomForestClassifier     NaN  0.671429\n",
       "730          730    7     10      RandomForestClassifier     NaN  0.814286\n",
       "731          731    7     11      RandomForestClassifier     NaN  0.785714\n",
       "732          732    7     12      RandomForestClassifier     NaN  0.757143\n",
       "733          733    7     13      RandomForestClassifier     NaN  0.771429\n",
       "734          734    7     14      RandomForestClassifier     NaN  0.828571\n",
       "735          735    8      0      RandomForestClassifier     NaN  0.724638\n",
       "736          736    8      1      RandomForestClassifier     NaN  0.623188\n",
       "737          737    8      2      RandomForestClassifier     NaN  0.695652\n",
       "738          738    8      3      RandomForestClassifier     NaN  0.623188\n",
       "739          739    8      4      RandomForestClassifier     NaN  0.724638\n",
       "740          740    8      5      RandomForestClassifier     NaN  0.724638\n",
       "741          741    8      6      RandomForestClassifier     NaN  0.710145\n",
       "742          742    8      7      RandomForestClassifier     NaN  0.739130\n",
       "743          743    8      8      RandomForestClassifier     NaN  0.739130\n",
       "744          744    8      9      RandomForestClassifier     NaN  0.608696\n",
       "745          745    8     10      RandomForestClassifier     NaN  0.739130\n",
       "746          746    8     11      RandomForestClassifier     NaN  0.753623\n",
       "747          747    8     12      RandomForestClassifier     NaN  0.753623\n",
       "748          748    8     13      RandomForestClassifier     NaN  0.652174\n",
       "749          749    8     14      RandomForestClassifier     NaN  0.797101\n",
       "750          750    9      0      RandomForestClassifier     NaN  0.623188\n",
       "751          751    9      1      RandomForestClassifier     NaN  0.550725\n",
       "752          752    9      2      RandomForestClassifier     NaN  0.652174\n",
       "753          753    9      3      RandomForestClassifier     NaN  0.666667\n",
       "754          754    9      4      RandomForestClassifier     NaN  0.695652\n",
       "755          755    9      5      RandomForestClassifier     NaN  0.652174\n",
       "756          756    9      6      RandomForestClassifier     NaN  0.695652\n",
       "757          757    9      7      RandomForestClassifier     NaN  0.666667\n",
       "758          758    9      8      RandomForestClassifier     NaN  0.579710\n",
       "759          759    9      9      RandomForestClassifier     NaN  0.652174\n",
       "760          760    9     10      RandomForestClassifier     NaN  0.666667\n",
       "761          761    9     11      RandomForestClassifier     NaN  0.623188\n",
       "762          762    9     12      RandomForestClassifier     NaN  0.724638\n",
       "763          763    9     13      RandomForestClassifier     NaN  0.739130\n",
       "764          764    9     14      RandomForestClassifier     NaN  0.710145\n",
       "765          765   10      0      RandomForestClassifier     NaN  0.666667\n",
       "766          766   10      1      RandomForestClassifier     NaN  0.638889\n",
       "767          767   10      2      RandomForestClassifier     NaN  0.583333\n",
       "768          768   10      3      RandomForestClassifier     NaN  0.625000\n",
       "769          769   10      4      RandomForestClassifier     NaN  0.680556\n",
       "770          770   10      5      RandomForestClassifier     NaN  0.680556\n",
       "771          771   10      6      RandomForestClassifier     NaN  0.638889\n",
       "772          772   10      7      RandomForestClassifier     NaN  0.625000\n",
       "773          773   10      8      RandomForestClassifier     NaN  0.680556\n",
       "774          774   10      9      RandomForestClassifier     NaN  0.722222\n",
       "775          775   10     10      RandomForestClassifier     NaN  0.694444\n",
       "776          776   10     11      RandomForestClassifier     NaN  0.750000\n",
       "777          777   10     12      RandomForestClassifier     NaN  0.722222\n",
       "778          778   10     13      RandomForestClassifier     NaN  0.666667\n",
       "779          779   10     14      RandomForestClassifier     NaN  0.805556\n",
       "780          780   11      0      RandomForestClassifier     NaN  0.680000\n",
       "781          781   11      1      RandomForestClassifier     NaN  0.706667\n",
       "782          782   11      2      RandomForestClassifier     NaN  0.640000\n",
       "783          783   11      3      RandomForestClassifier     NaN  0.586667\n",
       "784          784   11      4      RandomForestClassifier     NaN  0.786667\n",
       "785          785   11      5      RandomForestClassifier     NaN  0.826667\n",
       "786          786   11      6      RandomForestClassifier     NaN  0.733333\n",
       "787          787   11      7      RandomForestClassifier     NaN  0.733333\n",
       "788          788   11      8      RandomForestClassifier     NaN  0.693333\n",
       "789          789   11      9      RandomForestClassifier     NaN  0.760000\n",
       "790          790   11     10      RandomForestClassifier     NaN  0.826667\n",
       "791          791   11     11      RandomForestClassifier     NaN  0.813333\n",
       "792          792   11     12      RandomForestClassifier     NaN  0.773333\n",
       "793          793   11     13      RandomForestClassifier     NaN  0.733333\n",
       "794          794   11     14      RandomForestClassifier     NaN  0.826667\n",
       "795          795   12      0      RandomForestClassifier     NaN  0.602564\n",
       "796          796   12      1      RandomForestClassifier     NaN  0.551282\n",
       "797          797   12      2      RandomForestClassifier     NaN  0.628205\n",
       "798          798   12      3      RandomForestClassifier     NaN  0.589744\n",
       "799          799   12      4      RandomForestClassifier     NaN  0.679487\n",
       "800          800   12      5      RandomForestClassifier     NaN  0.730769\n",
       "801          801   12      6      RandomForestClassifier     NaN  0.756410\n",
       "802          802   12      7      RandomForestClassifier     NaN  0.641026\n",
       "803          803   12      8      RandomForestClassifier     NaN  0.435897\n",
       "804          804   12      9      RandomForestClassifier     NaN  0.602564\n",
       "805          805   12     10      RandomForestClassifier     NaN  0.730769\n",
       "806          806   12     11      RandomForestClassifier     NaN  0.679487\n",
       "807          807   12     12      RandomForestClassifier     NaN  0.576923\n",
       "808          808   12     13      RandomForestClassifier     NaN  0.782051\n",
       "809          809   12     14      RandomForestClassifier     NaN  0.705128\n",
       "810          810   13      0      RandomForestClassifier     NaN  0.587500\n",
       "811          811   13      1      RandomForestClassifier     NaN  0.762500\n",
       "812          812   13      2      RandomForestClassifier     NaN  0.612500\n",
       "813          813   13      3      RandomForestClassifier     NaN  0.675000\n",
       "814          814   13      4      RandomForestClassifier     NaN  0.700000\n",
       "815          815   13      5      RandomForestClassifier     NaN  0.787500\n",
       "816          816   13      6      RandomForestClassifier     NaN  0.700000\n",
       "817          817   13      7      RandomForestClassifier     NaN  0.462500\n",
       "818          818   13      8      RandomForestClassifier     NaN  0.637500\n",
       "819          819   13      9      RandomForestClassifier     NaN  0.787500\n",
       "820          820   13     10      RandomForestClassifier     NaN  0.700000\n",
       "821          821   13     11      RandomForestClassifier     NaN  0.625000\n",
       "822          822   13     12      RandomForestClassifier     NaN  0.737500\n",
       "823          823   13     13      RandomForestClassifier     NaN  0.750000\n",
       "824          824   13     14      RandomForestClassifier     NaN  0.750000\n",
       "825          825   14      0      RandomForestClassifier     NaN  0.612500\n",
       "826          826   14      1      RandomForestClassifier     NaN  0.762500\n",
       "827          827   14      2      RandomForestClassifier     NaN  0.600000\n",
       "828          828   14      3      RandomForestClassifier     NaN  0.637500\n",
       "829          829   14      4      RandomForestClassifier     NaN  0.762500\n",
       "830          830   14      5      RandomForestClassifier     NaN  0.725000\n",
       "831          831   14      6      RandomForestClassifier     NaN  0.612500\n",
       "832          832   14      7      RandomForestClassifier     NaN  0.700000\n",
       "833          833   14      8      RandomForestClassifier     NaN  0.650000\n",
       "834          834   14      9      RandomForestClassifier     NaN  0.775000\n",
       "835          835   14     10      RandomForestClassifier     NaN  0.762500\n",
       "836          836   14     11      RandomForestClassifier     NaN  0.712500\n",
       "837          837   14     12      RandomForestClassifier     NaN  0.800000\n",
       "838          838   14     13      RandomForestClassifier     NaN  0.775000\n",
       "839          839   14     14      RandomForestClassifier     NaN  0.862500\n",
       "840          840   15      0      RandomForestClassifier     NaN  0.662500\n",
       "841          841   15      1      RandomForestClassifier     NaN  0.662500\n",
       "842          842   15      2      RandomForestClassifier     NaN  0.625000\n",
       "843          843   15      3      RandomForestClassifier     NaN  0.687500\n",
       "844          844   15      4      RandomForestClassifier     NaN  0.712500\n",
       "845          845   15      5      RandomForestClassifier     NaN  0.675000\n",
       "846          846   15      6      RandomForestClassifier     NaN  0.600000\n",
       "847          847   15      7      RandomForestClassifier     NaN  0.725000\n",
       "848          848   15      8      RandomForestClassifier     NaN  0.737500\n",
       "849          849   15      9      RandomForestClassifier     NaN  0.737500\n",
       "850          850   15     10      RandomForestClassifier     NaN  0.775000\n",
       "851          851   15     11      RandomForestClassifier     NaN  0.675000\n",
       "852          852   15     12      RandomForestClassifier     NaN  0.800000\n",
       "853          853   15     13      RandomForestClassifier     NaN  0.800000\n",
       "854          854   15     14      RandomForestClassifier     NaN  0.800000\n",
       "855          855   16      0      RandomForestClassifier     NaN  0.537500\n",
       "856          856   16      1      RandomForestClassifier     NaN  0.612500\n",
       "857          857   16      2      RandomForestClassifier     NaN  0.612500\n",
       "858          858   16      3      RandomForestClassifier     NaN  0.612500\n",
       "859          859   16      4      RandomForestClassifier     NaN  0.650000\n",
       "860          860   16      5      RandomForestClassifier     NaN  0.650000\n",
       "861          861   16      6      RandomForestClassifier     NaN  0.675000\n",
       "862          862   16      7      RandomForestClassifier     NaN  0.537500\n",
       "863          863   16      8      RandomForestClassifier     NaN  0.562500\n",
       "864          864   16      9      RandomForestClassifier     NaN  0.725000\n",
       "865          865   16     10      RandomForestClassifier     NaN  0.712500\n",
       "866          866   16     11      RandomForestClassifier     NaN  0.600000\n",
       "867          867   16     12      RandomForestClassifier     NaN  0.675000\n",
       "868          868   16     13      RandomForestClassifier     NaN  0.750000\n",
       "869          869   16     14      RandomForestClassifier     NaN  0.750000\n",
       "870          870   17      0      RandomForestClassifier     NaN  0.675000\n",
       "871          871   17      1      RandomForestClassifier     NaN  0.675000\n",
       "872          872   17      2      RandomForestClassifier     NaN  0.687500\n",
       "873          873   17      3      RandomForestClassifier     NaN  0.625000\n",
       "874          874   17      4      RandomForestClassifier     NaN  0.650000\n",
       "875          875   17      5      RandomForestClassifier     NaN  0.725000\n",
       "876          876   17      6      RandomForestClassifier     NaN  0.737500\n",
       "877          877   17      7      RandomForestClassifier     NaN  0.687500\n",
       "878          878   17      8      RandomForestClassifier     NaN  0.712500\n",
       "879          879   17      9      RandomForestClassifier     NaN  0.662500\n",
       "880          880   17     10      RandomForestClassifier     NaN  0.737500\n",
       "881          881   17     11      RandomForestClassifier     NaN  0.762500\n",
       "882          882   17     12      RandomForestClassifier     NaN  0.737500\n",
       "883          883   17     13      RandomForestClassifier     NaN  0.750000\n",
       "884          884   17     14      RandomForestClassifier     NaN  0.787500\n",
       "885          885   WC      0      RandomForestClassifier     NaN  0.550000\n",
       "886          886   WC      1      RandomForestClassifier     NaN  0.600000\n",
       "887          887   WC      2      RandomForestClassifier     NaN  0.650000\n",
       "888          888   WC      3      RandomForestClassifier     NaN  0.500000\n",
       "889          889   WC      4      RandomForestClassifier     NaN  0.600000\n",
       "890          890   WC      5      RandomForestClassifier     NaN  0.600000\n",
       "891          891   WC      6      RandomForestClassifier     NaN  0.700000\n",
       "892          892   WC      7      RandomForestClassifier     NaN  0.600000\n",
       "893          893   WC      8      RandomForestClassifier     NaN  0.450000\n",
       "894          894   WC      9      RandomForestClassifier     NaN  0.550000\n",
       "895          895   WC     10      RandomForestClassifier     NaN  0.750000\n",
       "896          896   WC     11      RandomForestClassifier     NaN  0.750000\n",
       "897          897   WC     12      RandomForestClassifier     NaN  0.600000\n",
       "898          898   WC     13      RandomForestClassifier     NaN  0.700000\n",
       "899          899   WC     14      RandomForestClassifier     NaN  0.800000\n",
       "900          900   DV      0      RandomForestClassifier     NaN  0.700000\n",
       "901          901   DV      1      RandomForestClassifier     NaN  0.550000\n",
       "902          902   DV      2      RandomForestClassifier     NaN  0.450000\n",
       "903          903   DV      3      RandomForestClassifier     NaN  0.550000\n",
       "904          904   DV      4      RandomForestClassifier     NaN  0.600000\n",
       "905          905   DV      5      RandomForestClassifier     NaN  0.500000\n",
       "906          906   DV      6      RandomForestClassifier     NaN  0.400000\n",
       "907          907   DV      7      RandomForestClassifier     NaN  0.650000\n",
       "908          908   DV      8      RandomForestClassifier     NaN  0.500000\n",
       "909          909   DV      9      RandomForestClassifier     NaN  0.400000\n",
       "910          910   DV     10      RandomForestClassifier     NaN  0.550000\n",
       "911          911   DV     11      RandomForestClassifier     NaN  0.600000\n",
       "912          912   DV     12      RandomForestClassifier     NaN  0.500000\n",
       "913          913   DV     13      RandomForestClassifier     NaN  0.450000\n",
       "914          914   DV     14      RandomForestClassifier     NaN  0.450000\n",
       "915          915   CC      0      RandomForestClassifier     NaN  0.400000\n",
       "916          916   CC      1      RandomForestClassifier     NaN  0.500000\n",
       "917          917   CC      2      RandomForestClassifier     NaN  0.500000\n",
       "918          918   CC      3      RandomForestClassifier     NaN  0.500000\n",
       "919          919   CC      4      RandomForestClassifier     NaN  0.400000\n",
       "920          920   CC      5      RandomForestClassifier     NaN  0.600000\n",
       "921          921   CC      6      RandomForestClassifier     NaN  0.400000\n",
       "922          922   CC      7      RandomForestClassifier     NaN  0.400000\n",
       "923          923   CC      8      RandomForestClassifier     NaN  0.400000\n",
       "924          924   CC      9      RandomForestClassifier     NaN  0.500000\n",
       "925          925   CC     10      RandomForestClassifier     NaN  0.500000\n",
       "926          926   CC     11      RandomForestClassifier     NaN  0.400000\n",
       "927          927   CC     12      RandomForestClassifier     NaN  0.400000\n",
       "928          928   CC     13      RandomForestClassifier     NaN  0.400000\n",
       "929          929   CC     14      RandomForestClassifier     NaN  0.400000\n",
       "930          930   SB      0      RandomForestClassifier     NaN  0.400000\n",
       "931          931   SB      1      RandomForestClassifier     NaN  0.400000\n",
       "932          932   SB      2      RandomForestClassifier     NaN  0.600000\n",
       "933          933   SB      3      RandomForestClassifier     NaN  0.600000\n",
       "934          934   SB      4      RandomForestClassifier     NaN  0.400000\n",
       "935          935   SB      5      RandomForestClassifier     NaN  0.400000\n",
       "936          936   SB      6      RandomForestClassifier     NaN  0.600000\n",
       "937          937   SB      7      RandomForestClassifier     NaN  0.600000\n",
       "938          938   SB      8      RandomForestClassifier     NaN  0.400000\n",
       "939          939   SB      9      RandomForestClassifier     NaN  0.400000\n",
       "940          940   SB     10      RandomForestClassifier     NaN  0.400000\n",
       "941          941   SB     11      RandomForestClassifier     NaN  0.600000\n",
       "942          942   SB     12      RandomForestClassifier     NaN  0.400000\n",
       "943          943   SB     13      RandomForestClassifier     NaN  0.400000\n",
       "944          944   SB     14      RandomForestClassifier     NaN  0.400000\n",
       "945          945    1      0        ExtraTreesClassifier     NaN  0.612500\n",
       "946          946    1      1        ExtraTreesClassifier     NaN  0.675000\n",
       "947          947    1      2        ExtraTreesClassifier     NaN  0.762500\n",
       "948          948    1      3        ExtraTreesClassifier     NaN  0.637500\n",
       "949          949    1      4        ExtraTreesClassifier     NaN  0.637500\n",
       "950          950    1      5        ExtraTreesClassifier     NaN  0.787500\n",
       "951          951    1      6        ExtraTreesClassifier     NaN  0.750000\n",
       "952          952    1      7        ExtraTreesClassifier     NaN  0.737500\n",
       "953          953    1      8        ExtraTreesClassifier     NaN  0.612500\n",
       "954          954    1      9        ExtraTreesClassifier     NaN  0.687500\n",
       "955          955    1     10        ExtraTreesClassifier     NaN  0.775000\n",
       "956          956    1     11        ExtraTreesClassifier     NaN  0.750000\n",
       "957          957    1     12        ExtraTreesClassifier     NaN  0.750000\n",
       "958          958    1     13        ExtraTreesClassifier     NaN  0.787500\n",
       "959          959    1     14        ExtraTreesClassifier     NaN  0.837500\n",
       "960          960    2      0        ExtraTreesClassifier     NaN  0.645570\n",
       "961          961    2      1        ExtraTreesClassifier     NaN  0.569620\n",
       "962          962    2      2        ExtraTreesClassifier     NaN  0.670886\n",
       "963          963    2      3        ExtraTreesClassifier     NaN  0.620253\n",
       "964          964    2      4        ExtraTreesClassifier     NaN  0.620253\n",
       "965          965    2      5        ExtraTreesClassifier     NaN  0.645570\n",
       "966          966    2      6        ExtraTreesClassifier     NaN  0.683544\n",
       "967          967    2      7        ExtraTreesClassifier     NaN  0.607595\n",
       "968          968    2      8        ExtraTreesClassifier     NaN  0.607595\n",
       "969          969    2      9        ExtraTreesClassifier     NaN  0.696203\n",
       "970          970    2     10        ExtraTreesClassifier     NaN  0.670886\n",
       "971          971    2     11        ExtraTreesClassifier     NaN  0.734177\n",
       "972          972    2     12        ExtraTreesClassifier     NaN  0.658228\n",
       "973          973    2     13        ExtraTreesClassifier     NaN  0.746835\n",
       "974          974    2     14        ExtraTreesClassifier     NaN  0.784810\n",
       "975          975    3      0        ExtraTreesClassifier     NaN  0.571429\n",
       "976          976    3      1        ExtraTreesClassifier     NaN  0.636364\n",
       "977          977    3      2        ExtraTreesClassifier     NaN  0.623377\n",
       "978          978    3      3        ExtraTreesClassifier     NaN  0.610390\n",
       "979          979    3      4        ExtraTreesClassifier     NaN  0.636364\n",
       "980          980    3      5        ExtraTreesClassifier     NaN  0.675325\n",
       "981          981    3      6        ExtraTreesClassifier     NaN  0.688312\n",
       "982          982    3      7        ExtraTreesClassifier     NaN  0.714286\n",
       "983          983    3      8        ExtraTreesClassifier     NaN  0.662338\n",
       "984          984    3      9        ExtraTreesClassifier     NaN  0.649351\n",
       "985          985    3     10        ExtraTreesClassifier     NaN  0.675325\n",
       "986          986    3     11        ExtraTreesClassifier     NaN  0.662338\n",
       "987          987    3     12        ExtraTreesClassifier     NaN  0.740260\n",
       "988          988    3     13        ExtraTreesClassifier     NaN  0.727273\n",
       "989          989    3     14        ExtraTreesClassifier     NaN  0.779221\n",
       "990          990    4      0        ExtraTreesClassifier     NaN  0.657534\n",
       "991          991    4      1        ExtraTreesClassifier     NaN  0.671233\n",
       "992          992    4      2        ExtraTreesClassifier     NaN  0.616438\n",
       "993          993    4      3        ExtraTreesClassifier     NaN  0.452055\n",
       "994          994    4      4        ExtraTreesClassifier     NaN  0.726027\n",
       "995          995    4      5        ExtraTreesClassifier     NaN  0.684932\n",
       "996          996    4      6        ExtraTreesClassifier     NaN  0.630137\n",
       "997          997    4      7        ExtraTreesClassifier     NaN  0.671233\n",
       "998          998    4      8        ExtraTreesClassifier     NaN  0.671233\n",
       "999          999    4      9        ExtraTreesClassifier     NaN  0.589041\n",
       "1000        1000    4     10        ExtraTreesClassifier     NaN  0.753425\n",
       "1001        1001    4     11        ExtraTreesClassifier     NaN  0.726027\n",
       "1002        1002    4     12        ExtraTreesClassifier     NaN  0.726027\n",
       "1003        1003    4     13        ExtraTreesClassifier     NaN  0.712329\n",
       "1004        1004    4     14        ExtraTreesClassifier     NaN  0.821918\n",
       "1005        1005    5      0        ExtraTreesClassifier     NaN  0.563380\n",
       "1006        1006    5      1        ExtraTreesClassifier     NaN  0.704225\n",
       "1007        1007    5      2        ExtraTreesClassifier     NaN  0.718310\n",
       "1008        1008    5      3        ExtraTreesClassifier     NaN  0.605634\n",
       "1009        1009    5      4        ExtraTreesClassifier     NaN  0.633803\n",
       "1010        1010    5      5        ExtraTreesClassifier     NaN  0.704225\n",
       "1011        1011    5      6        ExtraTreesClassifier     NaN  0.718310\n",
       "1012        1012    5      7        ExtraTreesClassifier     NaN  0.647887\n",
       "1013        1013    5      8        ExtraTreesClassifier     NaN  0.661972\n",
       "1014        1014    5      9        ExtraTreesClassifier     NaN  0.676056\n",
       "1015        1015    5     10        ExtraTreesClassifier     NaN  0.732394\n",
       "1016        1016    5     11        ExtraTreesClassifier     NaN  0.647887\n",
       "1017        1017    5     12        ExtraTreesClassifier     NaN  0.690141\n",
       "1018        1018    5     13        ExtraTreesClassifier     NaN  0.704225\n",
       "1019        1019    5     14        ExtraTreesClassifier     NaN  0.774648\n",
       "1020        1020    6      0        ExtraTreesClassifier     NaN  0.471429\n",
       "1021        1021    6      1        ExtraTreesClassifier     NaN  0.614286\n",
       "1022        1022    6      2        ExtraTreesClassifier     NaN  0.542857\n",
       "1023        1023    6      3        ExtraTreesClassifier     NaN  0.571429\n",
       "1024        1024    6      4        ExtraTreesClassifier     NaN  0.671429\n",
       "1025        1025    6      5        ExtraTreesClassifier     NaN  0.585714\n",
       "1026        1026    6      6        ExtraTreesClassifier     NaN  0.657143\n",
       "1027        1027    6      7        ExtraTreesClassifier     NaN  0.657143\n",
       "1028        1028    6      8        ExtraTreesClassifier     NaN  0.571429\n",
       "1029        1029    6      9        ExtraTreesClassifier     NaN  0.557143\n",
       "1030        1030    6     10        ExtraTreesClassifier     NaN  0.671429\n",
       "1031        1031    6     11        ExtraTreesClassifier     NaN  0.685714\n",
       "1032        1032    6     12        ExtraTreesClassifier     NaN  0.642857\n",
       "1033        1033    6     13        ExtraTreesClassifier     NaN  0.685714\n",
       "1034        1034    6     14        ExtraTreesClassifier     NaN  0.685714\n",
       "1035        1035    7      0        ExtraTreesClassifier     NaN  0.785714\n",
       "1036        1036    7      1        ExtraTreesClassifier     NaN  0.671429\n",
       "1037        1037    7      2        ExtraTreesClassifier     NaN  0.757143\n",
       "1038        1038    7      3        ExtraTreesClassifier     NaN  0.585714\n",
       "1039        1039    7      4        ExtraTreesClassifier     NaN  0.785714\n",
       "1040        1040    7      5        ExtraTreesClassifier     NaN  0.742857\n",
       "1041        1041    7      6        ExtraTreesClassifier     NaN  0.742857\n",
       "1042        1042    7      7        ExtraTreesClassifier     NaN  0.757143\n",
       "1043        1043    7      8        ExtraTreesClassifier     NaN  0.700000\n",
       "1044        1044    7      9        ExtraTreesClassifier     NaN  0.671429\n",
       "1045        1045    7     10        ExtraTreesClassifier     NaN  0.828571\n",
       "1046        1046    7     11        ExtraTreesClassifier     NaN  0.771429\n",
       "1047        1047    7     12        ExtraTreesClassifier     NaN  0.742857\n",
       "1048        1048    7     13        ExtraTreesClassifier     NaN  0.757143\n",
       "1049        1049    7     14        ExtraTreesClassifier     NaN  0.800000\n",
       "1050        1050    8      0        ExtraTreesClassifier     NaN  0.724638\n",
       "1051        1051    8      1        ExtraTreesClassifier     NaN  0.623188\n",
       "1052        1052    8      2        ExtraTreesClassifier     NaN  0.695652\n",
       "1053        1053    8      3        ExtraTreesClassifier     NaN  0.623188\n",
       "1054        1054    8      4        ExtraTreesClassifier     NaN  0.710145\n",
       "1055        1055    8      5        ExtraTreesClassifier     NaN  0.724638\n",
       "1056        1056    8      6        ExtraTreesClassifier     NaN  0.739130\n",
       "1057        1057    8      7        ExtraTreesClassifier     NaN  0.753623\n",
       "1058        1058    8      8        ExtraTreesClassifier     NaN  0.768116\n",
       "1059        1059    8      9        ExtraTreesClassifier     NaN  0.594203\n",
       "1060        1060    8     10        ExtraTreesClassifier     NaN  0.710145\n",
       "1061        1061    8     11        ExtraTreesClassifier     NaN  0.753623\n",
       "1062        1062    8     12        ExtraTreesClassifier     NaN  0.782609\n",
       "1063        1063    8     13        ExtraTreesClassifier     NaN  0.652174\n",
       "1064        1064    8     14        ExtraTreesClassifier     NaN  0.768116\n",
       "1065        1065    9      0        ExtraTreesClassifier     NaN  0.608696\n",
       "1066        1066    9      1        ExtraTreesClassifier     NaN  0.550725\n",
       "1067        1067    9      2        ExtraTreesClassifier     NaN  0.652174\n",
       "1068        1068    9      3        ExtraTreesClassifier     NaN  0.666667\n",
       "1069        1069    9      4        ExtraTreesClassifier     NaN  0.695652\n",
       "1070        1070    9      5        ExtraTreesClassifier     NaN  0.666667\n",
       "1071        1071    9      6        ExtraTreesClassifier     NaN  0.695652\n",
       "1072        1072    9      7        ExtraTreesClassifier     NaN  0.594203\n",
       "1073        1073    9      8        ExtraTreesClassifier     NaN  0.579710\n",
       "1074        1074    9      9        ExtraTreesClassifier     NaN  0.652174\n",
       "1075        1075    9     10        ExtraTreesClassifier     NaN  0.637681\n",
       "1076        1076    9     11        ExtraTreesClassifier     NaN  0.608696\n",
       "1077        1077    9     12        ExtraTreesClassifier     NaN  0.695652\n",
       "1078        1078    9     13        ExtraTreesClassifier     NaN  0.652174\n",
       "1079        1079    9     14        ExtraTreesClassifier     NaN  0.710145\n",
       "1080        1080   10      0        ExtraTreesClassifier     NaN  0.625000\n",
       "1081        1081   10      1        ExtraTreesClassifier     NaN  0.638889\n",
       "1082        1082   10      2        ExtraTreesClassifier     NaN  0.583333\n",
       "1083        1083   10      3        ExtraTreesClassifier     NaN  0.625000\n",
       "1084        1084   10      4        ExtraTreesClassifier     NaN  0.680556\n",
       "1085        1085   10      5        ExtraTreesClassifier     NaN  0.680556\n",
       "1086        1086   10      6        ExtraTreesClassifier     NaN  0.638889\n",
       "1087        1087   10      7        ExtraTreesClassifier     NaN  0.597222\n",
       "1088        1088   10      8        ExtraTreesClassifier     NaN  0.625000\n",
       "1089        1089   10      9        ExtraTreesClassifier     NaN  0.694444\n",
       "1090        1090   10     10        ExtraTreesClassifier     NaN  0.638889\n",
       "1091        1091   10     11        ExtraTreesClassifier     NaN  0.708333\n",
       "1092        1092   10     12        ExtraTreesClassifier     NaN  0.694444\n",
       "1093        1093   10     13        ExtraTreesClassifier     NaN  0.666667\n",
       "1094        1094   10     14        ExtraTreesClassifier     NaN  0.805556\n",
       "1095        1095   11      0        ExtraTreesClassifier     NaN  0.680000\n",
       "1096        1096   11      1        ExtraTreesClassifier     NaN  0.706667\n",
       "1097        1097   11      2        ExtraTreesClassifier     NaN  0.693333\n",
       "1098        1098   11      3        ExtraTreesClassifier     NaN  0.586667\n",
       "1099        1099   11      4        ExtraTreesClassifier     NaN  0.786667\n",
       "1100        1100   11      5        ExtraTreesClassifier     NaN  0.826667\n",
       "1101        1101   11      6        ExtraTreesClassifier     NaN  0.733333\n",
       "1102        1102   11      7        ExtraTreesClassifier     NaN  0.733333\n",
       "1103        1103   11      8        ExtraTreesClassifier     NaN  0.666667\n",
       "1104        1104   11      9        ExtraTreesClassifier     NaN  0.746667\n",
       "1105        1105   11     10        ExtraTreesClassifier     NaN  0.853333\n",
       "1106        1106   11     11        ExtraTreesClassifier     NaN  0.813333\n",
       "1107        1107   11     12        ExtraTreesClassifier     NaN  0.773333\n",
       "1108        1108   11     13        ExtraTreesClassifier     NaN  0.720000\n",
       "1109        1109   11     14        ExtraTreesClassifier     NaN  0.786667\n",
       "1110        1110   12      0        ExtraTreesClassifier     NaN  0.602564\n",
       "1111        1111   12      1        ExtraTreesClassifier     NaN  0.551282\n",
       "1112        1112   12      2        ExtraTreesClassifier     NaN  0.628205\n",
       "1113        1113   12      3        ExtraTreesClassifier     NaN  0.589744\n",
       "1114        1114   12      4        ExtraTreesClassifier     NaN  0.692308\n",
       "1115        1115   12      5        ExtraTreesClassifier     NaN  0.730769\n",
       "1116        1116   12      6        ExtraTreesClassifier     NaN  0.756410\n",
       "1117        1117   12      7        ExtraTreesClassifier     NaN  0.653846\n",
       "1118        1118   12      8        ExtraTreesClassifier     NaN  0.435897\n",
       "1119        1119   12      9        ExtraTreesClassifier     NaN  0.653846\n",
       "1120        1120   12     10        ExtraTreesClassifier     NaN  0.717949\n",
       "1121        1121   12     11        ExtraTreesClassifier     NaN  0.730769\n",
       "1122        1122   12     12        ExtraTreesClassifier     NaN  0.551282\n",
       "1123        1123   12     13        ExtraTreesClassifier     NaN  0.794872\n",
       "1124        1124   12     14        ExtraTreesClassifier     NaN  0.743590\n",
       "1125        1125   13      0        ExtraTreesClassifier     NaN  0.575000\n",
       "1126        1126   13      1        ExtraTreesClassifier     NaN  0.762500\n",
       "1127        1127   13      2        ExtraTreesClassifier     NaN  0.612500\n",
       "1128        1128   13      3        ExtraTreesClassifier     NaN  0.675000\n",
       "1129        1129   13      4        ExtraTreesClassifier     NaN  0.700000\n",
       "1130        1130   13      5        ExtraTreesClassifier     NaN  0.725000\n",
       "1131        1131   13      6        ExtraTreesClassifier     NaN  0.700000\n",
       "1132        1132   13      7        ExtraTreesClassifier     NaN  0.562500\n",
       "1133        1133   13      8        ExtraTreesClassifier     NaN  0.625000\n",
       "1134        1134   13      9        ExtraTreesClassifier     NaN  0.750000\n",
       "1135        1135   13     10        ExtraTreesClassifier     NaN  0.750000\n",
       "1136        1136   13     11        ExtraTreesClassifier     NaN  0.625000\n",
       "1137        1137   13     12        ExtraTreesClassifier     NaN  0.700000\n",
       "1138        1138   13     13        ExtraTreesClassifier     NaN  0.750000\n",
       "1139        1139   13     14        ExtraTreesClassifier     NaN  0.725000\n",
       "1140        1140   14      0        ExtraTreesClassifier     NaN  0.612500\n",
       "1141        1141   14      1        ExtraTreesClassifier     NaN  0.762500\n",
       "1142        1142   14      2        ExtraTreesClassifier     NaN  0.600000\n",
       "1143        1143   14      3        ExtraTreesClassifier     NaN  0.637500\n",
       "1144        1144   14      4        ExtraTreesClassifier     NaN  0.725000\n",
       "1145        1145   14      5        ExtraTreesClassifier     NaN  0.825000\n",
       "1146        1146   14      6        ExtraTreesClassifier     NaN  0.650000\n",
       "1147        1147   14      7        ExtraTreesClassifier     NaN  0.700000\n",
       "1148        1148   14      8        ExtraTreesClassifier     NaN  0.625000\n",
       "1149        1149   14      9        ExtraTreesClassifier     NaN  0.775000\n",
       "1150        1150   14     10        ExtraTreesClassifier     NaN  0.750000\n",
       "1151        1151   14     11        ExtraTreesClassifier     NaN  0.712500\n",
       "1152        1152   14     12        ExtraTreesClassifier     NaN  0.737500\n",
       "1153        1153   14     13        ExtraTreesClassifier     NaN  0.775000\n",
       "1154        1154   14     14        ExtraTreesClassifier     NaN  0.825000\n",
       "1155        1155   15      0        ExtraTreesClassifier     NaN  0.662500\n",
       "1156        1156   15      1        ExtraTreesClassifier     NaN  0.662500\n",
       "1157        1157   15      2        ExtraTreesClassifier     NaN  0.625000\n",
       "1158        1158   15      3        ExtraTreesClassifier     NaN  0.687500\n",
       "1159        1159   15      4        ExtraTreesClassifier     NaN  0.775000\n",
       "1160        1160   15      5        ExtraTreesClassifier     NaN  0.675000\n",
       "1161        1161   15      6        ExtraTreesClassifier     NaN  0.612500\n",
       "1162        1162   15      7        ExtraTreesClassifier     NaN  0.700000\n",
       "1163        1163   15      8        ExtraTreesClassifier     NaN  0.737500\n",
       "1164        1164   15      9        ExtraTreesClassifier     NaN  0.737500\n",
       "1165        1165   15     10        ExtraTreesClassifier     NaN  0.750000\n",
       "1166        1166   15     11        ExtraTreesClassifier     NaN  0.662500\n",
       "1167        1167   15     12        ExtraTreesClassifier     NaN  0.800000\n",
       "1168        1168   15     13        ExtraTreesClassifier     NaN  0.787500\n",
       "1169        1169   15     14        ExtraTreesClassifier     NaN  0.812500\n",
       "1170        1170   16      0        ExtraTreesClassifier     NaN  0.537500\n",
       "1171        1171   16      1        ExtraTreesClassifier     NaN  0.612500\n",
       "1172        1172   16      2        ExtraTreesClassifier     NaN  0.612500\n",
       "1173        1173   16      3        ExtraTreesClassifier     NaN  0.612500\n",
       "1174        1174   16      4        ExtraTreesClassifier     NaN  0.650000\n",
       "1175        1175   16      5        ExtraTreesClassifier     NaN  0.637500\n",
       "1176        1176   16      6        ExtraTreesClassifier     NaN  0.712500\n",
       "1177        1177   16      7        ExtraTreesClassifier     NaN  0.537500\n",
       "1178        1178   16      8        ExtraTreesClassifier     NaN  0.562500\n",
       "1179        1179   16      9        ExtraTreesClassifier     NaN  0.725000\n",
       "1180        1180   16     10        ExtraTreesClassifier     NaN  0.675000\n",
       "1181        1181   16     11        ExtraTreesClassifier     NaN  0.612500\n",
       "1182        1182   16     12        ExtraTreesClassifier     NaN  0.712500\n",
       "1183        1183   16     13        ExtraTreesClassifier     NaN  0.750000\n",
       "1184        1184   16     14        ExtraTreesClassifier     NaN  0.737500\n",
       "1185        1185   17      0        ExtraTreesClassifier     NaN  0.675000\n",
       "1186        1186   17      1        ExtraTreesClassifier     NaN  0.675000\n",
       "1187        1187   17      2        ExtraTreesClassifier     NaN  0.687500\n",
       "1188        1188   17      3        ExtraTreesClassifier     NaN  0.625000\n",
       "1189        1189   17      4        ExtraTreesClassifier     NaN  0.650000\n",
       "1190        1190   17      5        ExtraTreesClassifier     NaN  0.712500\n",
       "1191        1191   17      6        ExtraTreesClassifier     NaN  0.725000\n",
       "1192        1192   17      7        ExtraTreesClassifier     NaN  0.750000\n",
       "1193        1193   17      8        ExtraTreesClassifier     NaN  0.725000\n",
       "1194        1194   17      9        ExtraTreesClassifier     NaN  0.725000\n",
       "1195        1195   17     10        ExtraTreesClassifier     NaN  0.750000\n",
       "1196        1196   17     11        ExtraTreesClassifier     NaN  0.800000\n",
       "1197        1197   17     12        ExtraTreesClassifier     NaN  0.712500\n",
       "1198        1198   17     13        ExtraTreesClassifier     NaN  0.800000\n",
       "1199        1199   17     14        ExtraTreesClassifier     NaN  0.812500\n",
       "1200        1200   WC      0        ExtraTreesClassifier     NaN  0.550000\n",
       "1201        1201   WC      1        ExtraTreesClassifier     NaN  0.600000\n",
       "1202        1202   WC      2        ExtraTreesClassifier     NaN  0.650000\n",
       "1203        1203   WC      3        ExtraTreesClassifier     NaN  0.500000\n",
       "1204        1204   WC      4        ExtraTreesClassifier     NaN  0.550000\n",
       "1205        1205   WC      5        ExtraTreesClassifier     NaN  0.700000\n",
       "1206        1206   WC      6        ExtraTreesClassifier     NaN  0.700000\n",
       "1207        1207   WC      7        ExtraTreesClassifier     NaN  0.500000\n",
       "1208        1208   WC      8        ExtraTreesClassifier     NaN  0.450000\n",
       "1209        1209   WC      9        ExtraTreesClassifier     NaN  0.600000\n",
       "1210        1210   WC     10        ExtraTreesClassifier     NaN  0.600000\n",
       "1211        1211   WC     11        ExtraTreesClassifier     NaN  0.750000\n",
       "1212        1212   WC     12        ExtraTreesClassifier     NaN  0.550000\n",
       "1213        1213   WC     13        ExtraTreesClassifier     NaN  0.700000\n",
       "1214        1214   WC     14        ExtraTreesClassifier     NaN  0.800000\n",
       "1215        1215   DV      0        ExtraTreesClassifier     NaN  0.700000\n",
       "1216        1216   DV      1        ExtraTreesClassifier     NaN  0.500000\n",
       "1217        1217   DV      2        ExtraTreesClassifier     NaN  0.450000\n",
       "1218        1218   DV      3        ExtraTreesClassifier     NaN  0.550000\n",
       "1219        1219   DV      4        ExtraTreesClassifier     NaN  0.650000\n",
       "1220        1220   DV      5        ExtraTreesClassifier     NaN  0.500000\n",
       "1221        1221   DV      6        ExtraTreesClassifier     NaN  0.400000\n",
       "1222        1222   DV      7        ExtraTreesClassifier     NaN  0.650000\n",
       "1223        1223   DV      8        ExtraTreesClassifier     NaN  0.550000\n",
       "1224        1224   DV      9        ExtraTreesClassifier     NaN  0.400000\n",
       "1225        1225   DV     10        ExtraTreesClassifier     NaN  0.550000\n",
       "1226        1226   DV     11        ExtraTreesClassifier     NaN  0.650000\n",
       "1227        1227   DV     12        ExtraTreesClassifier     NaN  0.450000\n",
       "1228        1228   DV     13        ExtraTreesClassifier     NaN  0.450000\n",
       "1229        1229   DV     14        ExtraTreesClassifier     NaN  0.500000\n",
       "1230        1230   CC      0        ExtraTreesClassifier     NaN  0.400000\n",
       "1231        1231   CC      1        ExtraTreesClassifier     NaN  0.500000\n",
       "1232        1232   CC      2        ExtraTreesClassifier     NaN  0.500000\n",
       "1233        1233   CC      3        ExtraTreesClassifier     NaN  0.500000\n",
       "1234        1234   CC      4        ExtraTreesClassifier     NaN  0.500000\n",
       "1235        1235   CC      5        ExtraTreesClassifier     NaN  0.600000\n",
       "1236        1236   CC      6        ExtraTreesClassifier     NaN  0.500000\n",
       "1237        1237   CC      7        ExtraTreesClassifier     NaN  0.500000\n",
       "1238        1238   CC      8        ExtraTreesClassifier     NaN  0.500000\n",
       "1239        1239   CC      9        ExtraTreesClassifier     NaN  0.500000\n",
       "1240        1240   CC     10        ExtraTreesClassifier     NaN  0.500000\n",
       "1241        1241   CC     11        ExtraTreesClassifier     NaN  0.400000\n",
       "1242        1242   CC     12        ExtraTreesClassifier     NaN  0.500000\n",
       "1243        1243   CC     13        ExtraTreesClassifier     NaN  0.500000\n",
       "1244        1244   CC     14        ExtraTreesClassifier     NaN  0.500000\n",
       "1245        1245   SB      0        ExtraTreesClassifier     NaN  0.800000\n",
       "1246        1246   SB      1        ExtraTreesClassifier     NaN  0.600000\n",
       "1247        1247   SB      2        ExtraTreesClassifier     NaN  0.600000\n",
       "1248        1248   SB      3        ExtraTreesClassifier     NaN  0.600000\n",
       "1249        1249   SB      4        ExtraTreesClassifier     NaN  0.600000\n",
       "1250        1250   SB      5        ExtraTreesClassifier     NaN  0.600000\n",
       "1251        1251   SB      6        ExtraTreesClassifier     NaN  0.600000\n",
       "1252        1252   SB      7        ExtraTreesClassifier     NaN  0.600000\n",
       "1253        1253   SB      8        ExtraTreesClassifier     NaN  0.400000\n",
       "1254        1254   SB      9        ExtraTreesClassifier     NaN  0.400000\n",
       "1255        1255   SB     10        ExtraTreesClassifier     NaN  0.400000\n",
       "1256        1256   SB     11        ExtraTreesClassifier     NaN  0.600000\n",
       "1257        1257   SB     12        ExtraTreesClassifier     NaN  0.400000\n",
       "1258        1258   SB     13        ExtraTreesClassifier     NaN  0.400000\n",
       "1259        1259   SB     14        ExtraTreesClassifier     NaN  0.400000\n",
       "1260        1260    1      0      DecisionTreeClassifier     NaN  0.612500\n",
       "1261        1261    1      1      DecisionTreeClassifier     NaN  0.675000\n",
       "1262        1262    1      2      DecisionTreeClassifier     NaN  0.762500\n",
       "1263        1263    1      3      DecisionTreeClassifier     NaN  0.637500\n",
       "1264        1264    1      4      DecisionTreeClassifier     NaN  0.637500\n",
       "1265        1265    1      5      DecisionTreeClassifier     NaN  0.787500\n",
       "1266        1266    1      6      DecisionTreeClassifier     NaN  0.750000\n",
       "1267        1267    1      7      DecisionTreeClassifier     NaN  0.750000\n",
       "1268        1268    1      8      DecisionTreeClassifier     NaN  0.612500\n",
       "1269        1269    1      9      DecisionTreeClassifier     NaN  0.687500\n",
       "1270        1270    1     10      DecisionTreeClassifier     NaN  0.737500\n",
       "1271        1271    1     11      DecisionTreeClassifier     NaN  0.737500\n",
       "1272        1272    1     12      DecisionTreeClassifier     NaN  0.762500\n",
       "1273        1273    1     13      DecisionTreeClassifier     NaN  0.812500\n",
       "1274        1274    1     14      DecisionTreeClassifier     NaN  0.825000\n",
       "1275        1275    2      0      DecisionTreeClassifier     NaN  0.645570\n",
       "1276        1276    2      1      DecisionTreeClassifier     NaN  0.569620\n",
       "1277        1277    2      2      DecisionTreeClassifier     NaN  0.696203\n",
       "1278        1278    2      3      DecisionTreeClassifier     NaN  0.620253\n",
       "1279        1279    2      4      DecisionTreeClassifier     NaN  0.620253\n",
       "1280        1280    2      5      DecisionTreeClassifier     NaN  0.632911\n",
       "1281        1281    2      6      DecisionTreeClassifier     NaN  0.670886\n",
       "1282        1282    2      7      DecisionTreeClassifier     NaN  0.607595\n",
       "1283        1283    2      8      DecisionTreeClassifier     NaN  0.607595\n",
       "1284        1284    2      9      DecisionTreeClassifier     NaN  0.683544\n",
       "1285        1285    2     10      DecisionTreeClassifier     NaN  0.683544\n",
       "1286        1286    2     11      DecisionTreeClassifier     NaN  0.746835\n",
       "1287        1287    2     12      DecisionTreeClassifier     NaN  0.683544\n",
       "1288        1288    2     13      DecisionTreeClassifier     NaN  0.683544\n",
       "1289        1289    2     14      DecisionTreeClassifier     NaN  0.746835\n",
       "1290        1290    3      0      DecisionTreeClassifier     NaN  0.571429\n",
       "1291        1291    3      1      DecisionTreeClassifier     NaN  0.636364\n",
       "1292        1292    3      2      DecisionTreeClassifier     NaN  0.623377\n",
       "1293        1293    3      3      DecisionTreeClassifier     NaN  0.610390\n",
       "1294        1294    3      4      DecisionTreeClassifier     NaN  0.636364\n",
       "1295        1295    3      5      DecisionTreeClassifier     NaN  0.688312\n",
       "1296        1296    3      6      DecisionTreeClassifier     NaN  0.688312\n",
       "1297        1297    3      7      DecisionTreeClassifier     NaN  0.701299\n",
       "1298        1298    3      8      DecisionTreeClassifier     NaN  0.623377\n",
       "1299        1299    3      9      DecisionTreeClassifier     NaN  0.649351\n",
       "1300        1300    3     10      DecisionTreeClassifier     NaN  0.636364\n",
       "1301        1301    3     11      DecisionTreeClassifier     NaN  0.649351\n",
       "1302        1302    3     12      DecisionTreeClassifier     NaN  0.662338\n",
       "1303        1303    3     13      DecisionTreeClassifier     NaN  0.701299\n",
       "1304        1304    3     14      DecisionTreeClassifier     NaN  0.714286\n",
       "1305        1305    4      0      DecisionTreeClassifier     NaN  0.657534\n",
       "1306        1306    4      1      DecisionTreeClassifier     NaN  0.671233\n",
       "1307        1307    4      2      DecisionTreeClassifier     NaN  0.616438\n",
       "1308        1308    4      3      DecisionTreeClassifier     NaN  0.452055\n",
       "1309        1309    4      4      DecisionTreeClassifier     NaN  0.726027\n",
       "1310        1310    4      5      DecisionTreeClassifier     NaN  0.684932\n",
       "1311        1311    4      6      DecisionTreeClassifier     NaN  0.630137\n",
       "1312        1312    4      7      DecisionTreeClassifier     NaN  0.671233\n",
       "1313        1313    4      8      DecisionTreeClassifier     NaN  0.657534\n",
       "1314        1314    4      9      DecisionTreeClassifier     NaN  0.589041\n",
       "1315        1315    4     10      DecisionTreeClassifier     NaN  0.726027\n",
       "1316        1316    4     11      DecisionTreeClassifier     NaN  0.712329\n",
       "1317        1317    4     12      DecisionTreeClassifier     NaN  0.698630\n",
       "1318        1318    4     13      DecisionTreeClassifier     NaN  0.712329\n",
       "1319        1319    4     14      DecisionTreeClassifier     NaN  0.794521\n",
       "1320        1320    5      0      DecisionTreeClassifier     NaN  0.563380\n",
       "1321        1321    5      1      DecisionTreeClassifier     NaN  0.704225\n",
       "1322        1322    5      2      DecisionTreeClassifier     NaN  0.718310\n",
       "1323        1323    5      3      DecisionTreeClassifier     NaN  0.605634\n",
       "1324        1324    5      4      DecisionTreeClassifier     NaN  0.633803\n",
       "1325        1325    5      5      DecisionTreeClassifier     NaN  0.704225\n",
       "1326        1326    5      6      DecisionTreeClassifier     NaN  0.718310\n",
       "1327        1327    5      7      DecisionTreeClassifier     NaN  0.647887\n",
       "1328        1328    5      8      DecisionTreeClassifier     NaN  0.661972\n",
       "1329        1329    5      9      DecisionTreeClassifier     NaN  0.676056\n",
       "1330        1330    5     10      DecisionTreeClassifier     NaN  0.746479\n",
       "1331        1331    5     11      DecisionTreeClassifier     NaN  0.661972\n",
       "1332        1332    5     12      DecisionTreeClassifier     NaN  0.690141\n",
       "1333        1333    5     13      DecisionTreeClassifier     NaN  0.676056\n",
       "1334        1334    5     14      DecisionTreeClassifier     NaN  0.704225\n",
       "1335        1335    6      0      DecisionTreeClassifier     NaN  0.471429\n",
       "1336        1336    6      1      DecisionTreeClassifier     NaN  0.614286\n",
       "1337        1337    6      2      DecisionTreeClassifier     NaN  0.542857\n",
       "1338        1338    6      3      DecisionTreeClassifier     NaN  0.571429\n",
       "1339        1339    6      4      DecisionTreeClassifier     NaN  0.671429\n",
       "1340        1340    6      5      DecisionTreeClassifier     NaN  0.571429\n",
       "1341        1341    6      6      DecisionTreeClassifier     NaN  0.628571\n",
       "1342        1342    6      7      DecisionTreeClassifier     NaN  0.642857\n",
       "1343        1343    6      8      DecisionTreeClassifier     NaN  0.557143\n",
       "1344        1344    6      9      DecisionTreeClassifier     NaN  0.542857\n",
       "1345        1345    6     10      DecisionTreeClassifier     NaN  0.614286\n",
       "1346        1346    6     11      DecisionTreeClassifier     NaN  0.685714\n",
       "1347        1347    6     12      DecisionTreeClassifier     NaN  0.657143\n",
       "1348        1348    6     13      DecisionTreeClassifier     NaN  0.700000\n",
       "1349        1349    6     14      DecisionTreeClassifier     NaN  0.700000\n",
       "1350        1350    7      0      DecisionTreeClassifier     NaN  0.785714\n",
       "1351        1351    7      1      DecisionTreeClassifier     NaN  0.671429\n",
       "1352        1352    7      2      DecisionTreeClassifier     NaN  0.757143\n",
       "1353        1353    7      3      DecisionTreeClassifier     NaN  0.585714\n",
       "1354        1354    7      4      DecisionTreeClassifier     NaN  0.785714\n",
       "1355        1355    7      5      DecisionTreeClassifier     NaN  0.757143\n",
       "1356        1356    7      6      DecisionTreeClassifier     NaN  0.742857\n",
       "1357        1357    7      7      DecisionTreeClassifier     NaN  0.757143\n",
       "1358        1358    7      8      DecisionTreeClassifier     NaN  0.700000\n",
       "1359        1359    7      9      DecisionTreeClassifier     NaN  0.671429\n",
       "1360        1360    7     10      DecisionTreeClassifier     NaN  0.771429\n",
       "1361        1361    7     11      DecisionTreeClassifier     NaN  0.742857\n",
       "1362        1362    7     12      DecisionTreeClassifier     NaN  0.757143\n",
       "1363        1363    7     13      DecisionTreeClassifier     NaN  0.742857\n",
       "1364        1364    7     14      DecisionTreeClassifier     NaN  0.685714\n",
       "1365        1365    8      0      DecisionTreeClassifier     NaN  0.724638\n",
       "1366        1366    8      1      DecisionTreeClassifier     NaN  0.623188\n",
       "1367        1367    8      2      DecisionTreeClassifier     NaN  0.724638\n",
       "1368        1368    8      3      DecisionTreeClassifier     NaN  0.623188\n",
       "1369        1369    8      4      DecisionTreeClassifier     NaN  0.710145\n",
       "1370        1370    8      5      DecisionTreeClassifier     NaN  0.724638\n",
       "1371        1371    8      6      DecisionTreeClassifier     NaN  0.753623\n",
       "1372        1372    8      7      DecisionTreeClassifier     NaN  0.753623\n",
       "1373        1373    8      8      DecisionTreeClassifier     NaN  0.753623\n",
       "1374        1374    8      9      DecisionTreeClassifier     NaN  0.594203\n",
       "1375        1375    8     10      DecisionTreeClassifier     NaN  0.681159\n",
       "1376        1376    8     11      DecisionTreeClassifier     NaN  0.782609\n",
       "1377        1377    8     12      DecisionTreeClassifier     NaN  0.768116\n",
       "1378        1378    8     13      DecisionTreeClassifier     NaN  0.637681\n",
       "1379        1379    8     14      DecisionTreeClassifier     NaN  0.710145\n",
       "1380        1380    9      0      DecisionTreeClassifier     NaN  0.608696\n",
       "1381        1381    9      1      DecisionTreeClassifier     NaN  0.550725\n",
       "1382        1382    9      2      DecisionTreeClassifier     NaN  0.652174\n",
       "1383        1383    9      3      DecisionTreeClassifier     NaN  0.666667\n",
       "1384        1384    9      4      DecisionTreeClassifier     NaN  0.681159\n",
       "1385        1385    9      5      DecisionTreeClassifier     NaN  0.666667\n",
       "1386        1386    9      6      DecisionTreeClassifier     NaN  0.695652\n",
       "1387        1387    9      7      DecisionTreeClassifier     NaN  0.594203\n",
       "1388        1388    9      8      DecisionTreeClassifier     NaN  0.579710\n",
       "1389        1389    9      9      DecisionTreeClassifier     NaN  0.652174\n",
       "1390        1390    9     10      DecisionTreeClassifier     NaN  0.637681\n",
       "1391        1391    9     11      DecisionTreeClassifier     NaN  0.579710\n",
       "1392        1392    9     12      DecisionTreeClassifier     NaN  0.710145\n",
       "1393        1393    9     13      DecisionTreeClassifier     NaN  0.637681\n",
       "1394        1394    9     14      DecisionTreeClassifier     NaN  0.710145\n",
       "1395        1395   10      0      DecisionTreeClassifier     NaN  0.625000\n",
       "1396        1396   10      1      DecisionTreeClassifier     NaN  0.638889\n",
       "1397        1397   10      2      DecisionTreeClassifier     NaN  0.583333\n",
       "1398        1398   10      3      DecisionTreeClassifier     NaN  0.625000\n",
       "1399        1399   10      4      DecisionTreeClassifier     NaN  0.666667\n",
       "1400        1400   10      5      DecisionTreeClassifier     NaN  0.666667\n",
       "1401        1401   10      6      DecisionTreeClassifier     NaN  0.638889\n",
       "1402        1402   10      7      DecisionTreeClassifier     NaN  0.597222\n",
       "1403        1403   10      8      DecisionTreeClassifier     NaN  0.625000\n",
       "1404        1404   10      9      DecisionTreeClassifier     NaN  0.680556\n",
       "1405        1405   10     10      DecisionTreeClassifier     NaN  0.597222\n",
       "1406        1406   10     11      DecisionTreeClassifier     NaN  0.694444\n",
       "1407        1407   10     12      DecisionTreeClassifier     NaN  0.638889\n",
       "1408        1408   10     13      DecisionTreeClassifier     NaN  0.652778\n",
       "1409        1409   10     14      DecisionTreeClassifier     NaN  0.750000\n",
       "1410        1410   11      0      DecisionTreeClassifier     NaN  0.693333\n",
       "1411        1411   11      1      DecisionTreeClassifier     NaN  0.706667\n",
       "1412        1412   11      2      DecisionTreeClassifier     NaN  0.693333\n",
       "1413        1413   11      3      DecisionTreeClassifier     NaN  0.586667\n",
       "1414        1414   11      4      DecisionTreeClassifier     NaN  0.786667\n",
       "1415        1415   11      5      DecisionTreeClassifier     NaN  0.826667\n",
       "1416        1416   11      6      DecisionTreeClassifier     NaN  0.733333\n",
       "1417        1417   11      7      DecisionTreeClassifier     NaN  0.733333\n",
       "1418        1418   11      8      DecisionTreeClassifier     NaN  0.613333\n",
       "1419        1419   11      9      DecisionTreeClassifier     NaN  0.746667\n",
       "1420        1420   11     10      DecisionTreeClassifier     NaN  0.786667\n",
       "1421        1421   11     11      DecisionTreeClassifier     NaN  0.746667\n",
       "1422        1422   11     12      DecisionTreeClassifier     NaN  0.746667\n",
       "1423        1423   11     13      DecisionTreeClassifier     NaN  0.720000\n",
       "1424        1424   11     14      DecisionTreeClassifier     NaN  0.760000\n",
       "1425        1425   12      0      DecisionTreeClassifier     NaN  0.602564\n",
       "1426        1426   12      1      DecisionTreeClassifier     NaN  0.551282\n",
       "1427        1427   12      2      DecisionTreeClassifier     NaN  0.628205\n",
       "1428        1428   12      3      DecisionTreeClassifier     NaN  0.589744\n",
       "1429        1429   12      4      DecisionTreeClassifier     NaN  0.692308\n",
       "1430        1430   12      5      DecisionTreeClassifier     NaN  0.730769\n",
       "1431        1431   12      6      DecisionTreeClassifier     NaN  0.743590\n",
       "1432        1432   12      7      DecisionTreeClassifier     NaN  0.641026\n",
       "1433        1433   12      8      DecisionTreeClassifier     NaN  0.423077\n",
       "1434        1434   12      9      DecisionTreeClassifier     NaN  0.653846\n",
       "1435        1435   12     10      DecisionTreeClassifier     NaN  0.692308\n",
       "1436        1436   12     11      DecisionTreeClassifier     NaN  0.730769\n",
       "1437        1437   12     12      DecisionTreeClassifier     NaN  0.525641\n",
       "1438        1438   12     13      DecisionTreeClassifier     NaN  0.756410\n",
       "1439        1439   12     14      DecisionTreeClassifier     NaN  0.730769\n",
       "1440        1440   13      0      DecisionTreeClassifier     NaN  0.575000\n",
       "1441        1441   13      1      DecisionTreeClassifier     NaN  0.762500\n",
       "1442        1442   13      2      DecisionTreeClassifier     NaN  0.612500\n",
       "1443        1443   13      3      DecisionTreeClassifier     NaN  0.675000\n",
       "1444        1444   13      4      DecisionTreeClassifier     NaN  0.700000\n",
       "1445        1445   13      5      DecisionTreeClassifier     NaN  0.712500\n",
       "1446        1446   13      6      DecisionTreeClassifier     NaN  0.700000\n",
       "1447        1447   13      7      DecisionTreeClassifier     NaN  0.550000\n",
       "1448        1448   13      8      DecisionTreeClassifier     NaN  0.637500\n",
       "1449        1449   13      9      DecisionTreeClassifier     NaN  0.750000\n",
       "1450        1450   13     10      DecisionTreeClassifier     NaN  0.725000\n",
       "1451        1451   13     11      DecisionTreeClassifier     NaN  0.625000\n",
       "1452        1452   13     12      DecisionTreeClassifier     NaN  0.675000\n",
       "1453        1453   13     13      DecisionTreeClassifier     NaN  0.725000\n",
       "1454        1454   13     14      DecisionTreeClassifier     NaN  0.725000\n",
       "1455        1455   14      0      DecisionTreeClassifier     NaN  0.612500\n",
       "1456        1456   14      1      DecisionTreeClassifier     NaN  0.762500\n",
       "1457        1457   14      2      DecisionTreeClassifier     NaN  0.600000\n",
       "1458        1458   14      3      DecisionTreeClassifier     NaN  0.637500\n",
       "1459        1459   14      4      DecisionTreeClassifier     NaN  0.725000\n",
       "1460        1460   14      5      DecisionTreeClassifier     NaN  0.812500\n",
       "1461        1461   14      6      DecisionTreeClassifier     NaN  0.637500\n",
       "1462        1462   14      7      DecisionTreeClassifier     NaN  0.700000\n",
       "1463        1463   14      8      DecisionTreeClassifier     NaN  0.612500\n",
       "1464        1464   14      9      DecisionTreeClassifier     NaN  0.775000\n",
       "1465        1465   14     10      DecisionTreeClassifier     NaN  0.750000\n",
       "1466        1466   14     11      DecisionTreeClassifier     NaN  0.712500\n",
       "1467        1467   14     12      DecisionTreeClassifier     NaN  0.700000\n",
       "1468        1468   14     13      DecisionTreeClassifier     NaN  0.750000\n",
       "1469        1469   14     14      DecisionTreeClassifier     NaN  0.737500\n",
       "1470        1470   15      0      DecisionTreeClassifier     NaN  0.662500\n",
       "1471        1471   15      1      DecisionTreeClassifier     NaN  0.662500\n",
       "1472        1472   15      2      DecisionTreeClassifier     NaN  0.625000\n",
       "1473        1473   15      3      DecisionTreeClassifier     NaN  0.687500\n",
       "1474        1474   15      4      DecisionTreeClassifier     NaN  0.775000\n",
       "1475        1475   15      5      DecisionTreeClassifier     NaN  0.687500\n",
       "1476        1476   15      6      DecisionTreeClassifier     NaN  0.612500\n",
       "1477        1477   15      7      DecisionTreeClassifier     NaN  0.700000\n",
       "1478        1478   15      8      DecisionTreeClassifier     NaN  0.725000\n",
       "1479        1479   15      9      DecisionTreeClassifier     NaN  0.737500\n",
       "1480        1480   15     10      DecisionTreeClassifier     NaN  0.750000\n",
       "1481        1481   15     11      DecisionTreeClassifier     NaN  0.662500\n",
       "1482        1482   15     12      DecisionTreeClassifier     NaN  0.775000\n",
       "1483        1483   15     13      DecisionTreeClassifier     NaN  0.762500\n",
       "1484        1484   15     14      DecisionTreeClassifier     NaN  0.775000\n",
       "1485        1485   16      0      DecisionTreeClassifier     NaN  0.537500\n",
       "1486        1486   16      1      DecisionTreeClassifier     NaN  0.612500\n",
       "1487        1487   16      2      DecisionTreeClassifier     NaN  0.612500\n",
       "1488        1488   16      3      DecisionTreeClassifier     NaN  0.612500\n",
       "1489        1489   16      4      DecisionTreeClassifier     NaN  0.650000\n",
       "1490        1490   16      5      DecisionTreeClassifier     NaN  0.662500\n",
       "1491        1491   16      6      DecisionTreeClassifier     NaN  0.712500\n",
       "1492        1492   16      7      DecisionTreeClassifier     NaN  0.537500\n",
       "1493        1493   16      8      DecisionTreeClassifier     NaN  0.562500\n",
       "1494        1494   16      9      DecisionTreeClassifier     NaN  0.725000\n",
       "1495        1495   16     10      DecisionTreeClassifier     NaN  0.662500\n",
       "1496        1496   16     11      DecisionTreeClassifier     NaN  0.612500\n",
       "1497        1497   16     12      DecisionTreeClassifier     NaN  0.700000\n",
       "1498        1498   16     13      DecisionTreeClassifier     NaN  0.750000\n",
       "1499        1499   16     14      DecisionTreeClassifier     NaN  0.737500\n",
       "1500        1500   17      0      DecisionTreeClassifier     NaN  0.675000\n",
       "1501        1501   17      1      DecisionTreeClassifier     NaN  0.675000\n",
       "1502        1502   17      2      DecisionTreeClassifier     NaN  0.687500\n",
       "1503        1503   17      3      DecisionTreeClassifier     NaN  0.625000\n",
       "1504        1504   17      4      DecisionTreeClassifier     NaN  0.650000\n",
       "1505        1505   17      5      DecisionTreeClassifier     NaN  0.712500\n",
       "1506        1506   17      6      DecisionTreeClassifier     NaN  0.725000\n",
       "1507        1507   17      7      DecisionTreeClassifier     NaN  0.737500\n",
       "1508        1508   17      8      DecisionTreeClassifier     NaN  0.725000\n",
       "1509        1509   17      9      DecisionTreeClassifier     NaN  0.737500\n",
       "1510        1510   17     10      DecisionTreeClassifier     NaN  0.737500\n",
       "1511        1511   17     11      DecisionTreeClassifier     NaN  0.787500\n",
       "1512        1512   17     12      DecisionTreeClassifier     NaN  0.712500\n",
       "1513        1513   17     13      DecisionTreeClassifier     NaN  0.787500\n",
       "1514        1514   17     14      DecisionTreeClassifier     NaN  0.700000\n",
       "1515        1515   WC      0      DecisionTreeClassifier     NaN  0.550000\n",
       "1516        1516   WC      1      DecisionTreeClassifier     NaN  0.600000\n",
       "1517        1517   WC      2      DecisionTreeClassifier     NaN  0.650000\n",
       "1518        1518   WC      3      DecisionTreeClassifier     NaN  0.500000\n",
       "1519        1519   WC      4      DecisionTreeClassifier     NaN  0.500000\n",
       "1520        1520   WC      5      DecisionTreeClassifier     NaN  0.650000\n",
       "1521        1521   WC      6      DecisionTreeClassifier     NaN  0.700000\n",
       "1522        1522   WC      7      DecisionTreeClassifier     NaN  0.600000\n",
       "1523        1523   WC      8      DecisionTreeClassifier     NaN  0.450000\n",
       "1524        1524   WC      9      DecisionTreeClassifier     NaN  0.600000\n",
       "1525        1525   WC     10      DecisionTreeClassifier     NaN  0.600000\n",
       "1526        1526   WC     11      DecisionTreeClassifier     NaN  0.700000\n",
       "1527        1527   WC     12      DecisionTreeClassifier     NaN  0.600000\n",
       "1528        1528   WC     13      DecisionTreeClassifier     NaN  0.650000\n",
       "1529        1529   WC     14      DecisionTreeClassifier     NaN  0.700000\n",
       "1530        1530   DV      0      DecisionTreeClassifier     NaN  0.700000\n",
       "1531        1531   DV      1      DecisionTreeClassifier     NaN  0.500000\n",
       "1532        1532   DV      2      DecisionTreeClassifier     NaN  0.450000\n",
       "1533        1533   DV      3      DecisionTreeClassifier     NaN  0.550000\n",
       "1534        1534   DV      4      DecisionTreeClassifier     NaN  0.550000\n",
       "1535        1535   DV      5      DecisionTreeClassifier     NaN  0.500000\n",
       "1536        1536   DV      6      DecisionTreeClassifier     NaN  0.400000\n",
       "1537        1537   DV      7      DecisionTreeClassifier     NaN  0.650000\n",
       "1538        1538   DV      8      DecisionTreeClassifier     NaN  0.600000\n",
       "1539        1539   DV      9      DecisionTreeClassifier     NaN  0.400000\n",
       "1540        1540   DV     10      DecisionTreeClassifier     NaN  0.550000\n",
       "1541        1541   DV     11      DecisionTreeClassifier     NaN  0.600000\n",
       "1542        1542   DV     12      DecisionTreeClassifier     NaN  0.400000\n",
       "1543        1543   DV     13      DecisionTreeClassifier     NaN  0.400000\n",
       "1544        1544   DV     14      DecisionTreeClassifier     NaN  0.650000\n",
       "1545        1545   CC      0      DecisionTreeClassifier     NaN  0.400000\n",
       "1546        1546   CC      1      DecisionTreeClassifier     NaN  0.500000\n",
       "1547        1547   CC      2      DecisionTreeClassifier     NaN  0.500000\n",
       "1548        1548   CC      3      DecisionTreeClassifier     NaN  0.500000\n",
       "1549        1549   CC      4      DecisionTreeClassifier     NaN  0.500000\n",
       "1550        1550   CC      5      DecisionTreeClassifier     NaN  0.600000\n",
       "1551        1551   CC      6      DecisionTreeClassifier     NaN  0.500000\n",
       "1552        1552   CC      7      DecisionTreeClassifier     NaN  0.500000\n",
       "1553        1553   CC      8      DecisionTreeClassifier     NaN  0.500000\n",
       "1554        1554   CC      9      DecisionTreeClassifier     NaN  0.400000\n",
       "1555        1555   CC     10      DecisionTreeClassifier     NaN  0.500000\n",
       "1556        1556   CC     11      DecisionTreeClassifier     NaN  0.500000\n",
       "1557        1557   CC     12      DecisionTreeClassifier     NaN  0.500000\n",
       "1558        1558   CC     13      DecisionTreeClassifier     NaN  0.500000\n",
       "1559        1559   CC     14      DecisionTreeClassifier     NaN  0.400000\n",
       "1560        1560   SB      0      DecisionTreeClassifier     NaN  0.800000\n",
       "1561        1561   SB      1      DecisionTreeClassifier     NaN  0.200000\n",
       "1562        1562   SB      2      DecisionTreeClassifier     NaN  0.600000\n",
       "1563        1563   SB      3      DecisionTreeClassifier     NaN  0.600000\n",
       "1564        1564   SB      4      DecisionTreeClassifier     NaN  0.400000\n",
       "1565        1565   SB      5      DecisionTreeClassifier     NaN  0.200000\n",
       "1566        1566   SB      6      DecisionTreeClassifier     NaN  0.800000\n",
       "1567        1567   SB      7      DecisionTreeClassifier     NaN  0.600000\n",
       "1568        1568   SB      8      DecisionTreeClassifier     NaN  1.000000\n",
       "1569        1569   SB      9      DecisionTreeClassifier     NaN  0.600000\n",
       "1570        1570   SB     10      DecisionTreeClassifier     NaN  0.400000\n",
       "1571        1571   SB     11      DecisionTreeClassifier     NaN  0.800000\n",
       "1572        1572   SB     12      DecisionTreeClassifier     NaN  0.600000\n",
       "1573        1573   SB     13      DecisionTreeClassifier     NaN  0.600000\n",
       "1574        1574   SB     14      DecisionTreeClassifier     NaN  0.600000\n",
       "1575        1575    1      0        KNeighborsClassifier     NaN  0.650000\n",
       "1576        1576    1      1        KNeighborsClassifier     NaN  0.675000\n",
       "1577        1577    1      2        KNeighborsClassifier     NaN  0.587500\n",
       "1578        1578    1      3        KNeighborsClassifier     NaN  0.600000\n",
       "1579        1579    1      4        KNeighborsClassifier     NaN  0.700000\n",
       "1580        1580    1      5        KNeighborsClassifier     NaN  0.750000\n",
       "1581        1581    1      6        KNeighborsClassifier     NaN  0.725000\n",
       "1582        1582    1      7        KNeighborsClassifier     NaN  0.725000\n",
       "1583        1583    1      8        KNeighborsClassifier     NaN  0.675000\n",
       "1584        1584    1      9        KNeighborsClassifier     NaN  0.537500\n",
       "1585        1585    1     10        KNeighborsClassifier     NaN  0.750000\n",
       "1586        1586    1     11        KNeighborsClassifier     NaN  0.787500\n",
       "1587        1587    1     12        KNeighborsClassifier     NaN  0.737500\n",
       "1588        1588    1     13        KNeighborsClassifier     NaN  0.787500\n",
       "1589        1589    1     14        KNeighborsClassifier     NaN  0.725000\n",
       "1590        1590    2      0        KNeighborsClassifier     NaN  0.658228\n",
       "1591        1591    2      1        KNeighborsClassifier     NaN  0.620253\n",
       "1592        1592    2      2        KNeighborsClassifier     NaN  0.594937\n",
       "1593        1593    2      3        KNeighborsClassifier     NaN  0.556962\n",
       "1594        1594    2      4        KNeighborsClassifier     NaN  0.645570\n",
       "1595        1595    2      5        KNeighborsClassifier     NaN  0.645570\n",
       "1596        1596    2      6        KNeighborsClassifier     NaN  0.556962\n",
       "1597        1597    2      7        KNeighborsClassifier     NaN  0.582278\n",
       "1598        1598    2      8        KNeighborsClassifier     NaN  0.683544\n",
       "1599        1599    2      9        KNeighborsClassifier     NaN  0.683544\n",
       "1600        1600    2     10        KNeighborsClassifier     NaN  0.658228\n",
       "1601        1601    2     11        KNeighborsClassifier     NaN  0.708861\n",
       "1602        1602    2     12        KNeighborsClassifier     NaN  0.708861\n",
       "1603        1603    2     13        KNeighborsClassifier     NaN  0.670886\n",
       "1604        1604    2     14        KNeighborsClassifier     NaN  0.632911\n",
       "1605        1605    3      0        KNeighborsClassifier     NaN  0.636364\n",
       "1606        1606    3      1        KNeighborsClassifier     NaN  0.584416\n",
       "1607        1607    3      2        KNeighborsClassifier     NaN  0.636364\n",
       "1608        1608    3      3        KNeighborsClassifier     NaN  0.610390\n",
       "1609        1609    3      4        KNeighborsClassifier     NaN  0.597403\n",
       "1610        1610    3      5        KNeighborsClassifier     NaN  0.662338\n",
       "1611        1611    3      6        KNeighborsClassifier     NaN  0.727273\n",
       "1612        1612    3      7        KNeighborsClassifier     NaN  0.675325\n",
       "1613        1613    3      8        KNeighborsClassifier     NaN  0.623377\n",
       "1614        1614    3      9        KNeighborsClassifier     NaN  0.675325\n",
       "1615        1615    3     10        KNeighborsClassifier     NaN  0.779221\n",
       "1616        1616    3     11        KNeighborsClassifier     NaN  0.623377\n",
       "1617        1617    3     12        KNeighborsClassifier     NaN  0.662338\n",
       "1618        1618    3     13        KNeighborsClassifier     NaN  0.714286\n",
       "1619        1619    3     14        KNeighborsClassifier     NaN  0.675325\n",
       "1620        1620    4      0        KNeighborsClassifier     NaN  0.657534\n",
       "1621        1621    4      1        KNeighborsClassifier     NaN  0.589041\n",
       "1622        1622    4      2        KNeighborsClassifier     NaN  0.616438\n",
       "1623        1623    4      3        KNeighborsClassifier     NaN  0.452055\n",
       "1624        1624    4      4        KNeighborsClassifier     NaN  0.698630\n",
       "1625        1625    4      5        KNeighborsClassifier     NaN  0.671233\n",
       "1626        1626    4      6        KNeighborsClassifier     NaN  0.602740\n",
       "1627        1627    4      7        KNeighborsClassifier     NaN  0.616438\n",
       "1628        1628    4      8        KNeighborsClassifier     NaN  0.547945\n",
       "1629        1629    4      9        KNeighborsClassifier     NaN  0.589041\n",
       "1630        1630    4     10        KNeighborsClassifier     NaN  0.726027\n",
       "1631        1631    4     11        KNeighborsClassifier     NaN  0.712329\n",
       "1632        1632    4     12        KNeighborsClassifier     NaN  0.657534\n",
       "1633        1633    4     13        KNeighborsClassifier     NaN  0.671233\n",
       "1634        1634    4     14        KNeighborsClassifier     NaN  0.657534\n",
       "1635        1635    5      0        KNeighborsClassifier     NaN  0.535211\n",
       "1636        1636    5      1        KNeighborsClassifier     NaN  0.676056\n",
       "1637        1637    5      2        KNeighborsClassifier     NaN  0.619718\n",
       "1638        1638    5      3        KNeighborsClassifier     NaN  0.605634\n",
       "1639        1639    5      4        KNeighborsClassifier     NaN  0.647887\n",
       "1640        1640    5      5        KNeighborsClassifier     NaN  0.718310\n",
       "1641        1641    5      6        KNeighborsClassifier     NaN  0.577465\n",
       "1642        1642    5      7        KNeighborsClassifier     NaN  0.619718\n",
       "1643        1643    5      8        KNeighborsClassifier     NaN  0.661972\n",
       "1644        1644    5      9        KNeighborsClassifier     NaN  0.690141\n",
       "1645        1645    5     10        KNeighborsClassifier     NaN  0.704225\n",
       "1646        1646    5     11        KNeighborsClassifier     NaN  0.605634\n",
       "1647        1647    5     12        KNeighborsClassifier     NaN  0.690141\n",
       "1648        1648    5     13        KNeighborsClassifier     NaN  0.746479\n",
       "1649        1649    5     14        KNeighborsClassifier     NaN  0.746479\n",
       "1650        1650    6      0        KNeighborsClassifier     NaN  0.614286\n",
       "1651        1651    6      1        KNeighborsClassifier     NaN  0.542857\n",
       "1652        1652    6      2        KNeighborsClassifier     NaN  0.585714\n",
       "1653        1653    6      3        KNeighborsClassifier     NaN  0.528571\n",
       "1654        1654    6      4        KNeighborsClassifier     NaN  0.628571\n",
       "1655        1655    6      5        KNeighborsClassifier     NaN  0.614286\n",
       "1656        1656    6      6        KNeighborsClassifier     NaN  0.628571\n",
       "1657        1657    6      7        KNeighborsClassifier     NaN  0.600000\n",
       "1658        1658    6      8        KNeighborsClassifier     NaN  0.571429\n",
       "1659        1659    6      9        KNeighborsClassifier     NaN  0.528571\n",
       "1660        1660    6     10        KNeighborsClassifier     NaN  0.657143\n",
       "1661        1661    6     11        KNeighborsClassifier     NaN  0.657143\n",
       "1662        1662    6     12        KNeighborsClassifier     NaN  0.585714\n",
       "1663        1663    6     13        KNeighborsClassifier     NaN  0.614286\n",
       "1664        1664    6     14        KNeighborsClassifier     NaN  0.657143\n",
       "1665        1665    7      0        KNeighborsClassifier     NaN  0.785714\n",
       "1666        1666    7      1        KNeighborsClassifier     NaN  0.671429\n",
       "1667        1667    7      2        KNeighborsClassifier     NaN  0.642857\n",
       "1668        1668    7      3        KNeighborsClassifier     NaN  0.571429\n",
       "1669        1669    7      4        KNeighborsClassifier     NaN  0.742857\n",
       "1670        1670    7      5        KNeighborsClassifier     NaN  0.771429\n",
       "1671        1671    7      6        KNeighborsClassifier     NaN  0.657143\n",
       "1672        1672    7      7        KNeighborsClassifier     NaN  0.742857\n",
       "1673        1673    7      8        KNeighborsClassifier     NaN  0.742857\n",
       "1674        1674    7      9        KNeighborsClassifier     NaN  0.642857\n",
       "1675        1675    7     10        KNeighborsClassifier     NaN  0.671429\n",
       "1676        1676    7     11        KNeighborsClassifier     NaN  0.814286\n",
       "1677        1677    7     12        KNeighborsClassifier     NaN  0.685714\n",
       "1678        1678    7     13        KNeighborsClassifier     NaN  0.742857\n",
       "1679        1679    7     14        KNeighborsClassifier     NaN  0.757143\n",
       "1680        1680    8      0        KNeighborsClassifier     NaN  0.724638\n",
       "1681        1681    8      1        KNeighborsClassifier     NaN  0.739130\n",
       "1682        1682    8      2        KNeighborsClassifier     NaN  0.594203\n",
       "1683        1683    8      3        KNeighborsClassifier     NaN  0.521739\n",
       "1684        1684    8      4        KNeighborsClassifier     NaN  0.739130\n",
       "1685        1685    8      5        KNeighborsClassifier     NaN  0.753623\n",
       "1686        1686    8      6        KNeighborsClassifier     NaN  0.652174\n",
       "1687        1687    8      7        KNeighborsClassifier     NaN  0.739130\n",
       "1688        1688    8      8        KNeighborsClassifier     NaN  0.739130\n",
       "1689        1689    8      9        KNeighborsClassifier     NaN  0.695652\n",
       "1690        1690    8     10        KNeighborsClassifier     NaN  0.782609\n",
       "1691        1691    8     11        KNeighborsClassifier     NaN  0.768116\n",
       "1692        1692    8     12        KNeighborsClassifier     NaN  0.753623\n",
       "1693        1693    8     13        KNeighborsClassifier     NaN  0.681159\n",
       "1694        1694    8     14        KNeighborsClassifier     NaN  0.840580\n",
       "1695        1695    9      0        KNeighborsClassifier     NaN  0.594203\n",
       "1696        1696    9      1        KNeighborsClassifier     NaN  0.608696\n",
       "1697        1697    9      2        KNeighborsClassifier     NaN  0.536232\n",
       "1698        1698    9      3        KNeighborsClassifier     NaN  0.434783\n",
       "1699        1699    9      4        KNeighborsClassifier     NaN  0.666667\n",
       "1700        1700    9      5        KNeighborsClassifier     NaN  0.579710\n",
       "1701        1701    9      6        KNeighborsClassifier     NaN  0.623188\n",
       "1702        1702    9      7        KNeighborsClassifier     NaN  0.594203\n",
       "1703        1703    9      8        KNeighborsClassifier     NaN  0.550725\n",
       "1704        1704    9      9        KNeighborsClassifier     NaN  0.608696\n",
       "1705        1705    9     10        KNeighborsClassifier     NaN  0.652174\n",
       "1706        1706    9     11        KNeighborsClassifier     NaN  0.637681\n",
       "1707        1707    9     12        KNeighborsClassifier     NaN  0.666667\n",
       "1708        1708    9     13        KNeighborsClassifier     NaN  0.637681\n",
       "1709        1709    9     14        KNeighborsClassifier     NaN  0.666667\n",
       "1710        1710   10      0        KNeighborsClassifier     NaN  0.513889\n",
       "1711        1711   10      1        KNeighborsClassifier     NaN  0.541667\n",
       "1712        1712   10      2        KNeighborsClassifier     NaN  0.569444\n",
       "1713        1713   10      3        KNeighborsClassifier     NaN  0.569444\n",
       "1714        1714   10      4        KNeighborsClassifier     NaN  0.625000\n",
       "1715        1715   10      5        KNeighborsClassifier     NaN  0.583333\n",
       "1716        1716   10      6        KNeighborsClassifier     NaN  0.666667\n",
       "1717        1717   10      7        KNeighborsClassifier     NaN  0.625000\n",
       "1718        1718   10      8        KNeighborsClassifier     NaN  0.666667\n",
       "1719        1719   10      9        KNeighborsClassifier     NaN  0.708333\n",
       "1720        1720   10     10        KNeighborsClassifier     NaN  0.597222\n",
       "1721        1721   10     11        KNeighborsClassifier     NaN  0.680556\n",
       "1722        1722   10     12        KNeighborsClassifier     NaN  0.750000\n",
       "1723        1723   10     13        KNeighborsClassifier     NaN  0.750000\n",
       "1724        1724   10     14        KNeighborsClassifier     NaN  0.666667\n",
       "1725        1725   11      0        KNeighborsClassifier     NaN  0.453333\n",
       "1726        1726   11      1        KNeighborsClassifier     NaN  0.706667\n",
       "1727        1727   11      2        KNeighborsClassifier     NaN  0.640000\n",
       "1728        1728   11      3        KNeighborsClassifier     NaN  0.600000\n",
       "1729        1729   11      4        KNeighborsClassifier     NaN  0.706667\n",
       "1730        1730   11      5        KNeighborsClassifier     NaN  0.760000\n",
       "1731        1731   11      6        KNeighborsClassifier     NaN  0.720000\n",
       "1732        1732   11      7        KNeighborsClassifier     NaN  0.733333\n",
       "1733        1733   11      8        KNeighborsClassifier     NaN  0.720000\n",
       "1734        1734   11      9        KNeighborsClassifier     NaN  0.706667\n",
       "1735        1735   11     10        KNeighborsClassifier     NaN  0.773333\n",
       "1736        1736   11     11        KNeighborsClassifier     NaN  0.800000\n",
       "1737        1737   11     12        KNeighborsClassifier     NaN  0.733333\n",
       "1738        1738   11     13        KNeighborsClassifier     NaN  0.760000\n",
       "1739        1739   11     14        KNeighborsClassifier     NaN  0.733333\n",
       "1740        1740   12      0        KNeighborsClassifier     NaN  0.358974\n",
       "1741        1741   12      1        KNeighborsClassifier     NaN  0.564103\n",
       "1742        1742   12      2        KNeighborsClassifier     NaN  0.653846\n",
       "1743        1743   12      3        KNeighborsClassifier     NaN  0.589744\n",
       "1744        1744   12      4        KNeighborsClassifier     NaN  0.500000\n",
       "1745        1745   12      5        KNeighborsClassifier     NaN  0.615385\n",
       "1746        1746   12      6        KNeighborsClassifier     NaN  0.743590\n",
       "1747        1747   12      7        KNeighborsClassifier     NaN  0.589744\n",
       "1748        1748   12      8        KNeighborsClassifier     NaN  0.448718\n",
       "1749        1749   12      9        KNeighborsClassifier     NaN  0.602564\n",
       "1750        1750   12     10        KNeighborsClassifier     NaN  0.641026\n",
       "1751        1751   12     11        KNeighborsClassifier     NaN  0.666667\n",
       "1752        1752   12     12        KNeighborsClassifier     NaN  0.525641\n",
       "1753        1753   12     13        KNeighborsClassifier     NaN  0.653846\n",
       "1754        1754   12     14        KNeighborsClassifier     NaN  0.679487\n",
       "1755        1755   13      0        KNeighborsClassifier     NaN  0.475000\n",
       "1756        1756   13      1        KNeighborsClassifier     NaN  0.762500\n",
       "1757        1757   13      2        KNeighborsClassifier     NaN  0.450000\n",
       "1758        1758   13      3        KNeighborsClassifier     NaN  0.675000\n",
       "1759        1759   13      4        KNeighborsClassifier     NaN  0.600000\n",
       "1760        1760   13      5        KNeighborsClassifier     NaN  0.762500\n",
       "1761        1761   13      6        KNeighborsClassifier     NaN  0.700000\n",
       "1762        1762   13      7        KNeighborsClassifier     NaN  0.550000\n",
       "1763        1763   13      8        KNeighborsClassifier     NaN  0.650000\n",
       "1764        1764   13      9        KNeighborsClassifier     NaN  0.750000\n",
       "1765        1765   13     10        KNeighborsClassifier     NaN  0.700000\n",
       "1766        1766   13     11        KNeighborsClassifier     NaN  0.662500\n",
       "1767        1767   13     12        KNeighborsClassifier     NaN  0.725000\n",
       "1768        1768   13     13        KNeighborsClassifier     NaN  0.737500\n",
       "1769        1769   13     14        KNeighborsClassifier     NaN  0.775000\n",
       "1770        1770   14      0        KNeighborsClassifier     NaN  0.687500\n",
       "1771        1771   14      1        KNeighborsClassifier     NaN  0.712500\n",
       "1772        1772   14      2        KNeighborsClassifier     NaN  0.612500\n",
       "1773        1773   14      3        KNeighborsClassifier     NaN  0.637500\n",
       "1774        1774   14      4        KNeighborsClassifier     NaN  0.700000\n",
       "1775        1775   14      5        KNeighborsClassifier     NaN  0.687500\n",
       "1776        1776   14      6        KNeighborsClassifier     NaN  0.650000\n",
       "1777        1777   14      7        KNeighborsClassifier     NaN  0.737500\n",
       "1778        1778   14      8        KNeighborsClassifier     NaN  0.725000\n",
       "1779        1779   14      9        KNeighborsClassifier     NaN  0.712500\n",
       "1780        1780   14     10        KNeighborsClassifier     NaN  0.662500\n",
       "1781        1781   14     11        KNeighborsClassifier     NaN  0.637500\n",
       "1782        1782   14     12        KNeighborsClassifier     NaN  0.700000\n",
       "1783        1783   14     13        KNeighborsClassifier     NaN  0.662500\n",
       "1784        1784   14     14        KNeighborsClassifier     NaN  0.687500\n",
       "1785        1785   15      0        KNeighborsClassifier     NaN  0.662500\n",
       "1786        1786   15      1        KNeighborsClassifier     NaN  0.625000\n",
       "1787        1787   15      2        KNeighborsClassifier     NaN  0.600000\n",
       "1788        1788   15      3        KNeighborsClassifier     NaN  0.537500\n",
       "1789        1789   15      4        KNeighborsClassifier     NaN  0.662500\n",
       "1790        1790   15      5        KNeighborsClassifier     NaN  0.625000\n",
       "1791        1791   15      6        KNeighborsClassifier     NaN  0.612500\n",
       "1792        1792   15      7        KNeighborsClassifier     NaN  0.700000\n",
       "1793        1793   15      8        KNeighborsClassifier     NaN  0.700000\n",
       "1794        1794   15      9        KNeighborsClassifier     NaN  0.762500\n",
       "1795        1795   15     10        KNeighborsClassifier     NaN  0.762500\n",
       "1796        1796   15     11        KNeighborsClassifier     NaN  0.687500\n",
       "1797        1797   15     12        KNeighborsClassifier     NaN  0.775000\n",
       "1798        1798   15     13        KNeighborsClassifier     NaN  0.712500\n",
       "1799        1799   15     14        KNeighborsClassifier     NaN  0.837500\n",
       "1800        1800   16      0        KNeighborsClassifier     NaN  0.575000\n",
       "1801        1801   16      1        KNeighborsClassifier     NaN  0.550000\n",
       "1802        1802   16      2        KNeighborsClassifier     NaN  0.612500\n",
       "1803        1803   16      3        KNeighborsClassifier     NaN  0.650000\n",
       "1804        1804   16      4        KNeighborsClassifier     NaN  0.637500\n",
       "1805        1805   16      5        KNeighborsClassifier     NaN  0.625000\n",
       "1806        1806   16      6        KNeighborsClassifier     NaN  0.575000\n",
       "1807        1807   16      7        KNeighborsClassifier     NaN  0.575000\n",
       "1808        1808   16      8        KNeighborsClassifier     NaN  0.512500\n",
       "1809        1809   16      9        KNeighborsClassifier     NaN  0.712500\n",
       "1810        1810   16     10        KNeighborsClassifier     NaN  0.625000\n",
       "1811        1811   16     11        KNeighborsClassifier     NaN  0.600000\n",
       "1812        1812   16     12        KNeighborsClassifier     NaN  0.650000\n",
       "1813        1813   16     13        KNeighborsClassifier     NaN  0.750000\n",
       "1814        1814   16     14        KNeighborsClassifier     NaN  0.637500\n",
       "1815        1815   17      0        KNeighborsClassifier     NaN  0.675000\n",
       "1816        1816   17      1        KNeighborsClassifier     NaN  0.675000\n",
       "1817        1817   17      2        KNeighborsClassifier     NaN  0.400000\n",
       "1818        1818   17      3        KNeighborsClassifier     NaN  0.600000\n",
       "1819        1819   17      4        KNeighborsClassifier     NaN  0.662500\n",
       "1820        1820   17      5        KNeighborsClassifier     NaN  0.687500\n",
       "1821        1821   17      6        KNeighborsClassifier     NaN  0.650000\n",
       "1822        1822   17      7        KNeighborsClassifier     NaN  0.725000\n",
       "1823        1823   17      8        KNeighborsClassifier     NaN  0.775000\n",
       "1824        1824   17      9        KNeighborsClassifier     NaN  0.750000\n",
       "1825        1825   17     10        KNeighborsClassifier     NaN  0.675000\n",
       "1826        1826   17     11        KNeighborsClassifier     NaN  0.787500\n",
       "1827        1827   17     12        KNeighborsClassifier     NaN  0.700000\n",
       "1828        1828   17     13        KNeighborsClassifier     NaN  0.775000\n",
       "1829        1829   17     14        KNeighborsClassifier     NaN  0.775000\n",
       "1830        1830   WC      0        KNeighborsClassifier     NaN  0.450000\n",
       "1831        1831   WC      1        KNeighborsClassifier     NaN  0.500000\n",
       "1832        1832   WC      2        KNeighborsClassifier     NaN  0.650000\n",
       "1833        1833   WC      3        KNeighborsClassifier     NaN  0.400000\n",
       "1834        1834   WC      4        KNeighborsClassifier     NaN  0.600000\n",
       "1835        1835   WC      5        KNeighborsClassifier     NaN  0.650000\n",
       "1836        1836   WC      6        KNeighborsClassifier     NaN  0.500000\n",
       "1837        1837   WC      7        KNeighborsClassifier     NaN  0.600000\n",
       "1838        1838   WC      8        KNeighborsClassifier     NaN  0.450000\n",
       "1839        1839   WC      9        KNeighborsClassifier     NaN  0.500000\n",
       "1840        1840   WC     10        KNeighborsClassifier     NaN  0.550000\n",
       "1841        1841   WC     11        KNeighborsClassifier     NaN  0.600000\n",
       "1842        1842   WC     12        KNeighborsClassifier     NaN  0.450000\n",
       "1843        1843   WC     13        KNeighborsClassifier     NaN  0.700000\n",
       "1844        1844   WC     14        KNeighborsClassifier     NaN  0.600000\n",
       "1845        1845   DV      0        KNeighborsClassifier     NaN  0.700000\n",
       "1846        1846   DV      1        KNeighborsClassifier     NaN  0.550000\n",
       "1847        1847   DV      2        KNeighborsClassifier     NaN  0.450000\n",
       "1848        1848   DV      3        KNeighborsClassifier     NaN  0.550000\n",
       "1849        1849   DV      4        KNeighborsClassifier     NaN  0.650000\n",
       "1850        1850   DV      5        KNeighborsClassifier     NaN  0.450000\n",
       "1851        1851   DV      6        KNeighborsClassifier     NaN  0.450000\n",
       "1852        1852   DV      7        KNeighborsClassifier     NaN  0.600000\n",
       "1853        1853   DV      8        KNeighborsClassifier     NaN  0.600000\n",
       "1854        1854   DV      9        KNeighborsClassifier     NaN  0.450000\n",
       "1855        1855   DV     10        KNeighborsClassifier     NaN  0.600000\n",
       "1856        1856   DV     11        KNeighborsClassifier     NaN  0.600000\n",
       "1857        1857   DV     12        KNeighborsClassifier     NaN  0.500000\n",
       "1858        1858   DV     13        KNeighborsClassifier     NaN  0.450000\n",
       "1859        1859   DV     14        KNeighborsClassifier     NaN  0.500000\n",
       "1860        1860   CC      0        KNeighborsClassifier     NaN  0.400000\n",
       "1861        1861   CC      1        KNeighborsClassifier     NaN  0.500000\n",
       "1862        1862   CC      2        KNeighborsClassifier     NaN  0.500000\n",
       "1863        1863   CC      3        KNeighborsClassifier     NaN  0.500000\n",
       "1864        1864   CC      4        KNeighborsClassifier     NaN  0.500000\n",
       "1865        1865   CC      5        KNeighborsClassifier     NaN  0.600000\n",
       "1866        1866   CC      6        KNeighborsClassifier     NaN  0.500000\n",
       "1867        1867   CC      7        KNeighborsClassifier     NaN  0.400000\n",
       "1868        1868   CC      8        KNeighborsClassifier     NaN  0.500000\n",
       "1869        1869   CC      9        KNeighborsClassifier     NaN  0.500000\n",
       "1870        1870   CC     10        KNeighborsClassifier     NaN  0.400000\n",
       "1871        1871   CC     11        KNeighborsClassifier     NaN  0.400000\n",
       "1872        1872   CC     12        KNeighborsClassifier     NaN  0.500000\n",
       "1873        1873   CC     13        KNeighborsClassifier     NaN  0.500000\n",
       "1874        1874   CC     14        KNeighborsClassifier     NaN  0.500000\n",
       "1875        1875   SB      0        KNeighborsClassifier     NaN  0.400000\n",
       "1876        1876   SB      1        KNeighborsClassifier     NaN  0.400000\n",
       "1877        1877   SB      2        KNeighborsClassifier     NaN  0.400000\n",
       "1878        1878   SB      3        KNeighborsClassifier     NaN  0.600000\n",
       "1879        1879   SB      4        KNeighborsClassifier     NaN  0.600000\n",
       "1880        1880   SB      5        KNeighborsClassifier     NaN  0.400000\n",
       "1881        1881   SB      6        KNeighborsClassifier     NaN  0.400000\n",
       "1882        1882   SB      7        KNeighborsClassifier     NaN  0.400000\n",
       "1883        1883   SB      8        KNeighborsClassifier     NaN  0.600000\n",
       "1884        1884   SB      9        KNeighborsClassifier     NaN  0.400000\n",
       "1885        1885   SB     10        KNeighborsClassifier     NaN  0.400000\n",
       "1886        1886   SB     11        KNeighborsClassifier     NaN  0.400000\n",
       "1887        1887   SB     12        KNeighborsClassifier     NaN  0.400000\n",
       "1888        1888   SB     13        KNeighborsClassifier     NaN  0.400000\n",
       "1889        1889   SB     14        KNeighborsClassifier     NaN  0.400000\n",
       "1890        1890    1      0          AdaBoostClassifier     NaN  0.612500\n",
       "1891        1891    1      1          AdaBoostClassifier     NaN  0.675000\n",
       "1892        1892    1      2          AdaBoostClassifier     NaN  0.762500\n",
       "1893        1893    1      3          AdaBoostClassifier     NaN  0.637500\n",
       "1894        1894    1      4          AdaBoostClassifier     NaN  0.687500\n",
       "1895        1895    1      5          AdaBoostClassifier     NaN  0.750000\n",
       "1896        1896    1      6          AdaBoostClassifier     NaN  0.762500\n",
       "1897        1897    1      7          AdaBoostClassifier     NaN  0.762500\n",
       "1898        1898    1      8          AdaBoostClassifier     NaN  0.662500\n",
       "1899        1899    1      9          AdaBoostClassifier     NaN  0.737500\n",
       "1900        1900    1     10          AdaBoostClassifier     NaN  0.775000\n",
       "1901        1901    1     11          AdaBoostClassifier     NaN  0.675000\n",
       "1902        1902    1     12          AdaBoostClassifier     NaN  0.712500\n",
       "1903        1903    1     13          AdaBoostClassifier     NaN  0.787500\n",
       "1904        1904    1     14          AdaBoostClassifier     NaN  0.787500\n",
       "1905        1905    2      0          AdaBoostClassifier     NaN  0.645570\n",
       "1906        1906    2      1          AdaBoostClassifier     NaN  0.569620\n",
       "1907        1907    2      2          AdaBoostClassifier     NaN  0.670886\n",
       "1908        1908    2      3          AdaBoostClassifier     NaN  0.620253\n",
       "1909        1909    2      4          AdaBoostClassifier     NaN  0.683544\n",
       "1910        1910    2      5          AdaBoostClassifier     NaN  0.708861\n",
       "1911        1911    2      6          AdaBoostClassifier     NaN  0.721519\n",
       "1912        1912    2      7          AdaBoostClassifier     NaN  0.658228\n",
       "1913        1913    2      8          AdaBoostClassifier     NaN  0.683544\n",
       "1914        1914    2      9          AdaBoostClassifier     NaN  0.683544\n",
       "1915        1915    2     10          AdaBoostClassifier     NaN  0.708861\n",
       "1916        1916    2     11          AdaBoostClassifier     NaN  0.810127\n",
       "1917        1917    2     12          AdaBoostClassifier     NaN  0.708861\n",
       "1918        1918    2     13          AdaBoostClassifier     NaN  0.784810\n",
       "1919        1919    2     14          AdaBoostClassifier     NaN  0.784810\n",
       "1920        1920    3      0          AdaBoostClassifier     NaN  0.571429\n",
       "1921        1921    3      1          AdaBoostClassifier     NaN  0.636364\n",
       "1922        1922    3      2          AdaBoostClassifier     NaN  0.623377\n",
       "1923        1923    3      3          AdaBoostClassifier     NaN  0.610390\n",
       "1924        1924    3      4          AdaBoostClassifier     NaN  0.740260\n",
       "1925        1925    3      5          AdaBoostClassifier     NaN  0.701299\n",
       "1926        1926    3      6          AdaBoostClassifier     NaN  0.714286\n",
       "1927        1927    3      7          AdaBoostClassifier     NaN  0.740260\n",
       "1928        1928    3      8          AdaBoostClassifier     NaN  0.688312\n",
       "1929        1929    3      9          AdaBoostClassifier     NaN  0.649351\n",
       "1930        1930    3     10          AdaBoostClassifier     NaN  0.649351\n",
       "1931        1931    3     11          AdaBoostClassifier     NaN  0.701299\n",
       "1932        1932    3     12          AdaBoostClassifier     NaN  0.714286\n",
       "1933        1933    3     13          AdaBoostClassifier     NaN  0.649351\n",
       "1934        1934    3     14          AdaBoostClassifier     NaN  0.623377\n",
       "1935        1935    4      0          AdaBoostClassifier     NaN  0.657534\n",
       "1936        1936    4      1          AdaBoostClassifier     NaN  0.671233\n",
       "1937        1937    4      2          AdaBoostClassifier     NaN  0.616438\n",
       "1938        1938    4      3          AdaBoostClassifier     NaN  0.452055\n",
       "1939        1939    4      4          AdaBoostClassifier     NaN  0.684932\n",
       "1940        1940    4      5          AdaBoostClassifier     NaN  0.671233\n",
       "1941        1941    4      6          AdaBoostClassifier     NaN  0.643836\n",
       "1942        1942    4      7          AdaBoostClassifier     NaN  0.684932\n",
       "1943        1943    4      8          AdaBoostClassifier     NaN  0.630137\n",
       "1944        1944    4      9          AdaBoostClassifier     NaN  0.698630\n",
       "1945        1945    4     10          AdaBoostClassifier     NaN  0.657534\n",
       "1946        1946    4     11          AdaBoostClassifier     NaN  0.712329\n",
       "1947        1947    4     12          AdaBoostClassifier     NaN  0.684932\n",
       "1948        1948    4     13          AdaBoostClassifier     NaN  0.712329\n",
       "1949        1949    4     14          AdaBoostClassifier     NaN  0.794521\n",
       "1950        1950    5      0          AdaBoostClassifier     NaN  0.563380\n",
       "1951        1951    5      1          AdaBoostClassifier     NaN  0.704225\n",
       "1952        1952    5      2          AdaBoostClassifier     NaN  0.718310\n",
       "1953        1953    5      3          AdaBoostClassifier     NaN  0.605634\n",
       "1954        1954    5      4          AdaBoostClassifier     NaN  0.647887\n",
       "1955        1955    5      5          AdaBoostClassifier     NaN  0.746479\n",
       "1956        1956    5      6          AdaBoostClassifier     NaN  0.732394\n",
       "1957        1957    5      7          AdaBoostClassifier     NaN  0.661972\n",
       "1958        1958    5      8          AdaBoostClassifier     NaN  0.676056\n",
       "1959        1959    5      9          AdaBoostClassifier     NaN  0.676056\n",
       "1960        1960    5     10          AdaBoostClassifier     NaN  0.746479\n",
       "1961        1961    5     11          AdaBoostClassifier     NaN  0.704225\n",
       "1962        1962    5     12          AdaBoostClassifier     NaN  0.676056\n",
       "1963        1963    5     13          AdaBoostClassifier     NaN  0.746479\n",
       "1964        1964    5     14          AdaBoostClassifier     NaN  0.816901\n",
       "1965        1965    6      0          AdaBoostClassifier     NaN  0.485714\n",
       "1966        1966    6      1          AdaBoostClassifier     NaN  0.614286\n",
       "1967        1967    6      2          AdaBoostClassifier     NaN  0.542857\n",
       "1968        1968    6      3          AdaBoostClassifier     NaN  0.571429\n",
       "1969        1969    6      4          AdaBoostClassifier     NaN  0.671429\n",
       "1970        1970    6      5          AdaBoostClassifier     NaN  0.642857\n",
       "1971        1971    6      6          AdaBoostClassifier     NaN  0.657143\n",
       "1972        1972    6      7          AdaBoostClassifier     NaN  0.671429\n",
       "1973        1973    6      8          AdaBoostClassifier     NaN  0.600000\n",
       "1974        1974    6      9          AdaBoostClassifier     NaN  0.600000\n",
       "1975        1975    6     10          AdaBoostClassifier     NaN  0.628571\n",
       "1976        1976    6     11          AdaBoostClassifier     NaN  0.657143\n",
       "1977        1977    6     12          AdaBoostClassifier     NaN  0.700000\n",
       "1978        1978    6     13          AdaBoostClassifier     NaN  0.642857\n",
       "1979        1979    6     14          AdaBoostClassifier     NaN  0.657143\n",
       "1980        1980    7      0          AdaBoostClassifier     NaN  0.785714\n",
       "1981        1981    7      1          AdaBoostClassifier     NaN  0.671429\n",
       "1982        1982    7      2          AdaBoostClassifier     NaN  0.742857\n",
       "1983        1983    7      3          AdaBoostClassifier     NaN  0.585714\n",
       "1984        1984    7      4          AdaBoostClassifier     NaN  0.685714\n",
       "1985        1985    7      5          AdaBoostClassifier     NaN  0.728571\n",
       "1986        1986    7      6          AdaBoostClassifier     NaN  0.742857\n",
       "1987        1987    7      7          AdaBoostClassifier     NaN  0.814286\n",
       "1988        1988    7      8          AdaBoostClassifier     NaN  0.728571\n",
       "1989        1989    7      9          AdaBoostClassifier     NaN  0.685714\n",
       "1990        1990    7     10          AdaBoostClassifier     NaN  0.857143\n",
       "1991        1991    7     11          AdaBoostClassifier     NaN  0.842857\n",
       "1992        1992    7     12          AdaBoostClassifier     NaN  0.771429\n",
       "1993        1993    7     13          AdaBoostClassifier     NaN  0.800000\n",
       "1994        1994    7     14          AdaBoostClassifier     NaN  0.842857\n",
       "1995        1995    8      0          AdaBoostClassifier     NaN  0.724638\n",
       "1996        1996    8      1          AdaBoostClassifier     NaN  0.623188\n",
       "1997        1997    8      2          AdaBoostClassifier     NaN  0.724638\n",
       "1998        1998    8      3          AdaBoostClassifier     NaN  0.623188\n",
       "1999        1999    8      4          AdaBoostClassifier     NaN  0.724638\n",
       "2000        2000    8      5          AdaBoostClassifier     NaN  0.652174\n",
       "2001        2001    8      6          AdaBoostClassifier     NaN  0.637681\n",
       "2002        2002    8      7          AdaBoostClassifier     NaN  0.739130\n",
       "2003        2003    8      8          AdaBoostClassifier     NaN  0.782609\n",
       "2004        2004    8      9          AdaBoostClassifier     NaN  0.782609\n",
       "2005        2005    8     10          AdaBoostClassifier     NaN  0.724638\n",
       "2006        2006    8     11          AdaBoostClassifier     NaN  0.652174\n",
       "2007        2007    8     12          AdaBoostClassifier     NaN  0.768116\n",
       "2008        2008    8     13          AdaBoostClassifier     NaN  0.608696\n",
       "2009        2009    8     14          AdaBoostClassifier     NaN  0.753623\n",
       "2010        2010    9      0          AdaBoostClassifier     NaN  0.608696\n",
       "2011        2011    9      1          AdaBoostClassifier     NaN  0.550725\n",
       "2012        2012    9      2          AdaBoostClassifier     NaN  0.652174\n",
       "2013        2013    9      3          AdaBoostClassifier     NaN  0.666667\n",
       "2014        2014    9      4          AdaBoostClassifier     NaN  0.652174\n",
       "2015        2015    9      5          AdaBoostClassifier     NaN  0.724638\n",
       "2016        2016    9      6          AdaBoostClassifier     NaN  0.695652\n",
       "2017        2017    9      7          AdaBoostClassifier     NaN  0.652174\n",
       "2018        2018    9      8          AdaBoostClassifier     NaN  0.666667\n",
       "2019        2019    9      9          AdaBoostClassifier     NaN  0.681159\n",
       "2020        2020    9     10          AdaBoostClassifier     NaN  0.710145\n",
       "2021        2021    9     11          AdaBoostClassifier     NaN  0.710145\n",
       "2022        2022    9     12          AdaBoostClassifier     NaN  0.695652\n",
       "2023        2023    9     13          AdaBoostClassifier     NaN  0.739130\n",
       "2024        2024    9     14          AdaBoostClassifier     NaN  0.811594\n",
       "2025        2025   10      0          AdaBoostClassifier     NaN  0.625000\n",
       "2026        2026   10      1          AdaBoostClassifier     NaN  0.638889\n",
       "2027        2027   10      2          AdaBoostClassifier     NaN  0.583333\n",
       "2028        2028   10      3          AdaBoostClassifier     NaN  0.611111\n",
       "2029        2029   10      4          AdaBoostClassifier     NaN  0.722222\n",
       "2030        2030   10      5          AdaBoostClassifier     NaN  0.652778\n",
       "2031        2031   10      6          AdaBoostClassifier     NaN  0.680556\n",
       "2032        2032   10      7          AdaBoostClassifier     NaN  0.694444\n",
       "2033        2033   10      8          AdaBoostClassifier     NaN  0.708333\n",
       "2034        2034   10      9          AdaBoostClassifier     NaN  0.708333\n",
       "2035        2035   10     10          AdaBoostClassifier     NaN  0.763889\n",
       "2036        2036   10     11          AdaBoostClassifier     NaN  0.763889\n",
       "2037        2037   10     12          AdaBoostClassifier     NaN  0.791667\n",
       "2038        2038   10     13          AdaBoostClassifier     NaN  0.763889\n",
       "2039        2039   10     14          AdaBoostClassifier     NaN  0.847222\n",
       "2040        2040   11      0          AdaBoostClassifier     NaN  0.693333\n",
       "2041        2041   11      1          AdaBoostClassifier     NaN  0.706667\n",
       "2042        2042   11      2          AdaBoostClassifier     NaN  0.693333\n",
       "2043        2043   11      3          AdaBoostClassifier     NaN  0.586667\n",
       "2044        2044   11      4          AdaBoostClassifier     NaN  0.800000\n",
       "2045        2045   11      5          AdaBoostClassifier     NaN  0.800000\n",
       "2046        2046   11      6          AdaBoostClassifier     NaN  0.733333\n",
       "2047        2047   11      7          AdaBoostClassifier     NaN  0.773333\n",
       "2048        2048   11      8          AdaBoostClassifier     NaN  0.773333\n",
       "2049        2049   11      9          AdaBoostClassifier     NaN  0.693333\n",
       "2050        2050   11     10          AdaBoostClassifier     NaN  0.826667\n",
       "2051        2051   11     11          AdaBoostClassifier     NaN  0.733333\n",
       "2052        2052   11     12          AdaBoostClassifier     NaN  0.840000\n",
       "2053        2053   11     13          AdaBoostClassifier     NaN  0.680000\n",
       "2054        2054   11     14          AdaBoostClassifier     NaN  0.866667\n",
       "2055        2055   12      0          AdaBoostClassifier     NaN  0.602564\n",
       "2056        2056   12      1          AdaBoostClassifier     NaN  0.551282\n",
       "2057        2057   12      2          AdaBoostClassifier     NaN  0.628205\n",
       "2058        2058   12      3          AdaBoostClassifier     NaN  0.589744\n",
       "2059        2059   12      4          AdaBoostClassifier     NaN  0.679487\n",
       "2060        2060   12      5          AdaBoostClassifier     NaN  0.756410\n",
       "2061        2061   12      6          AdaBoostClassifier     NaN  0.743590\n",
       "2062        2062   12      7          AdaBoostClassifier     NaN  0.666667\n",
       "2063        2063   12      8          AdaBoostClassifier     NaN  0.615385\n",
       "2064        2064   12      9          AdaBoostClassifier     NaN  0.641026\n",
       "2065        2065   12     10          AdaBoostClassifier     NaN  0.756410\n",
       "2066        2066   12     11          AdaBoostClassifier     NaN  0.717949\n",
       "2067        2067   12     12          AdaBoostClassifier     NaN  0.743590\n",
       "2068        2068   12     13          AdaBoostClassifier     NaN  0.794872\n",
       "2069        2069   12     14          AdaBoostClassifier     NaN  0.794872\n",
       "2070        2070   13      0          AdaBoostClassifier     NaN  0.587500\n",
       "2071        2071   13      1          AdaBoostClassifier     NaN  0.762500\n",
       "2072        2072   13      2          AdaBoostClassifier     NaN  0.612500\n",
       "2073        2073   13      3          AdaBoostClassifier     NaN  0.675000\n",
       "2074        2074   13      4          AdaBoostClassifier     NaN  0.750000\n",
       "2075        2075   13      5          AdaBoostClassifier     NaN  0.762500\n",
       "2076        2076   13      6          AdaBoostClassifier     NaN  0.712500\n",
       "2077        2077   13      7          AdaBoostClassifier     NaN  0.687500\n",
       "2078        2078   13      8          AdaBoostClassifier     NaN  0.687500\n",
       "2079        2079   13      9          AdaBoostClassifier     NaN  0.825000\n",
       "2080        2080   13     10          AdaBoostClassifier     NaN  0.750000\n",
       "2081        2081   13     11          AdaBoostClassifier     NaN  0.737500\n",
       "2082        2082   13     12          AdaBoostClassifier     NaN  0.812500\n",
       "2083        2083   13     13          AdaBoostClassifier     NaN  0.787500\n",
       "2084        2084   13     14          AdaBoostClassifier     NaN  0.750000\n",
       "2085        2085   14      0          AdaBoostClassifier     NaN  0.612500\n",
       "2086        2086   14      1          AdaBoostClassifier     NaN  0.762500\n",
       "2087        2087   14      2          AdaBoostClassifier     NaN  0.600000\n",
       "2088        2088   14      3          AdaBoostClassifier     NaN  0.637500\n",
       "2089        2089   14      4          AdaBoostClassifier     NaN  0.750000\n",
       "2090        2090   14      5          AdaBoostClassifier     NaN  0.837500\n",
       "2091        2091   14      6          AdaBoostClassifier     NaN  0.625000\n",
       "2092        2092   14      7          AdaBoostClassifier     NaN  0.750000\n",
       "2093        2093   14      8          AdaBoostClassifier     NaN  0.737500\n",
       "2094        2094   14      9          AdaBoostClassifier     NaN  0.762500\n",
       "2095        2095   14     10          AdaBoostClassifier     NaN  0.800000\n",
       "2096        2096   14     11          AdaBoostClassifier     NaN  0.725000\n",
       "2097        2097   14     12          AdaBoostClassifier     NaN  0.787500\n",
       "2098        2098   14     13          AdaBoostClassifier     NaN  0.800000\n",
       "2099        2099   14     14          AdaBoostClassifier     NaN  0.800000\n",
       "2100        2100   15      0          AdaBoostClassifier     NaN  0.662500\n",
       "2101        2101   15      1          AdaBoostClassifier     NaN  0.662500\n",
       "2102        2102   15      2          AdaBoostClassifier     NaN  0.625000\n",
       "2103        2103   15      3          AdaBoostClassifier     NaN  0.687500\n",
       "2104        2104   15      4          AdaBoostClassifier     NaN  0.800000\n",
       "2105        2105   15      5          AdaBoostClassifier     NaN  0.675000\n",
       "2106        2106   15      6          AdaBoostClassifier     NaN  0.675000\n",
       "2107        2107   15      7          AdaBoostClassifier     NaN  0.675000\n",
       "2108        2108   15      8          AdaBoostClassifier     NaN  0.762500\n",
       "2109        2109   15      9          AdaBoostClassifier     NaN  0.750000\n",
       "2110        2110   15     10          AdaBoostClassifier     NaN  0.775000\n",
       "2111        2111   15     11          AdaBoostClassifier     NaN  0.762500\n",
       "2112        2112   15     12          AdaBoostClassifier     NaN  0.787500\n",
       "2113        2113   15     13          AdaBoostClassifier     NaN  0.800000\n",
       "2114        2114   15     14          AdaBoostClassifier     NaN  0.825000\n",
       "2115        2115   16      0          AdaBoostClassifier     NaN  0.537500\n",
       "2116        2116   16      1          AdaBoostClassifier     NaN  0.612500\n",
       "2117        2117   16      2          AdaBoostClassifier     NaN  0.612500\n",
       "2118        2118   16      3          AdaBoostClassifier     NaN  0.612500\n",
       "2119        2119   16      4          AdaBoostClassifier     NaN  0.650000\n",
       "2120        2120   16      5          AdaBoostClassifier     NaN  0.650000\n",
       "2121        2121   16      6          AdaBoostClassifier     NaN  0.675000\n",
       "2122        2122   16      7          AdaBoostClassifier     NaN  0.587500\n",
       "2123        2123   16      8          AdaBoostClassifier     NaN  0.575000\n",
       "2124        2124   16      9          AdaBoostClassifier     NaN  0.725000\n",
       "2125        2125   16     10          AdaBoostClassifier     NaN  0.700000\n",
       "2126        2126   16     11          AdaBoostClassifier     NaN  0.675000\n",
       "2127        2127   16     12          AdaBoostClassifier     NaN  0.700000\n",
       "2128        2128   16     13          AdaBoostClassifier     NaN  0.725000\n",
       "2129        2129   16     14          AdaBoostClassifier     NaN  0.712500\n",
       "2130        2130   17      0          AdaBoostClassifier     NaN  0.675000\n",
       "2131        2131   17      1          AdaBoostClassifier     NaN  0.675000\n",
       "2132        2132   17      2          AdaBoostClassifier     NaN  0.687500\n",
       "2133        2133   17      3          AdaBoostClassifier     NaN  0.625000\n",
       "2134        2134   17      4          AdaBoostClassifier     NaN  0.675000\n",
       "2135        2135   17      5          AdaBoostClassifier     NaN  0.737500\n",
       "2136        2136   17      6          AdaBoostClassifier     NaN  0.737500\n",
       "2137        2137   17      7          AdaBoostClassifier     NaN  0.750000\n",
       "2138        2138   17      8          AdaBoostClassifier     NaN  0.700000\n",
       "2139        2139   17      9          AdaBoostClassifier     NaN  0.712500\n",
       "2140        2140   17     10          AdaBoostClassifier     NaN  0.825000\n",
       "2141        2141   17     11          AdaBoostClassifier     NaN  0.812500\n",
       "2142        2142   17     12          AdaBoostClassifier     NaN  0.762500\n",
       "2143        2143   17     13          AdaBoostClassifier     NaN  0.825000\n",
       "2144        2144   17     14          AdaBoostClassifier     NaN  0.850000\n",
       "2145        2145   WC      0          AdaBoostClassifier     NaN  0.550000\n",
       "2146        2146   WC      1          AdaBoostClassifier     NaN  0.600000\n",
       "2147        2147   WC      2          AdaBoostClassifier     NaN  0.650000\n",
       "2148        2148   WC      3          AdaBoostClassifier     NaN  0.500000\n",
       "2149        2149   WC      4          AdaBoostClassifier     NaN  0.550000\n",
       "2150        2150   WC      5          AdaBoostClassifier     NaN  0.600000\n",
       "2151        2151   WC      6          AdaBoostClassifier     NaN  0.650000\n",
       "2152        2152   WC      7          AdaBoostClassifier     NaN  0.650000\n",
       "2153        2153   WC      8          AdaBoostClassifier     NaN  0.400000\n",
       "2154        2154   WC      9          AdaBoostClassifier     NaN  0.500000\n",
       "2155        2155   WC     10          AdaBoostClassifier     NaN  0.550000\n",
       "2156        2156   WC     11          AdaBoostClassifier     NaN  0.600000\n",
       "2157        2157   WC     12          AdaBoostClassifier     NaN  0.550000\n",
       "2158        2158   WC     13          AdaBoostClassifier     NaN  0.600000\n",
       "2159        2159   WC     14          AdaBoostClassifier     NaN  0.750000\n",
       "2160        2160   DV      0          AdaBoostClassifier     NaN  0.750000\n",
       "2161        2161   DV      1          AdaBoostClassifier     NaN  0.550000\n",
       "2162        2162   DV      2          AdaBoostClassifier     NaN  0.450000\n",
       "2163        2163   DV      3          AdaBoostClassifier     NaN  0.550000\n",
       "2164        2164   DV      4          AdaBoostClassifier     NaN  0.500000\n",
       "2165        2165   DV      5          AdaBoostClassifier     NaN  0.450000\n",
       "2166        2166   DV      6          AdaBoostClassifier     NaN  0.550000\n",
       "2167        2167   DV      7          AdaBoostClassifier     NaN  0.650000\n",
       "2168        2168   DV      8          AdaBoostClassifier     NaN  0.400000\n",
       "2169        2169   DV      9          AdaBoostClassifier     NaN  0.600000\n",
       "2170        2170   DV     10          AdaBoostClassifier     NaN  0.550000\n",
       "2171        2171   DV     11          AdaBoostClassifier     NaN  0.450000\n",
       "2172        2172   DV     12          AdaBoostClassifier     NaN  0.500000\n",
       "2173        2173   DV     13          AdaBoostClassifier     NaN  0.450000\n",
       "2174        2174   DV     14          AdaBoostClassifier     NaN  0.550000\n",
       "2175        2175   CC      0          AdaBoostClassifier     NaN  0.400000\n",
       "2176        2176   CC      1          AdaBoostClassifier     NaN  0.500000\n",
       "2177        2177   CC      2          AdaBoostClassifier     NaN  0.500000\n",
       "2178        2178   CC      3          AdaBoostClassifier     NaN  0.500000\n",
       "2179        2179   CC      4          AdaBoostClassifier     NaN  0.400000\n",
       "2180        2180   CC      5          AdaBoostClassifier     NaN  0.600000\n",
       "2181        2181   CC      6          AdaBoostClassifier     NaN  0.500000\n",
       "2182        2182   CC      7          AdaBoostClassifier     NaN  0.500000\n",
       "2183        2183   CC      8          AdaBoostClassifier     NaN  0.500000\n",
       "2184        2184   CC      9          AdaBoostClassifier     NaN  0.500000\n",
       "2185        2185   CC     10          AdaBoostClassifier     NaN  0.400000\n",
       "2186        2186   CC     11          AdaBoostClassifier     NaN  0.500000\n",
       "2187        2187   CC     12          AdaBoostClassifier     NaN  0.600000\n",
       "2188        2188   CC     13          AdaBoostClassifier     NaN  0.400000\n",
       "2189        2189   CC     14          AdaBoostClassifier     NaN  0.700000\n",
       "2190        2190   SB      0          AdaBoostClassifier     NaN  0.800000\n",
       "2191        2191   SB      1          AdaBoostClassifier     NaN  0.400000\n",
       "2192        2192   SB      2          AdaBoostClassifier     NaN  0.600000\n",
       "2193        2193   SB      3          AdaBoostClassifier     NaN  0.600000\n",
       "2194        2194   SB      4          AdaBoostClassifier     NaN  0.400000\n",
       "2195        2195   SB      5          AdaBoostClassifier     NaN  0.600000\n",
       "2196        2196   SB      6          AdaBoostClassifier     NaN  0.600000\n",
       "2197        2197   SB      7          AdaBoostClassifier     NaN  0.600000\n",
       "2198        2198   SB      8          AdaBoostClassifier     NaN  0.800000\n",
       "2199        2199   SB      9          AdaBoostClassifier     NaN  0.400000\n",
       "2200        2200   SB     10          AdaBoostClassifier     NaN  0.400000\n",
       "2201        2201   SB     11          AdaBoostClassifier     NaN  0.800000\n",
       "2202        2202   SB     12          AdaBoostClassifier     NaN  0.600000\n",
       "2203        2203   SB     13          AdaBoostClassifier     NaN  0.800000\n",
       "2204        2204   SB     14          AdaBoostClassifier     NaN  0.800000\n",
       "2205        2205    1      0  GradientBoostingClassifier     NaN  0.612500\n",
       "2206        2206    1      1  GradientBoostingClassifier     NaN  0.675000\n",
       "2207        2207    1      2  GradientBoostingClassifier     NaN  0.762500\n",
       "2208        2208    1      3  GradientBoostingClassifier     NaN  0.637500\n",
       "2209        2209    1      4  GradientBoostingClassifier     NaN  0.637500\n",
       "2210        2210    1      5  GradientBoostingClassifier     NaN  0.762500\n",
       "2211        2211    1      6  GradientBoostingClassifier     NaN  0.750000\n",
       "2212        2212    1      7  GradientBoostingClassifier     NaN  0.762500\n",
       "2213        2213    1      8  GradientBoostingClassifier     NaN  0.675000\n",
       "2214        2214    1      9  GradientBoostingClassifier     NaN  0.712500\n",
       "2215        2215    1     10  GradientBoostingClassifier     NaN  0.750000\n",
       "2216        2216    1     11  GradientBoostingClassifier     NaN  0.725000\n",
       "2217        2217    1     12  GradientBoostingClassifier     NaN  0.712500\n",
       "2218        2218    1     13  GradientBoostingClassifier     NaN  0.825000\n",
       "2219        2219    1     14  GradientBoostingClassifier     NaN  0.862500\n",
       "2220        2220    2      0  GradientBoostingClassifier     NaN  0.645570\n",
       "2221        2221    2      1  GradientBoostingClassifier     NaN  0.582278\n",
       "2222        2222    2      2  GradientBoostingClassifier     NaN  0.696203\n",
       "2223        2223    2      3  GradientBoostingClassifier     NaN  0.620253\n",
       "2224        2224    2      4  GradientBoostingClassifier     NaN  0.632911\n",
       "2225        2225    2      5  GradientBoostingClassifier     NaN  0.620253\n",
       "2226        2226    2      6  GradientBoostingClassifier     NaN  0.670886\n",
       "2227        2227    2      7  GradientBoostingClassifier     NaN  0.607595\n",
       "2228        2228    2      8  GradientBoostingClassifier     NaN  0.670886\n",
       "2229        2229    2      9  GradientBoostingClassifier     NaN  0.696203\n",
       "2230        2230    2     10  GradientBoostingClassifier     NaN  0.696203\n",
       "2231        2231    2     11  GradientBoostingClassifier     NaN  0.683544\n",
       "2232        2232    2     12  GradientBoostingClassifier     NaN  0.708861\n",
       "2233        2233    2     13  GradientBoostingClassifier     NaN  0.759494\n",
       "2234        2234    2     14  GradientBoostingClassifier     NaN  0.759494\n",
       "2235        2235    3      0  GradientBoostingClassifier     NaN  0.571429\n",
       "2236        2236    3      1  GradientBoostingClassifier     NaN  0.636364\n",
       "2237        2237    3      2  GradientBoostingClassifier     NaN  0.623377\n",
       "2238        2238    3      3  GradientBoostingClassifier     NaN  0.610390\n",
       "2239        2239    3      4  GradientBoostingClassifier     NaN  0.649351\n",
       "2240        2240    3      5  GradientBoostingClassifier     NaN  0.675325\n",
       "2241        2241    3      6  GradientBoostingClassifier     NaN  0.740260\n",
       "2242        2242    3      7  GradientBoostingClassifier     NaN  0.727273\n",
       "2243        2243    3      8  GradientBoostingClassifier     NaN  0.636364\n",
       "2244        2244    3      9  GradientBoostingClassifier     NaN  0.662338\n",
       "2245        2245    3     10  GradientBoostingClassifier     NaN  0.753247\n",
       "2246        2246    3     11  GradientBoostingClassifier     NaN  0.740260\n",
       "2247        2247    3     12  GradientBoostingClassifier     NaN  0.766234\n",
       "2248        2248    3     13  GradientBoostingClassifier     NaN  0.714286\n",
       "2249        2249    3     14  GradientBoostingClassifier     NaN  0.818182\n",
       "2250        2250    4      0  GradientBoostingClassifier     NaN  0.657534\n",
       "2251        2251    4      1  GradientBoostingClassifier     NaN  0.671233\n",
       "2252        2252    4      2  GradientBoostingClassifier     NaN  0.616438\n",
       "2253        2253    4      3  GradientBoostingClassifier     NaN  0.452055\n",
       "2254        2254    4      4  GradientBoostingClassifier     NaN  0.726027\n",
       "2255        2255    4      5  GradientBoostingClassifier     NaN  0.684932\n",
       "2256        2256    4      6  GradientBoostingClassifier     NaN  0.657534\n",
       "2257        2257    4      7  GradientBoostingClassifier     NaN  0.671233\n",
       "2258        2258    4      8  GradientBoostingClassifier     NaN  0.671233\n",
       "2259        2259    4      9  GradientBoostingClassifier     NaN  0.589041\n",
       "2260        2260    4     10  GradientBoostingClassifier     NaN  0.753425\n",
       "2261        2261    4     11  GradientBoostingClassifier     NaN  0.726027\n",
       "2262        2262    4     12  GradientBoostingClassifier     NaN  0.753425\n",
       "2263        2263    4     13  GradientBoostingClassifier     NaN  0.726027\n",
       "2264        2264    4     14  GradientBoostingClassifier     NaN  0.821918\n",
       "2265        2265    5      0  GradientBoostingClassifier     NaN  0.563380\n",
       "2266        2266    5      1  GradientBoostingClassifier     NaN  0.704225\n",
       "2267        2267    5      2  GradientBoostingClassifier     NaN  0.718310\n",
       "2268        2268    5      3  GradientBoostingClassifier     NaN  0.605634\n",
       "2269        2269    5      4  GradientBoostingClassifier     NaN  0.647887\n",
       "2270        2270    5      5  GradientBoostingClassifier     NaN  0.704225\n",
       "2271        2271    5      6  GradientBoostingClassifier     NaN  0.732394\n",
       "2272        2272    5      7  GradientBoostingClassifier     NaN  0.661972\n",
       "2273        2273    5      8  GradientBoostingClassifier     NaN  0.676056\n",
       "2274        2274    5      9  GradientBoostingClassifier     NaN  0.676056\n",
       "2275        2275    5     10  GradientBoostingClassifier     NaN  0.774648\n",
       "2276        2276    5     11  GradientBoostingClassifier     NaN  0.704225\n",
       "2277        2277    5     12  GradientBoostingClassifier     NaN  0.704225\n",
       "2278        2278    5     13  GradientBoostingClassifier     NaN  0.774648\n",
       "2279        2279    5     14  GradientBoostingClassifier     NaN  0.802817\n",
       "2280        2280    6      0  GradientBoostingClassifier     NaN  0.471429\n",
       "2281        2281    6      1  GradientBoostingClassifier     NaN  0.614286\n",
       "2282        2282    6      2  GradientBoostingClassifier     NaN  0.542857\n",
       "2283        2283    6      3  GradientBoostingClassifier     NaN  0.571429\n",
       "2284        2284    6      4  GradientBoostingClassifier     NaN  0.671429\n",
       "2285        2285    6      5  GradientBoostingClassifier     NaN  0.657143\n",
       "2286        2286    6      6  GradientBoostingClassifier     NaN  0.657143\n",
       "2287        2287    6      7  GradientBoostingClassifier     NaN  0.671429\n",
       "2288        2288    6      8  GradientBoostingClassifier     NaN  0.600000\n",
       "2289        2289    6      9  GradientBoostingClassifier     NaN  0.557143\n",
       "2290        2290    6     10  GradientBoostingClassifier     NaN  0.671429\n",
       "2291        2291    6     11  GradientBoostingClassifier     NaN  0.700000\n",
       "2292        2292    6     12  GradientBoostingClassifier     NaN  0.628571\n",
       "2293        2293    6     13  GradientBoostingClassifier     NaN  0.657143\n",
       "2294        2294    6     14  GradientBoostingClassifier     NaN  0.742857\n",
       "2295        2295    7      0  GradientBoostingClassifier     NaN  0.785714\n",
       "2296        2296    7      1  GradientBoostingClassifier     NaN  0.671429\n",
       "2297        2297    7      2  GradientBoostingClassifier     NaN  0.757143\n",
       "2298        2298    7      3  GradientBoostingClassifier     NaN  0.585714\n",
       "2299        2299    7      4  GradientBoostingClassifier     NaN  0.771429\n",
       "2300        2300    7      5  GradientBoostingClassifier     NaN  0.757143\n",
       "2301        2301    7      6  GradientBoostingClassifier     NaN  0.714286\n",
       "2302        2302    7      7  GradientBoostingClassifier     NaN  0.742857\n",
       "2303        2303    7      8  GradientBoostingClassifier     NaN  0.728571\n",
       "2304        2304    7      9  GradientBoostingClassifier     NaN  0.642857\n",
       "2305        2305    7     10  GradientBoostingClassifier     NaN  0.842857\n",
       "2306        2306    7     11  GradientBoostingClassifier     NaN  0.771429\n",
       "2307        2307    7     12  GradientBoostingClassifier     NaN  0.785714\n",
       "2308        2308    7     13  GradientBoostingClassifier     NaN  0.757143\n",
       "2309        2309    7     14  GradientBoostingClassifier     NaN  0.857143\n",
       "2310        2310    8      0  GradientBoostingClassifier     NaN  0.724638\n",
       "2311        2311    8      1  GradientBoostingClassifier     NaN  0.623188\n",
       "2312        2312    8      2  GradientBoostingClassifier     NaN  0.724638\n",
       "2313        2313    8      3  GradientBoostingClassifier     NaN  0.623188\n",
       "2314        2314    8      4  GradientBoostingClassifier     NaN  0.739130\n",
       "2315        2315    8      5  GradientBoostingClassifier     NaN  0.724638\n",
       "2316        2316    8      6  GradientBoostingClassifier     NaN  0.753623\n",
       "2317        2317    8      7  GradientBoostingClassifier     NaN  0.739130\n",
       "2318        2318    8      8  GradientBoostingClassifier     NaN  0.753623\n",
       "2319        2319    8      9  GradientBoostingClassifier     NaN  0.695652\n",
       "2320        2320    8     10  GradientBoostingClassifier     NaN  0.710145\n",
       "2321        2321    8     11  GradientBoostingClassifier     NaN  0.768116\n",
       "2322        2322    8     12  GradientBoostingClassifier     NaN  0.768116\n",
       "2323        2323    8     13  GradientBoostingClassifier     NaN  0.724638\n",
       "2324        2324    8     14  GradientBoostingClassifier     NaN  0.768116\n",
       "2325        2325    9      0  GradientBoostingClassifier     NaN  0.623188\n",
       "2326        2326    9      1  GradientBoostingClassifier     NaN  0.550725\n",
       "2327        2327    9      2  GradientBoostingClassifier     NaN  0.652174\n",
       "2328        2328    9      3  GradientBoostingClassifier     NaN  0.666667\n",
       "2329        2329    9      4  GradientBoostingClassifier     NaN  0.695652\n",
       "2330        2330    9      5  GradientBoostingClassifier     NaN  0.753623\n",
       "2331        2331    9      6  GradientBoostingClassifier     NaN  0.710145\n",
       "2332        2332    9      7  GradientBoostingClassifier     NaN  0.666667\n",
       "2333        2333    9      8  GradientBoostingClassifier     NaN  0.652174\n",
       "2334        2334    9      9  GradientBoostingClassifier     NaN  0.681159\n",
       "2335        2335    9     10  GradientBoostingClassifier     NaN  0.739130\n",
       "2336        2336    9     11  GradientBoostingClassifier     NaN  0.652174\n",
       "2337        2337    9     12  GradientBoostingClassifier     NaN  0.782609\n",
       "2338        2338    9     13  GradientBoostingClassifier     NaN  0.739130\n",
       "2339        2339    9     14  GradientBoostingClassifier     NaN  0.753623\n",
       "2340        2340   10      0  GradientBoostingClassifier     NaN  0.625000\n",
       "2341        2341   10      1  GradientBoostingClassifier     NaN  0.638889\n",
       "2342        2342   10      2  GradientBoostingClassifier     NaN  0.583333\n",
       "2343        2343   10      3  GradientBoostingClassifier     NaN  0.611111\n",
       "2344        2344   10      4  GradientBoostingClassifier     NaN  0.666667\n",
       "2345        2345   10      5  GradientBoostingClassifier     NaN  0.708333\n",
       "2346        2346   10      6  GradientBoostingClassifier     NaN  0.652778\n",
       "2347        2347   10      7  GradientBoostingClassifier     NaN  0.652778\n",
       "2348        2348   10      8  GradientBoostingClassifier     NaN  0.736111\n",
       "2349        2349   10      9  GradientBoostingClassifier     NaN  0.708333\n",
       "2350        2350   10     10  GradientBoostingClassifier     NaN  0.722222\n",
       "2351        2351   10     11  GradientBoostingClassifier     NaN  0.736111\n",
       "2352        2352   10     12  GradientBoostingClassifier     NaN  0.777778\n",
       "2353        2353   10     13  GradientBoostingClassifier     NaN  0.736111\n",
       "2354        2354   10     14  GradientBoostingClassifier     NaN  0.861111\n",
       "2355        2355   11      0  GradientBoostingClassifier     NaN  0.693333\n",
       "2356        2356   11      1  GradientBoostingClassifier     NaN  0.706667\n",
       "2357        2357   11      2  GradientBoostingClassifier     NaN  0.640000\n",
       "2358        2358   11      3  GradientBoostingClassifier     NaN  0.586667\n",
       "2359        2359   11      4  GradientBoostingClassifier     NaN  0.786667\n",
       "2360        2360   11      5  GradientBoostingClassifier     NaN  0.826667\n",
       "2361        2361   11      6  GradientBoostingClassifier     NaN  0.733333\n",
       "2362        2362   11      7  GradientBoostingClassifier     NaN  0.720000\n",
       "2363        2363   11      8  GradientBoostingClassifier     NaN  0.666667\n",
       "2364        2364   11      9  GradientBoostingClassifier     NaN  0.760000\n",
       "2365        2365   11     10  GradientBoostingClassifier     NaN  0.840000\n",
       "2366        2366   11     11  GradientBoostingClassifier     NaN  0.826667\n",
       "2367        2367   11     12  GradientBoostingClassifier     NaN  0.773333\n",
       "2368        2368   11     13  GradientBoostingClassifier     NaN  0.733333\n",
       "2369        2369   11     14  GradientBoostingClassifier     NaN  0.853333\n",
       "2370        2370   12      0  GradientBoostingClassifier     NaN  0.602564\n",
       "2371        2371   12      1  GradientBoostingClassifier     NaN  0.551282\n",
       "2372        2372   12      2  GradientBoostingClassifier     NaN  0.666667\n",
       "2373        2373   12      3  GradientBoostingClassifier     NaN  0.589744\n",
       "2374        2374   12      4  GradientBoostingClassifier     NaN  0.679487\n",
       "2375        2375   12      5  GradientBoostingClassifier     NaN  0.730769\n",
       "2376        2376   12      6  GradientBoostingClassifier     NaN  0.756410\n",
       "2377        2377   12      7  GradientBoostingClassifier     NaN  0.653846\n",
       "2378        2378   12      8  GradientBoostingClassifier     NaN  0.461538\n",
       "2379        2379   12      9  GradientBoostingClassifier     NaN  0.679487\n",
       "2380        2380   12     10  GradientBoostingClassifier     NaN  0.743590\n",
       "2381        2381   12     11  GradientBoostingClassifier     NaN  0.692308\n",
       "2382        2382   12     12  GradientBoostingClassifier     NaN  0.602564\n",
       "2383        2383   12     13  GradientBoostingClassifier     NaN  0.794872\n",
       "2384        2384   12     14  GradientBoostingClassifier     NaN  0.833333\n",
       "2385        2385   13      0  GradientBoostingClassifier     NaN  0.575000\n",
       "2386        2386   13      1  GradientBoostingClassifier     NaN  0.762500\n",
       "2387        2387   13      2  GradientBoostingClassifier     NaN  0.612500\n",
       "2388        2388   13      3  GradientBoostingClassifier     NaN  0.675000\n",
       "2389        2389   13      4  GradientBoostingClassifier     NaN  0.737500\n",
       "2390        2390   13      5  GradientBoostingClassifier     NaN  0.750000\n",
       "2391        2391   13      6  GradientBoostingClassifier     NaN  0.712500\n",
       "2392        2392   13      7  GradientBoostingClassifier     NaN  0.625000\n",
       "2393        2393   13      8  GradientBoostingClassifier     NaN  0.650000\n",
       "2394        2394   13      9  GradientBoostingClassifier     NaN  0.787500\n",
       "2395        2395   13     10  GradientBoostingClassifier     NaN  0.750000\n",
       "2396        2396   13     11  GradientBoostingClassifier     NaN  0.675000\n",
       "2397        2397   13     12  GradientBoostingClassifier     NaN  0.750000\n",
       "2398        2398   13     13  GradientBoostingClassifier     NaN  0.825000\n",
       "2399        2399   13     14  GradientBoostingClassifier     NaN  0.800000\n",
       "2400        2400   14      0  GradientBoostingClassifier     NaN  0.612500\n",
       "2401        2401   14      1  GradientBoostingClassifier     NaN  0.762500\n",
       "2402        2402   14      2  GradientBoostingClassifier     NaN  0.600000\n",
       "2403        2403   14      3  GradientBoostingClassifier     NaN  0.637500\n",
       "2404        2404   14      4  GradientBoostingClassifier     NaN  0.737500\n",
       "2405        2405   14      5  GradientBoostingClassifier     NaN  0.837500\n",
       "2406        2406   14      6  GradientBoostingClassifier     NaN  0.600000\n",
       "2407        2407   14      7  GradientBoostingClassifier     NaN  0.712500\n",
       "2408        2408   14      8  GradientBoostingClassifier     NaN  0.687500\n",
       "2409        2409   14      9  GradientBoostingClassifier     NaN  0.787500\n",
       "2410        2410   14     10  GradientBoostingClassifier     NaN  0.762500\n",
       "2411        2411   14     11  GradientBoostingClassifier     NaN  0.750000\n",
       "2412        2412   14     12  GradientBoostingClassifier     NaN  0.800000\n",
       "2413        2413   14     13  GradientBoostingClassifier     NaN  0.800000\n",
       "2414        2414   14     14  GradientBoostingClassifier     NaN  0.862500\n",
       "2415        2415   15      0  GradientBoostingClassifier     NaN  0.662500\n",
       "2416        2416   15      1  GradientBoostingClassifier     NaN  0.662500\n",
       "2417        2417   15      2  GradientBoostingClassifier     NaN  0.625000\n",
       "2418        2418   15      3  GradientBoostingClassifier     NaN  0.687500\n",
       "2419        2419   15      4  GradientBoostingClassifier     NaN  0.837500\n",
       "2420        2420   15      5  GradientBoostingClassifier     NaN  0.650000\n",
       "2421        2421   15      6  GradientBoostingClassifier     NaN  0.612500\n",
       "2422        2422   15      7  GradientBoostingClassifier     NaN  0.662500\n",
       "2423        2423   15      8  GradientBoostingClassifier     NaN  0.750000\n",
       "2424        2424   15      9  GradientBoostingClassifier     NaN  0.737500\n",
       "2425        2425   15     10  GradientBoostingClassifier     NaN  0.762500\n",
       "2426        2426   15     11  GradientBoostingClassifier     NaN  0.737500\n",
       "2427        2427   15     12  GradientBoostingClassifier     NaN  0.787500\n",
       "2428        2428   15     13  GradientBoostingClassifier     NaN  0.812500\n",
       "2429        2429   15     14  GradientBoostingClassifier     NaN  0.837500\n",
       "2430        2430   16      0  GradientBoostingClassifier     NaN  0.537500\n",
       "2431        2431   16      1  GradientBoostingClassifier     NaN  0.612500\n",
       "2432        2432   16      2  GradientBoostingClassifier     NaN  0.612500\n",
       "2433        2433   16      3  GradientBoostingClassifier     NaN  0.612500\n",
       "2434        2434   16      4  GradientBoostingClassifier     NaN  0.612500\n",
       "2435        2435   16      5  GradientBoostingClassifier     NaN  0.650000\n",
       "2436        2436   16      6  GradientBoostingClassifier     NaN  0.700000\n",
       "2437        2437   16      7  GradientBoostingClassifier     NaN  0.525000\n",
       "2438        2438   16      8  GradientBoostingClassifier     NaN  0.512500\n",
       "2439        2439   16      9  GradientBoostingClassifier     NaN  0.725000\n",
       "2440        2440   16     10  GradientBoostingClassifier     NaN  0.712500\n",
       "2441        2441   16     11  GradientBoostingClassifier     NaN  0.712500\n",
       "2442        2442   16     12  GradientBoostingClassifier     NaN  0.687500\n",
       "2443        2443   16     13  GradientBoostingClassifier     NaN  0.700000\n",
       "2444        2444   16     14  GradientBoostingClassifier     NaN  0.762500\n",
       "2445        2445   17      0  GradientBoostingClassifier     NaN  0.675000\n",
       "2446        2446   17      1  GradientBoostingClassifier     NaN  0.675000\n",
       "2447        2447   17      2  GradientBoostingClassifier     NaN  0.687500\n",
       "2448        2448   17      3  GradientBoostingClassifier     NaN  0.700000\n",
       "2449        2449   17      4  GradientBoostingClassifier     NaN  0.662500\n",
       "2450        2450   17      5  GradientBoostingClassifier     NaN  0.750000\n",
       "2451        2451   17      6  GradientBoostingClassifier     NaN  0.725000\n",
       "2452        2452   17      7  GradientBoostingClassifier     NaN  0.725000\n",
       "2453        2453   17      8  GradientBoostingClassifier     NaN  0.725000\n",
       "2454        2454   17      9  GradientBoostingClassifier     NaN  0.675000\n",
       "2455        2455   17     10  GradientBoostingClassifier     NaN  0.725000\n",
       "2456        2456   17     11  GradientBoostingClassifier     NaN  0.762500\n",
       "2457        2457   17     12  GradientBoostingClassifier     NaN  0.725000\n",
       "2458        2458   17     13  GradientBoostingClassifier     NaN  0.812500\n",
       "2459        2459   17     14  GradientBoostingClassifier     NaN  0.787500\n",
       "2460        2460   WC      0  GradientBoostingClassifier     NaN  0.550000\n",
       "2461        2461   WC      1  GradientBoostingClassifier     NaN  0.600000\n",
       "2462        2462   WC      2  GradientBoostingClassifier     NaN  0.650000\n",
       "2463        2463   WC      3  GradientBoostingClassifier     NaN  0.500000\n",
       "2464        2464   WC      4  GradientBoostingClassifier     NaN  0.600000\n",
       "2465        2465   WC      5  GradientBoostingClassifier     NaN  0.650000\n",
       "2466        2466   WC      6  GradientBoostingClassifier     NaN  0.700000\n",
       "2467        2467   WC      7  GradientBoostingClassifier     NaN  0.550000\n",
       "2468        2468   WC      8  GradientBoostingClassifier     NaN  0.450000\n",
       "2469        2469   WC      9  GradientBoostingClassifier     NaN  0.600000\n",
       "2470        2470   WC     10  GradientBoostingClassifier     NaN  0.800000\n",
       "2471        2471   WC     11  GradientBoostingClassifier     NaN  0.700000\n",
       "2472        2472   WC     12  GradientBoostingClassifier     NaN  0.550000\n",
       "2473        2473   WC     13  GradientBoostingClassifier     NaN  0.700000\n",
       "2474        2474   WC     14  GradientBoostingClassifier     NaN  0.750000\n",
       "2475        2475   DV      0  GradientBoostingClassifier     NaN  0.750000\n",
       "2476        2476   DV      1  GradientBoostingClassifier     NaN  0.500000\n",
       "2477        2477   DV      2  GradientBoostingClassifier     NaN  0.450000\n",
       "2478        2478   DV      3  GradientBoostingClassifier     NaN  0.550000\n",
       "2479        2479   DV      4  GradientBoostingClassifier     NaN  0.600000\n",
       "2480        2480   DV      5  GradientBoostingClassifier     NaN  0.500000\n",
       "2481        2481   DV      6  GradientBoostingClassifier     NaN  0.350000\n",
       "2482        2482   DV      7  GradientBoostingClassifier     NaN  0.650000\n",
       "2483        2483   DV      8  GradientBoostingClassifier     NaN  0.550000\n",
       "2484        2484   DV      9  GradientBoostingClassifier     NaN  0.400000\n",
       "2485        2485   DV     10  GradientBoostingClassifier     NaN  0.550000\n",
       "2486        2486   DV     11  GradientBoostingClassifier     NaN  0.550000\n",
       "2487        2487   DV     12  GradientBoostingClassifier     NaN  0.550000\n",
       "2488        2488   DV     13  GradientBoostingClassifier     NaN  0.500000\n",
       "2489        2489   DV     14  GradientBoostingClassifier     NaN  0.450000\n",
       "2490        2490   CC      0  GradientBoostingClassifier     NaN  0.400000\n",
       "2491        2491   CC      1  GradientBoostingClassifier     NaN  0.500000\n",
       "2492        2492   CC      2  GradientBoostingClassifier     NaN  0.500000\n",
       "2493        2493   CC      3  GradientBoostingClassifier     NaN  0.400000\n",
       "2494        2494   CC      4  GradientBoostingClassifier     NaN  0.500000\n",
       "2495        2495   CC      5  GradientBoostingClassifier     NaN  0.700000\n",
       "2496        2496   CC      6  GradientBoostingClassifier     NaN  0.300000\n",
       "2497        2497   CC      7  GradientBoostingClassifier     NaN  0.500000\n",
       "2498        2498   CC      8  GradientBoostingClassifier     NaN  0.500000\n",
       "2499        2499   CC      9  GradientBoostingClassifier     NaN  0.600000\n",
       "2500        2500   CC     10  GradientBoostingClassifier     NaN  0.500000\n",
       "2501        2501   CC     11  GradientBoostingClassifier     NaN  0.500000\n",
       "2502        2502   CC     12  GradientBoostingClassifier     NaN  0.400000\n",
       "2503        2503   CC     13  GradientBoostingClassifier     NaN  0.400000\n",
       "2504        2504   CC     14  GradientBoostingClassifier     NaN  0.400000\n",
       "2505        2505   SB      0  GradientBoostingClassifier     NaN  0.400000\n",
       "2506        2506   SB      1  GradientBoostingClassifier     NaN  0.400000\n",
       "2507        2507   SB      2  GradientBoostingClassifier     NaN  0.600000\n",
       "2508        2508   SB      3  GradientBoostingClassifier     NaN  0.600000\n",
       "2509        2509   SB      4  GradientBoostingClassifier     NaN  0.400000\n",
       "2510        2510   SB      5  GradientBoostingClassifier     NaN  0.400000\n",
       "2511        2511   SB      6  GradientBoostingClassifier     NaN  0.600000\n",
       "2512        2512   SB      7  GradientBoostingClassifier     NaN  0.600000\n",
       "2513        2513   SB      8  GradientBoostingClassifier     NaN  0.600000\n",
       "2514        2514   SB      9  GradientBoostingClassifier     NaN  0.600000\n",
       "2515        2515   SB     10  GradientBoostingClassifier     NaN  0.400000\n",
       "2516        2516   SB     11  GradientBoostingClassifier     NaN  0.600000\n",
       "2517        2517   SB     12  GradientBoostingClassifier     NaN  0.600000\n",
       "2518        2518   SB     13  GradientBoostingClassifier     NaN  0.400000\n",
       "2519        2519   SB     14  GradientBoostingClassifier     NaN  0.600000\n",
       "2520        2520    1      0        NaiveBayesClassifier     NaN  0.612500\n",
       "2521        2521    1      1        NaiveBayesClassifier     NaN  0.675000\n",
       "2522        2522    1      2        NaiveBayesClassifier     NaN  0.762500\n",
       "2523        2523    1      3        NaiveBayesClassifier     NaN  0.637500\n",
       "2524        2524    1      4        NaiveBayesClassifier     NaN  0.687500\n",
       "2525        2525    1      5        NaiveBayesClassifier     NaN  0.775000\n",
       "2526        2526    1      6        NaiveBayesClassifier     NaN  0.762500\n",
       "2527        2527    1      7        NaiveBayesClassifier     NaN  0.787500\n",
       "2528        2528    1      8        NaiveBayesClassifier     NaN  0.687500\n",
       "2529        2529    1      9        NaiveBayesClassifier     NaN  0.725000\n",
       "2530        2530    1     10        NaiveBayesClassifier     NaN  0.800000\n",
       "2531        2531    1     11        NaiveBayesClassifier     NaN  0.712500\n",
       "2532        2532    1     12        NaiveBayesClassifier     NaN  0.725000\n",
       "2533        2533    1     13        NaiveBayesClassifier     NaN  0.837500\n",
       "2534        2534    1     14        NaiveBayesClassifier     NaN  0.862500\n",
       "2535        2535    2      0        NaiveBayesClassifier     NaN  0.645570\n",
       "2536        2536    2      1        NaiveBayesClassifier     NaN  0.569620\n",
       "2537        2537    2      2        NaiveBayesClassifier     NaN  0.670886\n",
       "2538        2538    2      3        NaiveBayesClassifier     NaN  0.620253\n",
       "2539        2539    2      4        NaiveBayesClassifier     NaN  0.658228\n",
       "2540        2540    2      5        NaiveBayesClassifier     NaN  0.696203\n",
       "2541        2541    2      6        NaiveBayesClassifier     NaN  0.670886\n",
       "2542        2542    2      7        NaiveBayesClassifier     NaN  0.658228\n",
       "2543        2543    2      8        NaiveBayesClassifier     NaN  0.670886\n",
       "2544        2544    2      9        NaiveBayesClassifier     NaN  0.670886\n",
       "2545        2545    2     10        NaiveBayesClassifier     NaN  0.721519\n",
       "2546        2546    2     11        NaiveBayesClassifier     NaN  0.784810\n",
       "2547        2547    2     12        NaiveBayesClassifier     NaN  0.721519\n",
       "2548        2548    2     13        NaiveBayesClassifier     NaN  0.784810\n",
       "2549        2549    2     14        NaiveBayesClassifier     NaN  0.797468\n",
       "2550        2550    3      0        NaiveBayesClassifier     NaN  0.571429\n",
       "2551        2551    3      1        NaiveBayesClassifier     NaN  0.636364\n",
       "2552        2552    3      2        NaiveBayesClassifier     NaN  0.623377\n",
       "2553        2553    3      3        NaiveBayesClassifier     NaN  0.610390\n",
       "2554        2554    3      4        NaiveBayesClassifier     NaN  0.727273\n",
       "2555        2555    3      5        NaiveBayesClassifier     NaN  0.688312\n",
       "2556        2556    3      6        NaiveBayesClassifier     NaN  0.662338\n",
       "2557        2557    3      7        NaiveBayesClassifier     NaN  0.727273\n",
       "2558        2558    3      8        NaiveBayesClassifier     NaN  0.701299\n",
       "2559        2559    3      9        NaiveBayesClassifier     NaN  0.662338\n",
       "2560        2560    3     10        NaiveBayesClassifier     NaN  0.792208\n",
       "2561        2561    3     11        NaiveBayesClassifier     NaN  0.766234\n",
       "2562        2562    3     12        NaiveBayesClassifier     NaN  0.766234\n",
       "2563        2563    3     13        NaiveBayesClassifier     NaN  0.740260\n",
       "2564        2564    3     14        NaiveBayesClassifier     NaN  0.818182\n",
       "2565        2565    4      0        NaiveBayesClassifier     NaN  0.657534\n",
       "2566        2566    4      1        NaiveBayesClassifier     NaN  0.671233\n",
       "2567        2567    4      2        NaiveBayesClassifier     NaN  0.616438\n",
       "2568        2568    4      3        NaiveBayesClassifier     NaN  0.452055\n",
       "2569        2569    4      4        NaiveBayesClassifier     NaN  0.739726\n",
       "2570        2570    4      5        NaiveBayesClassifier     NaN  0.657534\n",
       "2571        2571    4      6        NaiveBayesClassifier     NaN  0.630137\n",
       "2572        2572    4      7        NaiveBayesClassifier     NaN  0.726027\n",
       "2573        2573    4      8        NaiveBayesClassifier     NaN  0.684932\n",
       "2574        2574    4      9        NaiveBayesClassifier     NaN  0.698630\n",
       "2575        2575    4     10        NaiveBayesClassifier     NaN  0.739726\n",
       "2576        2576    4     11        NaiveBayesClassifier     NaN  0.712329\n",
       "2577        2577    4     12        NaiveBayesClassifier     NaN  0.808219\n",
       "2578        2578    4     13        NaiveBayesClassifier     NaN  0.739726\n",
       "2579        2579    4     14        NaiveBayesClassifier     NaN  0.821918\n",
       "2580        2580    5      0        NaiveBayesClassifier     NaN  0.563380\n",
       "2581        2581    5      1        NaiveBayesClassifier     NaN  0.704225\n",
       "2582        2582    5      2        NaiveBayesClassifier     NaN  0.718310\n",
       "2583        2583    5      3        NaiveBayesClassifier     NaN  0.605634\n",
       "2584        2584    5      4        NaiveBayesClassifier     NaN  0.591549\n",
       "2585        2585    5      5        NaiveBayesClassifier     NaN  0.704225\n",
       "2586        2586    5      6        NaiveBayesClassifier     NaN  0.633803\n",
       "2587        2587    5      7        NaiveBayesClassifier     NaN  0.605634\n",
       "2588        2588    5      8        NaiveBayesClassifier     NaN  0.690141\n",
       "2589        2589    5      9        NaiveBayesClassifier     NaN  0.619718\n",
       "2590        2590    5     10        NaiveBayesClassifier     NaN  0.704225\n",
       "2591        2591    5     11        NaiveBayesClassifier     NaN  0.718310\n",
       "2592        2592    5     12        NaiveBayesClassifier     NaN  0.690141\n",
       "2593        2593    5     13        NaiveBayesClassifier     NaN  0.732394\n",
       "2594        2594    5     14        NaiveBayesClassifier     NaN  0.690141\n",
       "2595        2595    6      0        NaiveBayesClassifier     NaN  0.471429\n",
       "2596        2596    6      1        NaiveBayesClassifier     NaN  0.614286\n",
       "2597        2597    6      2        NaiveBayesClassifier     NaN  0.542857\n",
       "2598        2598    6      3        NaiveBayesClassifier     NaN  0.571429\n",
       "2599        2599    6      4        NaiveBayesClassifier     NaN  0.671429\n",
       "2600        2600    6      5        NaiveBayesClassifier     NaN  0.657143\n",
       "2601        2601    6      6        NaiveBayesClassifier     NaN  0.642857\n",
       "2602        2602    6      7        NaiveBayesClassifier     NaN  0.671429\n",
       "2603        2603    6      8        NaiveBayesClassifier     NaN  0.571429\n",
       "2604        2604    6      9        NaiveBayesClassifier     NaN  0.557143\n",
       "2605        2605    6     10        NaiveBayesClassifier     NaN  0.671429\n",
       "2606        2606    6     11        NaiveBayesClassifier     NaN  0.671429\n",
       "2607        2607    6     12        NaiveBayesClassifier     NaN  0.600000\n",
       "2608        2608    6     13        NaiveBayesClassifier     NaN  0.657143\n",
       "2609        2609    6     14        NaiveBayesClassifier     NaN  0.728571\n",
       "2610        2610    7      0        NaiveBayesClassifier     NaN  0.785714\n",
       "2611        2611    7      1        NaiveBayesClassifier     NaN  0.671429\n",
       "2612        2612    7      2        NaiveBayesClassifier     NaN  0.757143\n",
       "2613        2613    7      3        NaiveBayesClassifier     NaN  0.585714\n",
       "2614        2614    7      4        NaiveBayesClassifier     NaN  0.714286\n",
       "2615        2615    7      5        NaiveBayesClassifier     NaN  0.728571\n",
       "2616        2616    7      6        NaiveBayesClassifier     NaN  0.742857\n",
       "2617        2617    7      7        NaiveBayesClassifier     NaN  0.842857\n",
       "2618        2618    7      8        NaiveBayesClassifier     NaN  0.728571\n",
       "2619        2619    7      9        NaiveBayesClassifier     NaN  0.685714\n",
       "2620        2620    7     10        NaiveBayesClassifier     NaN  0.828571\n",
       "2621        2621    7     11        NaiveBayesClassifier     NaN  0.814286\n",
       "2622        2622    7     12        NaiveBayesClassifier     NaN  0.757143\n",
       "2623        2623    7     13        NaiveBayesClassifier     NaN  0.814286\n",
       "2624        2624    7     14        NaiveBayesClassifier     NaN  0.857143\n",
       "2625        2625    8      0        NaiveBayesClassifier     NaN  0.724638\n",
       "2626        2626    8      1        NaiveBayesClassifier     NaN  0.623188\n",
       "2627        2627    8      2        NaiveBayesClassifier     NaN  0.724638\n",
       "2628        2628    8      3        NaiveBayesClassifier     NaN  0.623188\n",
       "2629        2629    8      4        NaiveBayesClassifier     NaN  0.739130\n",
       "2630        2630    8      5        NaiveBayesClassifier     NaN  0.768116\n",
       "2631        2631    8      6        NaiveBayesClassifier     NaN  0.782609\n",
       "2632        2632    8      7        NaiveBayesClassifier     NaN  0.739130\n",
       "2633        2633    8      8        NaiveBayesClassifier     NaN  0.768116\n",
       "2634        2634    8      9        NaiveBayesClassifier     NaN  0.753623\n",
       "2635        2635    8     10        NaiveBayesClassifier     NaN  0.768116\n",
       "2636        2636    8     11        NaiveBayesClassifier     NaN  0.797101\n",
       "2637        2637    8     12        NaiveBayesClassifier     NaN  0.797101\n",
       "2638        2638    8     13        NaiveBayesClassifier     NaN  0.782609\n",
       "2639        2639    8     14        NaiveBayesClassifier     NaN  0.869565\n",
       "2640        2640    9      0        NaiveBayesClassifier     NaN  0.608696\n",
       "2641        2641    9      1        NaiveBayesClassifier     NaN  0.550725\n",
       "2642        2642    9      2        NaiveBayesClassifier     NaN  0.652174\n",
       "2643        2643    9      3        NaiveBayesClassifier     NaN  0.666667\n",
       "2644        2644    9      4        NaiveBayesClassifier     NaN  0.666667\n",
       "2645        2645    9      5        NaiveBayesClassifier     NaN  0.681159\n",
       "2646        2646    9      6        NaiveBayesClassifier     NaN  0.710145\n",
       "2647        2647    9      7        NaiveBayesClassifier     NaN  0.666667\n",
       "2648        2648    9      8        NaiveBayesClassifier     NaN  0.652174\n",
       "2649        2649    9      9        NaiveBayesClassifier     NaN  0.681159\n",
       "2650        2650    9     10        NaiveBayesClassifier     NaN  0.666667\n",
       "2651        2651    9     11        NaiveBayesClassifier     NaN  0.681159\n",
       "2652        2652    9     12        NaiveBayesClassifier     NaN  0.710145\n",
       "2653        2653    9     13        NaiveBayesClassifier     NaN  0.739130\n",
       "2654        2654    9     14        NaiveBayesClassifier     NaN  0.797101\n",
       "2655        2655   10      0        NaiveBayesClassifier     NaN  0.625000\n",
       "2656        2656   10      1        NaiveBayesClassifier     NaN  0.638889\n",
       "2657        2657   10      2        NaiveBayesClassifier     NaN  0.583333\n",
       "2658        2658   10      3        NaiveBayesClassifier     NaN  0.625000\n",
       "2659        2659   10      4        NaiveBayesClassifier     NaN  0.722222\n",
       "2660        2660   10      5        NaiveBayesClassifier     NaN  0.652778\n",
       "2661        2661   10      6        NaiveBayesClassifier     NaN  0.652778\n",
       "2662        2662   10      7        NaiveBayesClassifier     NaN  0.722222\n",
       "2663        2663   10      8        NaiveBayesClassifier     NaN  0.736111\n",
       "2664        2664   10      9        NaiveBayesClassifier     NaN  0.736111\n",
       "2665        2665   10     10        NaiveBayesClassifier     NaN  0.750000\n",
       "2666        2666   10     11        NaiveBayesClassifier     NaN  0.763889\n",
       "2667        2667   10     12        NaiveBayesClassifier     NaN  0.805556\n",
       "2668        2668   10     13        NaiveBayesClassifier     NaN  0.736111\n",
       "2669        2669   10     14        NaiveBayesClassifier     NaN  0.875000\n",
       "2670        2670   11      0        NaiveBayesClassifier     NaN  0.693333\n",
       "2671        2671   11      1        NaiveBayesClassifier     NaN  0.706667\n",
       "2672        2672   11      2        NaiveBayesClassifier     NaN  0.693333\n",
       "2673        2673   11      3        NaiveBayesClassifier     NaN  0.586667\n",
       "2674        2674   11      4        NaiveBayesClassifier     NaN  0.773333\n",
       "2675        2675   11      5        NaiveBayesClassifier     NaN  0.800000\n",
       "2676        2676   11      6        NaiveBayesClassifier     NaN  0.733333\n",
       "2677        2677   11      7        NaiveBayesClassifier     NaN  0.773333\n",
       "2678        2678   11      8        NaiveBayesClassifier     NaN  0.786667\n",
       "2679        2679   11      9        NaiveBayesClassifier     NaN  0.746667\n",
       "2680        2680   11     10        NaiveBayesClassifier     NaN  0.840000\n",
       "2681        2681   11     11        NaiveBayesClassifier     NaN  0.813333\n",
       "2682        2682   11     12        NaiveBayesClassifier     NaN  0.853333\n",
       "2683        2683   11     13        NaiveBayesClassifier     NaN  0.746667\n",
       "2684        2684   11     14        NaiveBayesClassifier     NaN  0.893333\n",
       "2685        2685   12      0        NaiveBayesClassifier     NaN  0.602564\n",
       "2686        2686   12      1        NaiveBayesClassifier     NaN  0.551282\n",
       "2687        2687   12      2        NaiveBayesClassifier     NaN  0.628205\n",
       "2688        2688   12      3        NaiveBayesClassifier     NaN  0.589744\n",
       "2689        2689   12      4        NaiveBayesClassifier     NaN  0.705128\n",
       "2690        2690   12      5        NaiveBayesClassifier     NaN  0.705128\n",
       "2691        2691   12      6        NaiveBayesClassifier     NaN  0.717949\n",
       "2692        2692   12      7        NaiveBayesClassifier     NaN  0.641026\n",
       "2693        2693   12      8        NaiveBayesClassifier     NaN  0.589744\n",
       "2694        2694   12      9        NaiveBayesClassifier     NaN  0.666667\n",
       "2695        2695   12     10        NaiveBayesClassifier     NaN  0.692308\n",
       "2696        2696   12     11        NaiveBayesClassifier     NaN  0.730769\n",
       "2697        2697   12     12        NaiveBayesClassifier     NaN  0.653846\n",
       "2698        2698   12     13        NaiveBayesClassifier     NaN  0.794872\n",
       "2699        2699   12     14        NaiveBayesClassifier     NaN  0.769231\n",
       "2700        2700   13      0        NaiveBayesClassifier     NaN  0.575000\n",
       "2701        2701   13      1        NaiveBayesClassifier     NaN  0.762500\n",
       "2702        2702   13      2        NaiveBayesClassifier     NaN  0.612500\n",
       "2703        2703   13      3        NaiveBayesClassifier     NaN  0.675000\n",
       "2704        2704   13      4        NaiveBayesClassifier     NaN  0.775000\n",
       "2705        2705   13      5        NaiveBayesClassifier     NaN  0.762500\n",
       "2706        2706   13      6        NaiveBayesClassifier     NaN  0.700000\n",
       "2707        2707   13      7        NaiveBayesClassifier     NaN  0.675000\n",
       "2708        2708   13      8        NaiveBayesClassifier     NaN  0.662500\n",
       "2709        2709   13      9        NaiveBayesClassifier     NaN  0.812500\n",
       "2710        2710   13     10        NaiveBayesClassifier     NaN  0.800000\n",
       "2711        2711   13     11        NaiveBayesClassifier     NaN  0.700000\n",
       "2712        2712   13     12        NaiveBayesClassifier     NaN  0.775000\n",
       "2713        2713   13     13        NaiveBayesClassifier     NaN  0.837500\n",
       "2714        2714   13     14        NaiveBayesClassifier     NaN  0.800000\n",
       "2715        2715   14      0        NaiveBayesClassifier     NaN  0.612500\n",
       "2716        2716   14      1        NaiveBayesClassifier     NaN  0.762500\n",
       "2717        2717   14      2        NaiveBayesClassifier     NaN  0.600000\n",
       "2718        2718   14      3        NaiveBayesClassifier     NaN  0.637500\n",
       "2719        2719   14      4        NaiveBayesClassifier     NaN  0.737500\n",
       "2720        2720   14      5        NaiveBayesClassifier     NaN  0.837500\n",
       "2721        2721   14      6        NaiveBayesClassifier     NaN  0.625000\n",
       "2722        2722   14      7        NaiveBayesClassifier     NaN  0.775000\n",
       "2723        2723   14      8        NaiveBayesClassifier     NaN  0.725000\n",
       "2724        2724   14      9        NaiveBayesClassifier     NaN  0.762500\n",
       "2725        2725   14     10        NaiveBayesClassifier     NaN  0.825000\n",
       "2726        2726   14     11        NaiveBayesClassifier     NaN  0.725000\n",
       "2727        2727   14     12        NaiveBayesClassifier     NaN  0.812500\n",
       "2728        2728   14     13        NaiveBayesClassifier     NaN  0.775000\n",
       "2729        2729   14     14        NaiveBayesClassifier     NaN  0.875000\n",
       "2730        2730   15      0        NaiveBayesClassifier     NaN  0.662500\n",
       "2731        2731   15      1        NaiveBayesClassifier     NaN  0.662500\n",
       "2732        2732   15      2        NaiveBayesClassifier     NaN  0.625000\n",
       "2733        2733   15      3        NaiveBayesClassifier     NaN  0.687500\n",
       "2734        2734   15      4        NaiveBayesClassifier     NaN  0.837500\n",
       "2735        2735   15      5        NaiveBayesClassifier     NaN  0.675000\n",
       "2736        2736   15      6        NaiveBayesClassifier     NaN  0.612500\n",
       "2737        2737   15      7        NaiveBayesClassifier     NaN  0.725000\n",
       "2738        2738   15      8        NaiveBayesClassifier     NaN  0.787500\n",
       "2739        2739   15      9        NaiveBayesClassifier     NaN  0.775000\n",
       "2740        2740   15     10        NaiveBayesClassifier     NaN  0.762500\n",
       "2741        2741   15     11        NaiveBayesClassifier     NaN  0.700000\n",
       "2742        2742   15     12        NaiveBayesClassifier     NaN  0.862500\n",
       "2743        2743   15     13        NaiveBayesClassifier     NaN  0.750000\n",
       "2744        2744   15     14        NaiveBayesClassifier     NaN  0.812500\n",
       "2745        2745   16      0        NaiveBayesClassifier     NaN  0.537500\n",
       "2746        2746   16      1        NaiveBayesClassifier     NaN  0.612500\n",
       "2747        2747   16      2        NaiveBayesClassifier     NaN  0.612500\n",
       "2748        2748   16      3        NaiveBayesClassifier     NaN  0.612500\n",
       "2749        2749   16      4        NaiveBayesClassifier     NaN  0.650000\n",
       "2750        2750   16      5        NaiveBayesClassifier     NaN  0.650000\n",
       "2751        2751   16      6        NaiveBayesClassifier     NaN  0.700000\n",
       "2752        2752   16      7        NaiveBayesClassifier     NaN  0.587500\n",
       "2753        2753   16      8        NaiveBayesClassifier     NaN  0.600000\n",
       "2754        2754   16      9        NaiveBayesClassifier     NaN  0.662500\n",
       "2755        2755   16     10        NaiveBayesClassifier     NaN  0.687500\n",
       "2756        2756   16     11        NaiveBayesClassifier     NaN  0.712500\n",
       "2757        2757   16     12        NaiveBayesClassifier     NaN  0.712500\n",
       "2758        2758   16     13        NaiveBayesClassifier     NaN  0.725000\n",
       "2759        2759   16     14        NaiveBayesClassifier     NaN  0.750000\n",
       "2760        2760   17      0        NaiveBayesClassifier     NaN  0.675000\n",
       "2761        2761   17      1        NaiveBayesClassifier     NaN  0.675000\n",
       "2762        2762   17      2        NaiveBayesClassifier     NaN  0.687500\n",
       "2763        2763   17      3        NaiveBayesClassifier     NaN  0.625000\n",
       "2764        2764   17      4        NaiveBayesClassifier     NaN  0.687500\n",
       "2765        2765   17      5        NaiveBayesClassifier     NaN  0.725000\n",
       "2766        2766   17      6        NaiveBayesClassifier     NaN  0.725000\n",
       "2767        2767   17      7        NaiveBayesClassifier     NaN  0.750000\n",
       "2768        2768   17      8        NaiveBayesClassifier     NaN  0.700000\n",
       "2769        2769   17      9        NaiveBayesClassifier     NaN  0.675000\n",
       "2770        2770   17     10        NaiveBayesClassifier     NaN  0.812500\n",
       "2771        2771   17     11        NaiveBayesClassifier     NaN  0.825000\n",
       "2772        2772   17     12        NaiveBayesClassifier     NaN  0.775000\n",
       "2773        2773   17     13        NaiveBayesClassifier     NaN  0.762500\n",
       "2774        2774   17     14        NaiveBayesClassifier     NaN  0.900000\n",
       "2775        2775   WC      0        NaiveBayesClassifier     NaN  0.550000\n",
       "2776        2776   WC      1        NaiveBayesClassifier     NaN  0.600000\n",
       "2777        2777   WC      2        NaiveBayesClassifier     NaN  0.650000\n",
       "2778        2778   WC      3        NaiveBayesClassifier     NaN  0.500000\n",
       "2779        2779   WC      4        NaiveBayesClassifier     NaN  0.650000\n",
       "2780        2780   WC      5        NaiveBayesClassifier     NaN  0.700000\n",
       "2781        2781   WC      6        NaiveBayesClassifier     NaN  0.700000\n",
       "2782        2782   WC      7        NaiveBayesClassifier     NaN  0.650000\n",
       "2783        2783   WC      8        NaiveBayesClassifier     NaN  0.450000\n",
       "2784        2784   WC      9        NaiveBayesClassifier     NaN  0.650000\n",
       "2785        2785   WC     10        NaiveBayesClassifier     NaN  0.700000\n",
       "2786        2786   WC     11        NaiveBayesClassifier     NaN  0.700000\n",
       "2787        2787   WC     12        NaiveBayesClassifier     NaN  0.600000\n",
       "2788        2788   WC     13        NaiveBayesClassifier     NaN  0.750000\n",
       "2789        2789   WC     14        NaiveBayesClassifier     NaN  0.700000\n",
       "2790        2790   DV      0        NaiveBayesClassifier     NaN  0.700000\n",
       "2791        2791   DV      1        NaiveBayesClassifier     NaN  0.500000\n",
       "2792        2792   DV      2        NaiveBayesClassifier     NaN  0.450000\n",
       "2793        2793   DV      3        NaiveBayesClassifier     NaN  0.550000\n",
       "2794        2794   DV      4        NaiveBayesClassifier     NaN  0.650000\n",
       "2795        2795   DV      5        NaiveBayesClassifier     NaN  0.500000\n",
       "2796        2796   DV      6        NaiveBayesClassifier     NaN  0.500000\n",
       "2797        2797   DV      7        NaiveBayesClassifier     NaN  0.500000\n",
       "2798        2798   DV      8        NaiveBayesClassifier     NaN  0.650000\n",
       "2799        2799   DV      9        NaiveBayesClassifier     NaN  0.500000\n",
       "2800        2800   DV     10        NaiveBayesClassifier     NaN  0.550000\n",
       "2801        2801   DV     11        NaiveBayesClassifier     NaN  0.550000\n",
       "2802        2802   DV     12        NaiveBayesClassifier     NaN  0.650000\n",
       "2803        2803   DV     13        NaiveBayesClassifier     NaN  0.550000\n",
       "2804        2804   DV     14        NaiveBayesClassifier     NaN  0.600000\n",
       "2805        2805   CC      0        NaiveBayesClassifier     NaN  0.500000\n",
       "2806        2806   CC      1        NaiveBayesClassifier     NaN  0.500000\n",
       "2807        2807   CC      2        NaiveBayesClassifier     NaN  0.500000\n",
       "2808        2808   CC      3        NaiveBayesClassifier     NaN  0.500000\n",
       "2809        2809   CC      4        NaiveBayesClassifier     NaN  0.500000\n",
       "2810        2810   CC      5        NaiveBayesClassifier     NaN  0.500000\n",
       "2811        2811   CC      6        NaiveBayesClassifier     NaN  0.500000\n",
       "2812        2812   CC      7        NaiveBayesClassifier     NaN  0.500000\n",
       "2813        2813   CC      8        NaiveBayesClassifier     NaN  0.500000\n",
       "2814        2814   CC      9        NaiveBayesClassifier     NaN  0.600000\n",
       "2815        2815   CC     10        NaiveBayesClassifier     NaN  0.500000\n",
       "2816        2816   CC     11        NaiveBayesClassifier     NaN  0.500000\n",
       "2817        2817   CC     12        NaiveBayesClassifier     NaN  0.500000\n",
       "2818        2818   CC     13        NaiveBayesClassifier     NaN  0.600000\n",
       "2819        2819   CC     14        NaiveBayesClassifier     NaN  0.500000\n",
       "2820        2820   SB      0        NaiveBayesClassifier     NaN  0.400000\n",
       "2821        2821   SB      1        NaiveBayesClassifier     NaN  0.400000\n",
       "2822        2822   SB      2        NaiveBayesClassifier     NaN  0.600000\n",
       "2823        2823   SB      3        NaiveBayesClassifier     NaN  0.600000\n",
       "2824        2824   SB      4        NaiveBayesClassifier     NaN  0.600000\n",
       "2825        2825   SB      5        NaiveBayesClassifier     NaN  0.400000\n",
       "2826        2826   SB      6        NaiveBayesClassifier     NaN  0.600000\n",
       "2827        2827   SB      7        NaiveBayesClassifier     NaN  0.600000\n",
       "2828        2828   SB      8        NaiveBayesClassifier     NaN  0.400000\n",
       "2829        2829   SB      9        NaiveBayesClassifier     NaN  0.400000\n",
       "2830        2830   SB     10        NaiveBayesClassifier     NaN  0.600000\n",
       "2831        2831   SB     11        NaiveBayesClassifier     NaN  0.600000\n",
       "2832        2832   SB     12        NaiveBayesClassifier     NaN  0.400000\n",
       "2833        2833   SB     13        NaiveBayesClassifier     NaN  0.400000\n",
       "2834        2834   SB     14        NaiveBayesClassifier     NaN  0.400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in weekly data\n",
    "weekly = pd.read_csv('data/Weekly_Quarter_Combos_Modeling_Results.csv')\n",
    "weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b4d5cb-cae7-4cbc-b99b-9dbe96cac8dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-2f31cf3c9ceb>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  x = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week</th>\n",
       "      <th>Clump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.737500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">10</th>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.736111</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.736111</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.763889</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">11</th>\n",
       "      <th>0</th>\n",
       "      <td>0.693333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.706667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.693333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.826667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.773333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.853333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.826667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.853333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.906667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">12</th>\n",
       "      <th>0</th>\n",
       "      <td>0.602564</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705128</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.679487</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.743590</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">13</th>\n",
       "      <th>0</th>\n",
       "      <td>0.587500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.737500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">14</th>\n",
       "      <th>0</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.737500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">15</th>\n",
       "      <th>0</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.837500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.862500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">16</th>\n",
       "      <th>0</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.587500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">17</th>\n",
       "      <th>0</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.658228</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620253</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.696203</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620253</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.696203</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708861</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.721519</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.658228</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.683544</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.696203</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.721519</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.810127</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.721519</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.784810</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.810127</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.610390</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740260</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.701299</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.740260</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.675325</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.792208</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.779221</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.740260</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671233</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630137</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.739726</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.726027</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.698630</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.767123</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.739726</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.808219</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.739726</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>0.563380</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.704225</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718310</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.746479</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.774648</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.887324</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <td>0.614286</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.614286</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">7</th>\n",
       "      <th>0</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.757143</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.842857</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.814286</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.871429</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">8</th>\n",
       "      <th>0</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623188</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.768116</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.753623</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.797101</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">9</th>\n",
       "      <th>0</th>\n",
       "      <td>0.623188</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753623</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.710145</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.681159</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.710145</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.753623</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.840580</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">CC</th>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">DV</th>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">SB</th>\n",
       "      <th>0</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">WC</th>\n",
       "      <th>0</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy               Estimator\n",
       "Week Clump                                  \n",
       "1    0      0.650000  RandomForestClassifier\n",
       "     1      0.675000  RandomForestClassifier\n",
       "     2      0.762500  RandomForestClassifier\n",
       "     3      0.637500  RandomForestClassifier\n",
       "     4      0.700000  RandomForestClassifier\n",
       "     5      0.787500  RandomForestClassifier\n",
       "     6      0.762500  RandomForestClassifier\n",
       "     7      0.787500  RandomForestClassifier\n",
       "     8      0.687500  RandomForestClassifier\n",
       "     9      0.737500  RandomForestClassifier\n",
       "     10     0.800000  RandomForestClassifier\n",
       "     11     0.787500  RandomForestClassifier\n",
       "     12     0.762500  RandomForestClassifier\n",
       "     13     0.837500  RandomForestClassifier\n",
       "     14     0.875000  RandomForestClassifier\n",
       "10   0      0.666667  RandomForestClassifier\n",
       "     1      0.638889  RandomForestClassifier\n",
       "     2      0.583333  RandomForestClassifier\n",
       "     3      0.625000  RandomForestClassifier\n",
       "     4      0.722222  RandomForestClassifier\n",
       "     5      0.708333  RandomForestClassifier\n",
       "     6      0.680556  RandomForestClassifier\n",
       "     7      0.722222  RandomForestClassifier\n",
       "     8      0.736111  RandomForestClassifier\n",
       "     9      0.736111  RandomForestClassifier\n",
       "     10     0.777778  RandomForestClassifier\n",
       "     11     0.777778  RandomForestClassifier\n",
       "     12     0.805556  RandomForestClassifier\n",
       "     13     0.763889  RandomForestClassifier\n",
       "     14     0.916667  RandomForestClassifier\n",
       "11   0      0.693333  RandomForestClassifier\n",
       "     1      0.706667  RandomForestClassifier\n",
       "     2      0.693333  RandomForestClassifier\n",
       "     3      0.600000  RandomForestClassifier\n",
       "     4      0.800000  RandomForestClassifier\n",
       "     5      0.826667  RandomForestClassifier\n",
       "     6      0.733333  RandomForestClassifier\n",
       "     7      0.773333  RandomForestClassifier\n",
       "     8      0.786667  RandomForestClassifier\n",
       "     9      0.760000  RandomForestClassifier\n",
       "     10     0.853333  RandomForestClassifier\n",
       "     11     0.826667  RandomForestClassifier\n",
       "     12     0.853333  RandomForestClassifier\n",
       "     13     0.786667  RandomForestClassifier\n",
       "     14     0.906667  RandomForestClassifier\n",
       "12   0      0.602564  RandomForestClassifier\n",
       "     1      0.564103  RandomForestClassifier\n",
       "     2      0.666667  RandomForestClassifier\n",
       "     3      0.589744  RandomForestClassifier\n",
       "     4      0.705128  RandomForestClassifier\n",
       "     5      0.756410  RandomForestClassifier\n",
       "     6      0.756410  RandomForestClassifier\n",
       "     7      0.666667  RandomForestClassifier\n",
       "     8      0.628205  RandomForestClassifier\n",
       "     9      0.679487  RandomForestClassifier\n",
       "     10     0.756410  RandomForestClassifier\n",
       "     11     0.730769  RandomForestClassifier\n",
       "     12     0.743590  RandomForestClassifier\n",
       "     13     0.807692  RandomForestClassifier\n",
       "     14     0.833333  RandomForestClassifier\n",
       "13   0      0.587500  RandomForestClassifier\n",
       "     1      0.762500  RandomForestClassifier\n",
       "     2      0.612500  RandomForestClassifier\n",
       "     3      0.675000  RandomForestClassifier\n",
       "     4      0.775000  RandomForestClassifier\n",
       "     5      0.787500  RandomForestClassifier\n",
       "     6      0.712500  RandomForestClassifier\n",
       "     7      0.687500  RandomForestClassifier\n",
       "     8      0.687500  RandomForestClassifier\n",
       "     9      0.825000  RandomForestClassifier\n",
       "     10     0.800000  RandomForestClassifier\n",
       "     11     0.737500  RandomForestClassifier\n",
       "     12     0.825000  RandomForestClassifier\n",
       "     13     0.837500  RandomForestClassifier\n",
       "     14     0.812500  RandomForestClassifier\n",
       "14   0      0.687500  RandomForestClassifier\n",
       "     1      0.762500  RandomForestClassifier\n",
       "     2      0.612500  RandomForestClassifier\n",
       "     3      0.637500  RandomForestClassifier\n",
       "     4      0.775000  RandomForestClassifier\n",
       "     5      0.837500  RandomForestClassifier\n",
       "     6      0.650000  RandomForestClassifier\n",
       "     7      0.775000  RandomForestClassifier\n",
       "     8      0.737500  RandomForestClassifier\n",
       "     9      0.787500  RandomForestClassifier\n",
       "     10     0.825000  RandomForestClassifier\n",
       "     11     0.775000  RandomForestClassifier\n",
       "     12     0.812500  RandomForestClassifier\n",
       "     13     0.850000  RandomForestClassifier\n",
       "     14     0.912500  RandomForestClassifier\n",
       "15   0      0.662500  RandomForestClassifier\n",
       "     1      0.662500  RandomForestClassifier\n",
       "     2      0.625000  RandomForestClassifier\n",
       "     3      0.687500  RandomForestClassifier\n",
       "     4      0.837500  RandomForestClassifier\n",
       "     5      0.687500  RandomForestClassifier\n",
       "     6      0.675000  RandomForestClassifier\n",
       "     7      0.725000  RandomForestClassifier\n",
       "     8      0.787500  RandomForestClassifier\n",
       "     9      0.775000  RandomForestClassifier\n",
       "     10     0.775000  RandomForestClassifier\n",
       "     11     0.762500  RandomForestClassifier\n",
       "     12     0.862500  RandomForestClassifier\n",
       "     13     0.875000  RandomForestClassifier\n",
       "     14     0.875000  RandomForestClassifier\n",
       "16   0      0.575000  RandomForestClassifier\n",
       "     1      0.612500  RandomForestClassifier\n",
       "     2      0.612500  RandomForestClassifier\n",
       "     3      0.650000  RandomForestClassifier\n",
       "     4      0.662500  RandomForestClassifier\n",
       "     5      0.675000  RandomForestClassifier\n",
       "     6      0.712500  RandomForestClassifier\n",
       "     7      0.587500  RandomForestClassifier\n",
       "     8      0.600000  RandomForestClassifier\n",
       "     9      0.750000  RandomForestClassifier\n",
       "     10     0.712500  RandomForestClassifier\n",
       "     11     0.712500  RandomForestClassifier\n",
       "     12     0.750000  RandomForestClassifier\n",
       "     13     0.750000  RandomForestClassifier\n",
       "     14     0.775000  RandomForestClassifier\n",
       "17   0      0.675000  RandomForestClassifier\n",
       "     1      0.675000  RandomForestClassifier\n",
       "     2      0.687500  RandomForestClassifier\n",
       "     3      0.700000  RandomForestClassifier\n",
       "     4      0.687500  RandomForestClassifier\n",
       "     5      0.750000  RandomForestClassifier\n",
       "     6      0.775000  RandomForestClassifier\n",
       "     7      0.750000  RandomForestClassifier\n",
       "     8      0.775000  RandomForestClassifier\n",
       "     9      0.750000  RandomForestClassifier\n",
       "     10     0.825000  RandomForestClassifier\n",
       "     11     0.825000  RandomForestClassifier\n",
       "     12     0.775000  RandomForestClassifier\n",
       "     13     0.825000  RandomForestClassifier\n",
       "     14     0.900000  RandomForestClassifier\n",
       "2    0      0.658228  RandomForestClassifier\n",
       "     1      0.620253  RandomForestClassifier\n",
       "     2      0.696203  RandomForestClassifier\n",
       "     3      0.620253  RandomForestClassifier\n",
       "     4      0.696203  RandomForestClassifier\n",
       "     5      0.708861  RandomForestClassifier\n",
       "     6      0.721519  RandomForestClassifier\n",
       "     7      0.658228  RandomForestClassifier\n",
       "     8      0.683544  RandomForestClassifier\n",
       "     9      0.696203  RandomForestClassifier\n",
       "     10     0.721519  RandomForestClassifier\n",
       "     11     0.810127  RandomForestClassifier\n",
       "     12     0.721519  RandomForestClassifier\n",
       "     13     0.784810  RandomForestClassifier\n",
       "     14     0.810127  RandomForestClassifier\n",
       "3    0      0.636364  RandomForestClassifier\n",
       "     1      0.636364  RandomForestClassifier\n",
       "     2      0.636364  RandomForestClassifier\n",
       "     3      0.610390  RandomForestClassifier\n",
       "     4      0.740260  RandomForestClassifier\n",
       "     5      0.701299  RandomForestClassifier\n",
       "     6      0.766234  RandomForestClassifier\n",
       "     7      0.740260  RandomForestClassifier\n",
       "     8      0.727273  RandomForestClassifier\n",
       "     9      0.675325  RandomForestClassifier\n",
       "     10     0.792208  RandomForestClassifier\n",
       "     11     0.766234  RandomForestClassifier\n",
       "     12     0.779221  RandomForestClassifier\n",
       "     13     0.740260  RandomForestClassifier\n",
       "     14     0.818182  RandomForestClassifier\n",
       "4    0      0.657534  RandomForestClassifier\n",
       "     1      0.671233  RandomForestClassifier\n",
       "     2      0.630137  RandomForestClassifier\n",
       "     3      0.452055  RandomForestClassifier\n",
       "     4      0.739726  RandomForestClassifier\n",
       "     5      0.684932  RandomForestClassifier\n",
       "     6      0.657534  RandomForestClassifier\n",
       "     7      0.726027  RandomForestClassifier\n",
       "     8      0.684932  RandomForestClassifier\n",
       "     9      0.698630  RandomForestClassifier\n",
       "     10     0.767123  RandomForestClassifier\n",
       "     11     0.739726  RandomForestClassifier\n",
       "     12     0.808219  RandomForestClassifier\n",
       "     13     0.739726  RandomForestClassifier\n",
       "     14     0.863014  RandomForestClassifier\n",
       "5    0      0.563380  RandomForestClassifier\n",
       "     1      0.704225  RandomForestClassifier\n",
       "     2      0.718310  RandomForestClassifier\n",
       "     3      0.605634  RandomForestClassifier\n",
       "     4      0.661972  RandomForestClassifier\n",
       "     5      0.746479  RandomForestClassifier\n",
       "     6      0.732394  RandomForestClassifier\n",
       "     7      0.661972  RandomForestClassifier\n",
       "     8      0.690141  RandomForestClassifier\n",
       "     9      0.690141  RandomForestClassifier\n",
       "     10     0.774648  RandomForestClassifier\n",
       "     11     0.732394  RandomForestClassifier\n",
       "     12     0.732394  RandomForestClassifier\n",
       "     13     0.788732  RandomForestClassifier\n",
       "     14     0.887324  RandomForestClassifier\n",
       "6    0      0.614286  RandomForestClassifier\n",
       "     1      0.614286  RandomForestClassifier\n",
       "     2      0.585714  RandomForestClassifier\n",
       "     3      0.571429  RandomForestClassifier\n",
       "     4      0.671429  RandomForestClassifier\n",
       "     5      0.671429  RandomForestClassifier\n",
       "     6      0.657143  RandomForestClassifier\n",
       "     7      0.671429  RandomForestClassifier\n",
       "     8      0.600000  RandomForestClassifier\n",
       "     9      0.600000  RandomForestClassifier\n",
       "     10     0.714286  RandomForestClassifier\n",
       "     11     0.700000  RandomForestClassifier\n",
       "     12     0.700000  RandomForestClassifier\n",
       "     13     0.714286  RandomForestClassifier\n",
       "     14     0.785714  RandomForestClassifier\n",
       "7    0      0.785714  RandomForestClassifier\n",
       "     1      0.671429  RandomForestClassifier\n",
       "     2      0.757143  RandomForestClassifier\n",
       "     3      0.585714  RandomForestClassifier\n",
       "     4      0.785714  RandomForestClassifier\n",
       "     5      0.771429  RandomForestClassifier\n",
       "     6      0.742857  RandomForestClassifier\n",
       "     7      0.842857  RandomForestClassifier\n",
       "     8      0.742857  RandomForestClassifier\n",
       "     9      0.685714  RandomForestClassifier\n",
       "     10     0.857143  RandomForestClassifier\n",
       "     11     0.857143  RandomForestClassifier\n",
       "     12     0.785714  RandomForestClassifier\n",
       "     13     0.814286  RandomForestClassifier\n",
       "     14     0.871429  RandomForestClassifier\n",
       "8    0      0.724638  RandomForestClassifier\n",
       "     1      0.739130  RandomForestClassifier\n",
       "     2      0.724638  RandomForestClassifier\n",
       "     3      0.623188  RandomForestClassifier\n",
       "     4      0.739130  RandomForestClassifier\n",
       "     5      0.768116  RandomForestClassifier\n",
       "     6      0.782609  RandomForestClassifier\n",
       "     7      0.753623  RandomForestClassifier\n",
       "     8      0.782609  RandomForestClassifier\n",
       "     9      0.782609  RandomForestClassifier\n",
       "     10     0.782609  RandomForestClassifier\n",
       "     11     0.826087  RandomForestClassifier\n",
       "     12     0.797101  RandomForestClassifier\n",
       "     13     0.782609  RandomForestClassifier\n",
       "     14     0.869565  RandomForestClassifier\n",
       "9    0      0.623188  RandomForestClassifier\n",
       "     1      0.608696  RandomForestClassifier\n",
       "     2      0.652174  RandomForestClassifier\n",
       "     3      0.666667  RandomForestClassifier\n",
       "     4      0.695652  RandomForestClassifier\n",
       "     5      0.753623  RandomForestClassifier\n",
       "     6      0.710145  RandomForestClassifier\n",
       "     7      0.666667  RandomForestClassifier\n",
       "     8      0.666667  RandomForestClassifier\n",
       "     9      0.681159  RandomForestClassifier\n",
       "     10     0.739130  RandomForestClassifier\n",
       "     11     0.710145  RandomForestClassifier\n",
       "     12     0.782609  RandomForestClassifier\n",
       "     13     0.753623  RandomForestClassifier\n",
       "     14     0.840580  RandomForestClassifier\n",
       "CC   0      0.500000  RandomForestClassifier\n",
       "     1      0.500000  RandomForestClassifier\n",
       "     2      0.500000  RandomForestClassifier\n",
       "     3      0.500000  RandomForestClassifier\n",
       "     4      0.600000  RandomForestClassifier\n",
       "     5      0.700000  RandomForestClassifier\n",
       "     6      0.500000  RandomForestClassifier\n",
       "     7      0.500000  RandomForestClassifier\n",
       "     8      0.500000  RandomForestClassifier\n",
       "     9      0.600000  RandomForestClassifier\n",
       "     10     0.600000  RandomForestClassifier\n",
       "     11     0.500000  RandomForestClassifier\n",
       "     12     0.600000  RandomForestClassifier\n",
       "     13     0.600000  RandomForestClassifier\n",
       "     14     0.700000  RandomForestClassifier\n",
       "DV   0      0.750000  RandomForestClassifier\n",
       "     1      0.550000  RandomForestClassifier\n",
       "     2      0.450000  RandomForestClassifier\n",
       "     3      0.550000  RandomForestClassifier\n",
       "     4      0.650000  RandomForestClassifier\n",
       "     5      0.550000  RandomForestClassifier\n",
       "     6      0.550000  RandomForestClassifier\n",
       "     7      0.650000  RandomForestClassifier\n",
       "     8      0.650000  RandomForestClassifier\n",
       "     9      0.600000  RandomForestClassifier\n",
       "     10     0.650000  RandomForestClassifier\n",
       "     11     0.650000  RandomForestClassifier\n",
       "     12     0.650000  RandomForestClassifier\n",
       "     13     0.550000  RandomForestClassifier\n",
       "     14     0.750000  RandomForestClassifier\n",
       "SB   0      0.800000  RandomForestClassifier\n",
       "     1      0.600000  RandomForestClassifier\n",
       "     2      0.600000  RandomForestClassifier\n",
       "     3      0.600000  RandomForestClassifier\n",
       "     4      0.600000  RandomForestClassifier\n",
       "     5      0.600000  RandomForestClassifier\n",
       "     6      0.800000  RandomForestClassifier\n",
       "     7      0.600000  RandomForestClassifier\n",
       "     8      1.000000  RandomForestClassifier\n",
       "     9      0.600000  RandomForestClassifier\n",
       "     10     0.600000  RandomForestClassifier\n",
       "     11     0.800000  RandomForestClassifier\n",
       "     12     0.600000  RandomForestClassifier\n",
       "     13     0.800000  RandomForestClassifier\n",
       "     14     0.800000  RandomForestClassifier\n",
       "WC   0      0.550000  RandomForestClassifier\n",
       "     1      0.600000  RandomForestClassifier\n",
       "     2      0.650000  RandomForestClassifier\n",
       "     3      0.500000  RandomForestClassifier\n",
       "     4      0.650000  RandomForestClassifier\n",
       "     5      0.700000  RandomForestClassifier\n",
       "     6      0.750000  RandomForestClassifier\n",
       "     7      0.800000  RandomForestClassifier\n",
       "     8      0.450000  RandomForestClassifier\n",
       "     9      0.650000  RandomForestClassifier\n",
       "     10     0.800000  RandomForestClassifier\n",
       "     11     0.800000  RandomForestClassifier\n",
       "     12     0.650000  RandomForestClassifier\n",
       "     13     0.750000  RandomForestClassifier\n",
       "     14     0.800000  RandomForestClassifier"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].max()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe508bd-7ad4-4846-be8d-cc4fdd6f8f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c0ace9de6ef0>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  x = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].max()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['RandomForestClassifier'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].max()\n",
    "x['Estimator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2500c59-eac4-4e2a-8086-250091e7c340",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-155cb3e73489>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  weekly.groupby(['Week','Clump'])['accuracy','Estimator'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week</th>\n",
       "      <th>Clump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.537500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.787500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">10</th>\n",
       "      <th>0</th>\n",
       "      <td>0.513889</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569444</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.569444</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.597222</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.597222</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.638889</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">11</th>\n",
       "      <th>0</th>\n",
       "      <td>0.453333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.706667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.586667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.706667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.613333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.693333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.773333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">12</th>\n",
       "      <th>0</th>\n",
       "      <td>0.358974</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551282</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.423077</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.525641</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.679487</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">13</th>\n",
       "      <th>0</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.762500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.462500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.587500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">14</th>\n",
       "      <th>0</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">15</th>\n",
       "      <th>0</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.737500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.737500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.712500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">16</th>\n",
       "      <th>0</th>\n",
       "      <td>0.537500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.612500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.525000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.512500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.637500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">17</th>\n",
       "      <th>0</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.645570</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.569620</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594937</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556962</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.620253</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.620253</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.556962</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.594937</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.670886</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.658228</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.683544</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.658228</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.670886</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.632911</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.584416</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.610390</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.597403</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662338</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.662338</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.675325</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.662338</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.649351</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616438</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.643836</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.616438</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.547945</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.698630</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.671233</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>0.535211</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.704225</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <td>0.471429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.557143</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.528571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.614286</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.614286</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.614286</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">7</th>\n",
       "      <th>0</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.742857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">8</th>\n",
       "      <th>0</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623188</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594203</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.710145</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.623188</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.637681</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.594203</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.681159</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.753623</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.710145</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">9</th>\n",
       "      <th>0</th>\n",
       "      <td>0.594203</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550725</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536232</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.579710</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.623188</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.594203</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.550725</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.637681</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.579710</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.637681</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">CC</th>\n",
       "      <th>0</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">DV</th>\n",
       "      <th>0</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">SB</th>\n",
       "      <th>0</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">WC</th>\n",
       "      <th>0</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy           Estimator\n",
       "Week Clump                              \n",
       "1    0      0.612500  AdaBoostClassifier\n",
       "     1      0.675000  AdaBoostClassifier\n",
       "     2      0.587500  AdaBoostClassifier\n",
       "     3      0.600000  AdaBoostClassifier\n",
       "     4      0.637500  AdaBoostClassifier\n",
       "     5      0.712500  AdaBoostClassifier\n",
       "     6      0.725000  AdaBoostClassifier\n",
       "     7      0.725000  AdaBoostClassifier\n",
       "     8      0.612500  AdaBoostClassifier\n",
       "     9      0.537500  AdaBoostClassifier\n",
       "     10     0.700000  AdaBoostClassifier\n",
       "     11     0.675000  AdaBoostClassifier\n",
       "     12     0.712500  AdaBoostClassifier\n",
       "     13     0.787500  AdaBoostClassifier\n",
       "     14     0.725000  AdaBoostClassifier\n",
       "10   0      0.513889  AdaBoostClassifier\n",
       "     1      0.541667  AdaBoostClassifier\n",
       "     2      0.569444  AdaBoostClassifier\n",
       "     3      0.569444  AdaBoostClassifier\n",
       "     4      0.625000  AdaBoostClassifier\n",
       "     5      0.583333  AdaBoostClassifier\n",
       "     6      0.638889  AdaBoostClassifier\n",
       "     7      0.597222  AdaBoostClassifier\n",
       "     8      0.625000  AdaBoostClassifier\n",
       "     9      0.652778  AdaBoostClassifier\n",
       "     10     0.597222  AdaBoostClassifier\n",
       "     11     0.680556  AdaBoostClassifier\n",
       "     12     0.638889  AdaBoostClassifier\n",
       "     13     0.652778  AdaBoostClassifier\n",
       "     14     0.666667  AdaBoostClassifier\n",
       "11   0      0.453333  AdaBoostClassifier\n",
       "     1      0.706667  AdaBoostClassifier\n",
       "     2      0.640000  AdaBoostClassifier\n",
       "     3      0.586667  AdaBoostClassifier\n",
       "     4      0.706667  AdaBoostClassifier\n",
       "     5      0.760000  AdaBoostClassifier\n",
       "     6      0.720000  AdaBoostClassifier\n",
       "     7      0.720000  AdaBoostClassifier\n",
       "     8      0.613333  AdaBoostClassifier\n",
       "     9      0.693333  AdaBoostClassifier\n",
       "     10     0.773333  AdaBoostClassifier\n",
       "     11     0.733333  AdaBoostClassifier\n",
       "     12     0.733333  AdaBoostClassifier\n",
       "     13     0.680000  AdaBoostClassifier\n",
       "     14     0.733333  AdaBoostClassifier\n",
       "12   0      0.358974  AdaBoostClassifier\n",
       "     1      0.551282  AdaBoostClassifier\n",
       "     2      0.628205  AdaBoostClassifier\n",
       "     3      0.589744  AdaBoostClassifier\n",
       "     4      0.500000  AdaBoostClassifier\n",
       "     5      0.615385  AdaBoostClassifier\n",
       "     6      0.717949  AdaBoostClassifier\n",
       "     7      0.589744  AdaBoostClassifier\n",
       "     8      0.423077  AdaBoostClassifier\n",
       "     9      0.564103  AdaBoostClassifier\n",
       "     10     0.641026  AdaBoostClassifier\n",
       "     11     0.653846  AdaBoostClassifier\n",
       "     12     0.525641  AdaBoostClassifier\n",
       "     13     0.653846  AdaBoostClassifier\n",
       "     14     0.679487  AdaBoostClassifier\n",
       "13   0      0.475000  AdaBoostClassifier\n",
       "     1      0.762500  AdaBoostClassifier\n",
       "     2      0.450000  AdaBoostClassifier\n",
       "     3      0.675000  AdaBoostClassifier\n",
       "     4      0.600000  AdaBoostClassifier\n",
       "     5      0.712500  AdaBoostClassifier\n",
       "     6      0.700000  AdaBoostClassifier\n",
       "     7      0.462500  AdaBoostClassifier\n",
       "     8      0.625000  AdaBoostClassifier\n",
       "     9      0.750000  AdaBoostClassifier\n",
       "     10     0.662500  AdaBoostClassifier\n",
       "     11     0.587500  AdaBoostClassifier\n",
       "     12     0.675000  AdaBoostClassifier\n",
       "     13     0.725000  AdaBoostClassifier\n",
       "     14     0.725000  AdaBoostClassifier\n",
       "14   0      0.612500  AdaBoostClassifier\n",
       "     1      0.712500  AdaBoostClassifier\n",
       "     2      0.600000  AdaBoostClassifier\n",
       "     3      0.637500  AdaBoostClassifier\n",
       "     4      0.700000  AdaBoostClassifier\n",
       "     5      0.687500  AdaBoostClassifier\n",
       "     6      0.600000  AdaBoostClassifier\n",
       "     7      0.625000  AdaBoostClassifier\n",
       "     8      0.612500  AdaBoostClassifier\n",
       "     9      0.712500  AdaBoostClassifier\n",
       "     10     0.662500  AdaBoostClassifier\n",
       "     11     0.637500  AdaBoostClassifier\n",
       "     12     0.700000  AdaBoostClassifier\n",
       "     13     0.662500  AdaBoostClassifier\n",
       "     14     0.687500  AdaBoostClassifier\n",
       "15   0      0.662500  AdaBoostClassifier\n",
       "     1      0.625000  AdaBoostClassifier\n",
       "     2      0.600000  AdaBoostClassifier\n",
       "     3      0.537500  AdaBoostClassifier\n",
       "     4      0.662500  AdaBoostClassifier\n",
       "     5      0.625000  AdaBoostClassifier\n",
       "     6      0.600000  AdaBoostClassifier\n",
       "     7      0.662500  AdaBoostClassifier\n",
       "     8      0.700000  AdaBoostClassifier\n",
       "     9      0.737500  AdaBoostClassifier\n",
       "     10     0.737500  AdaBoostClassifier\n",
       "     11     0.662500  AdaBoostClassifier\n",
       "     12     0.775000  AdaBoostClassifier\n",
       "     13     0.712500  AdaBoostClassifier\n",
       "     14     0.775000  AdaBoostClassifier\n",
       "16   0      0.537500  AdaBoostClassifier\n",
       "     1      0.550000  AdaBoostClassifier\n",
       "     2      0.612500  AdaBoostClassifier\n",
       "     3      0.612500  AdaBoostClassifier\n",
       "     4      0.612500  AdaBoostClassifier\n",
       "     5      0.625000  AdaBoostClassifier\n",
       "     6      0.575000  AdaBoostClassifier\n",
       "     7      0.525000  AdaBoostClassifier\n",
       "     8      0.512500  AdaBoostClassifier\n",
       "     9      0.662500  AdaBoostClassifier\n",
       "     10     0.625000  AdaBoostClassifier\n",
       "     11     0.562500  AdaBoostClassifier\n",
       "     12     0.650000  AdaBoostClassifier\n",
       "     13     0.700000  AdaBoostClassifier\n",
       "     14     0.637500  AdaBoostClassifier\n",
       "17   0      0.675000  AdaBoostClassifier\n",
       "     1      0.675000  AdaBoostClassifier\n",
       "     2      0.400000  AdaBoostClassifier\n",
       "     3      0.600000  AdaBoostClassifier\n",
       "     4      0.650000  AdaBoostClassifier\n",
       "     5      0.687500  AdaBoostClassifier\n",
       "     6      0.650000  AdaBoostClassifier\n",
       "     7      0.687500  AdaBoostClassifier\n",
       "     8      0.700000  AdaBoostClassifier\n",
       "     9      0.662500  AdaBoostClassifier\n",
       "     10     0.675000  AdaBoostClassifier\n",
       "     11     0.750000  AdaBoostClassifier\n",
       "     12     0.675000  AdaBoostClassifier\n",
       "     13     0.687500  AdaBoostClassifier\n",
       "     14     0.700000  AdaBoostClassifier\n",
       "2    0      0.645570  AdaBoostClassifier\n",
       "     1      0.569620  AdaBoostClassifier\n",
       "     2      0.594937  AdaBoostClassifier\n",
       "     3      0.556962  AdaBoostClassifier\n",
       "     4      0.620253  AdaBoostClassifier\n",
       "     5      0.620253  AdaBoostClassifier\n",
       "     6      0.556962  AdaBoostClassifier\n",
       "     7      0.582278  AdaBoostClassifier\n",
       "     8      0.594937  AdaBoostClassifier\n",
       "     9      0.670886  AdaBoostClassifier\n",
       "     10     0.658228  AdaBoostClassifier\n",
       "     11     0.683544  AdaBoostClassifier\n",
       "     12     0.658228  AdaBoostClassifier\n",
       "     13     0.670886  AdaBoostClassifier\n",
       "     14     0.632911  AdaBoostClassifier\n",
       "3    0      0.571429  AdaBoostClassifier\n",
       "     1      0.584416  AdaBoostClassifier\n",
       "     2      0.571429  AdaBoostClassifier\n",
       "     3      0.610390  AdaBoostClassifier\n",
       "     4      0.597403  AdaBoostClassifier\n",
       "     5      0.662338  AdaBoostClassifier\n",
       "     6      0.662338  AdaBoostClassifier\n",
       "     7      0.675325  AdaBoostClassifier\n",
       "     8      0.623377  AdaBoostClassifier\n",
       "     9      0.623377  AdaBoostClassifier\n",
       "     10     0.636364  AdaBoostClassifier\n",
       "     11     0.623377  AdaBoostClassifier\n",
       "     12     0.662338  AdaBoostClassifier\n",
       "     13     0.649351  AdaBoostClassifier\n",
       "     14     0.623377  AdaBoostClassifier\n",
       "4    0      0.657534  AdaBoostClassifier\n",
       "     1      0.561644  AdaBoostClassifier\n",
       "     2      0.616438  AdaBoostClassifier\n",
       "     3      0.452055  AdaBoostClassifier\n",
       "     4      0.684932  AdaBoostClassifier\n",
       "     5      0.643836  AdaBoostClassifier\n",
       "     6      0.589041  AdaBoostClassifier\n",
       "     7      0.616438  AdaBoostClassifier\n",
       "     8      0.547945  AdaBoostClassifier\n",
       "     9      0.589041  AdaBoostClassifier\n",
       "     10     0.657534  AdaBoostClassifier\n",
       "     11     0.698630  AdaBoostClassifier\n",
       "     12     0.657534  AdaBoostClassifier\n",
       "     13     0.671233  AdaBoostClassifier\n",
       "     14     0.657534  AdaBoostClassifier\n",
       "5    0      0.535211  AdaBoostClassifier\n",
       "     1      0.676056  AdaBoostClassifier\n",
       "     2      0.619718  AdaBoostClassifier\n",
       "     3      0.605634  AdaBoostClassifier\n",
       "     4      0.577465  AdaBoostClassifier\n",
       "     5      0.690141  AdaBoostClassifier\n",
       "     6      0.577465  AdaBoostClassifier\n",
       "     7      0.605634  AdaBoostClassifier\n",
       "     8      0.661972  AdaBoostClassifier\n",
       "     9      0.619718  AdaBoostClassifier\n",
       "     10     0.704225  AdaBoostClassifier\n",
       "     11     0.605634  AdaBoostClassifier\n",
       "     12     0.676056  AdaBoostClassifier\n",
       "     13     0.676056  AdaBoostClassifier\n",
       "     14     0.690141  AdaBoostClassifier\n",
       "6    0      0.471429  AdaBoostClassifier\n",
       "     1      0.542857  AdaBoostClassifier\n",
       "     2      0.542857  AdaBoostClassifier\n",
       "     3      0.528571  AdaBoostClassifier\n",
       "     4      0.628571  AdaBoostClassifier\n",
       "     5      0.571429  AdaBoostClassifier\n",
       "     6      0.585714  AdaBoostClassifier\n",
       "     7      0.600000  AdaBoostClassifier\n",
       "     8      0.557143  AdaBoostClassifier\n",
       "     9      0.528571  AdaBoostClassifier\n",
       "     10     0.614286  AdaBoostClassifier\n",
       "     11     0.614286  AdaBoostClassifier\n",
       "     12     0.585714  AdaBoostClassifier\n",
       "     13     0.614286  AdaBoostClassifier\n",
       "     14     0.657143  AdaBoostClassifier\n",
       "7    0      0.785714  AdaBoostClassifier\n",
       "     1      0.671429  AdaBoostClassifier\n",
       "     2      0.642857  AdaBoostClassifier\n",
       "     3      0.571429  AdaBoostClassifier\n",
       "     4      0.685714  AdaBoostClassifier\n",
       "     5      0.700000  AdaBoostClassifier\n",
       "     6      0.657143  AdaBoostClassifier\n",
       "     7      0.742857  AdaBoostClassifier\n",
       "     8      0.700000  AdaBoostClassifier\n",
       "     9      0.642857  AdaBoostClassifier\n",
       "     10     0.671429  AdaBoostClassifier\n",
       "     11     0.742857  AdaBoostClassifier\n",
       "     12     0.685714  AdaBoostClassifier\n",
       "     13     0.657143  AdaBoostClassifier\n",
       "     14     0.685714  AdaBoostClassifier\n",
       "8    0      0.724638  AdaBoostClassifier\n",
       "     1      0.623188  AdaBoostClassifier\n",
       "     2      0.594203  AdaBoostClassifier\n",
       "     3      0.521739  AdaBoostClassifier\n",
       "     4      0.710145  AdaBoostClassifier\n",
       "     5      0.623188  AdaBoostClassifier\n",
       "     6      0.637681  AdaBoostClassifier\n",
       "     7      0.739130  AdaBoostClassifier\n",
       "     8      0.739130  AdaBoostClassifier\n",
       "     9      0.594203  AdaBoostClassifier\n",
       "     10     0.681159  AdaBoostClassifier\n",
       "     11     0.652174  AdaBoostClassifier\n",
       "     12     0.753623  AdaBoostClassifier\n",
       "     13     0.608696  AdaBoostClassifier\n",
       "     14     0.710145  AdaBoostClassifier\n",
       "9    0      0.594203  AdaBoostClassifier\n",
       "     1      0.550725  AdaBoostClassifier\n",
       "     2      0.536232  AdaBoostClassifier\n",
       "     3      0.434783  AdaBoostClassifier\n",
       "     4      0.652174  AdaBoostClassifier\n",
       "     5      0.579710  AdaBoostClassifier\n",
       "     6      0.623188  AdaBoostClassifier\n",
       "     7      0.594203  AdaBoostClassifier\n",
       "     8      0.550725  AdaBoostClassifier\n",
       "     9      0.608696  AdaBoostClassifier\n",
       "     10     0.637681  AdaBoostClassifier\n",
       "     11     0.579710  AdaBoostClassifier\n",
       "     12     0.666667  AdaBoostClassifier\n",
       "     13     0.637681  AdaBoostClassifier\n",
       "     14     0.666667  AdaBoostClassifier\n",
       "CC   0      0.400000  AdaBoostClassifier\n",
       "     1      0.500000  AdaBoostClassifier\n",
       "     2      0.500000  AdaBoostClassifier\n",
       "     3      0.400000  AdaBoostClassifier\n",
       "     4      0.400000  AdaBoostClassifier\n",
       "     5      0.500000  AdaBoostClassifier\n",
       "     6      0.300000  AdaBoostClassifier\n",
       "     7      0.400000  AdaBoostClassifier\n",
       "     8      0.400000  AdaBoostClassifier\n",
       "     9      0.400000  AdaBoostClassifier\n",
       "     10     0.400000  AdaBoostClassifier\n",
       "     11     0.400000  AdaBoostClassifier\n",
       "     12     0.400000  AdaBoostClassifier\n",
       "     13     0.400000  AdaBoostClassifier\n",
       "     14     0.400000  AdaBoostClassifier\n",
       "DV   0      0.700000  AdaBoostClassifier\n",
       "     1      0.500000  AdaBoostClassifier\n",
       "     2      0.450000  AdaBoostClassifier\n",
       "     3      0.550000  AdaBoostClassifier\n",
       "     4      0.500000  AdaBoostClassifier\n",
       "     5      0.450000  AdaBoostClassifier\n",
       "     6      0.350000  AdaBoostClassifier\n",
       "     7      0.500000  AdaBoostClassifier\n",
       "     8      0.400000  AdaBoostClassifier\n",
       "     9      0.400000  AdaBoostClassifier\n",
       "     10     0.450000  AdaBoostClassifier\n",
       "     11     0.450000  AdaBoostClassifier\n",
       "     12     0.400000  AdaBoostClassifier\n",
       "     13     0.400000  AdaBoostClassifier\n",
       "     14     0.450000  AdaBoostClassifier\n",
       "SB   0      0.400000  AdaBoostClassifier\n",
       "     1      0.200000  AdaBoostClassifier\n",
       "     2      0.400000  AdaBoostClassifier\n",
       "     3      0.400000  AdaBoostClassifier\n",
       "     4      0.400000  AdaBoostClassifier\n",
       "     5      0.200000  AdaBoostClassifier\n",
       "     6      0.400000  AdaBoostClassifier\n",
       "     7      0.400000  AdaBoostClassifier\n",
       "     8      0.400000  AdaBoostClassifier\n",
       "     9      0.400000  AdaBoostClassifier\n",
       "     10     0.400000  AdaBoostClassifier\n",
       "     11     0.400000  AdaBoostClassifier\n",
       "     12     0.400000  AdaBoostClassifier\n",
       "     13     0.400000  AdaBoostClassifier\n",
       "     14     0.400000  AdaBoostClassifier\n",
       "WC   0      0.450000  AdaBoostClassifier\n",
       "     1      0.500000  AdaBoostClassifier\n",
       "     2      0.650000  AdaBoostClassifier\n",
       "     3      0.400000  AdaBoostClassifier\n",
       "     4      0.500000  AdaBoostClassifier\n",
       "     5      0.600000  AdaBoostClassifier\n",
       "     6      0.500000  AdaBoostClassifier\n",
       "     7      0.500000  AdaBoostClassifier\n",
       "     8      0.400000  AdaBoostClassifier\n",
       "     9      0.500000  AdaBoostClassifier\n",
       "     10     0.550000  AdaBoostClassifier\n",
       "     11     0.600000  AdaBoostClassifier\n",
       "     12     0.450000  AdaBoostClassifier\n",
       "     13     0.600000  AdaBoostClassifier\n",
       "     14     0.600000  AdaBoostClassifier"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly.groupby(['Week','Clump'])['accuracy','Estimator'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb60221e-c5f8-4824-8cdf-bf67931f14e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-1bcbbabe367a>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  y = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].min()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['AdaBoostClassifier'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = weekly.groupby(['Week','Clump'])['accuracy','Estimator'].min()\n",
    "y['Estimator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a16da05b-bf6b-4268-8593-a35058515758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump\n",
       "0     0.616667\n",
       "1     0.675000\n",
       "2     0.743056\n",
       "3     0.633333\n",
       "4     0.661111\n",
       "5     0.762500\n",
       "6     0.751389\n",
       "7     0.752778\n",
       "8     0.647222\n",
       "9     0.690278\n",
       "10    0.755556\n",
       "11    0.723611\n",
       "12    0.730556\n",
       "13    0.811111\n",
       "14    0.816667\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_1 = weekly[weekly['Week'] == '1']\n",
    "weekly_1.groupby('Clump')['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b0fa8f-7457-4caa-9947-c34e4f07597e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump\n",
       "0     0.646976\n",
       "1     0.576653\n",
       "2     0.670886\n",
       "3     0.613221\n",
       "4     0.648383\n",
       "5     0.658228\n",
       "6     0.654008\n",
       "7     0.618847\n",
       "8     0.649789\n",
       "9     0.683544\n",
       "10    0.691983\n",
       "11    0.744023\n",
       "12    0.697609\n",
       "13    0.742616\n",
       "14    0.756681\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_2 = weekly[weekly['Week'] == '2']\n",
    "weekly_2.groupby('Clump')['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4aac683-b764-4877-b927-6e76938702a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump\n",
       "0     0.578644\n",
       "1     0.630592\n",
       "2     0.619048\n",
       "3     0.610390\n",
       "4     0.663781\n",
       "5     0.679654\n",
       "6     0.720058\n",
       "7     0.715729\n",
       "8     0.669553\n",
       "9     0.653680\n",
       "10    0.715729\n",
       "11    0.686869\n",
       "12    0.730159\n",
       "13    0.711400\n",
       "14    0.750361\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_3 = weekly[weekly['Week'] == '3']\n",
    "weekly_3.groupby('Clump')['accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2649f6b-e3e0-4e5d-a715-62e31d908241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-8ff99f425b85>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weekly_C0['week_int'] = weekly_C0['Week'].map(week_dict)\n"
     ]
    }
   ],
   "source": [
    "# to make x axis with consecutive weeks, change string values to integers using a dictionary\n",
    "week_dict = {'1':1, '2':2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, '10':10,\n",
    "            '11':11, '12':12, '13':13, '14':14, '15':15, '16':16, '17': 17, 'WC': 18, 'DV': 19, 'CC':20, 'SB':21}\n",
    "\n",
    "weekly_C0 = weekly[weekly['Clump'] == 0]\n",
    "weekly_C0['week_int'] = weekly_C0['Week'].map(week_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1fedad6-b250-4612-9141-3f2e260226dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-55dd7fe0c1ff>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  C0 = weekly.groupby(['Clump','Week',])['accuracy','Estimator'].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6134326738123723"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of all weeks of 1st qtr clump\n",
    "C0 = weekly.groupby(['Clump','Week',])['accuracy','Estimator'].mean()\n",
    "C0\n",
    "C0.iloc[:20,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b7d00e-ae13-4d74-a5e4-2ac73c34ef3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227547063671336"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also did this with 2nd qtr clump\n",
    "C0.iloc[21:42,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f94515-e305-4f62-9022-bac4fbeeb97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62357217981542"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also did this with 3rd qtr clump\n",
    "C0.iloc[42:63,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6368db7f-8f5e-4879-b3e5-07eadc0ee5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930753255083512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also did this with 4th qtr clump\n",
    "C0.iloc[63:84,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1cf46f2-5897-46bf-a45c-0cddf1e413f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425631767654368"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#... and all qtrs clump\n",
    "C0.iloc[-21:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9014d9db-f8e7-4f66-9c1a-a38e263fbfac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-a9a68a324881>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weekly_C0['week_int'] = weekly_C0['Week'].map(week_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Week</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>week_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>690</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>720</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>735</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>765</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>780</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>825</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1080</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1170</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1185</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1275</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1320</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1335</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1350</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1365</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>1380</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1425</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1455</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1470</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1485</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1515</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1545</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1590</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1605</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1635</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1650</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1725</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1740</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1755</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1770</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1785</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1815</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>1830</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>1845</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1860</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1875</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1905</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1920</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1950</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1965</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2040</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2070</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2100</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2115</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2130</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2145</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2175</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2220</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2250</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2265</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>2280</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2295</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>2310</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2325</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2340</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>2355</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>2370</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2385</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2415</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2430</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>2445</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>2460</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2475</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2490</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>2505</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2535</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>2565</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2595</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2610</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2640</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2655</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2670</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>2685</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2700</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>2715</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>2730</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>2745</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>2760</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2775</td>\n",
       "      <td>WC</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>2790</td>\n",
       "      <td>DV</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2805</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>2820</td>\n",
       "      <td>SB</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Week  Clump                   Estimator  params  accuracy  week_int\n",
       "0              0    1      0          LogisticRegression     NaN  0.612500         1\n",
       "15            15    2      0          LogisticRegression     NaN  0.645570         2\n",
       "30            30    3      0          LogisticRegression     NaN  0.571429         3\n",
       "45            45    4      0          LogisticRegression     NaN  0.657534         4\n",
       "60            60    5      0          LogisticRegression     NaN  0.563380         5\n",
       "75            75    6      0          LogisticRegression     NaN  0.471429         6\n",
       "90            90    7      0          LogisticRegression     NaN  0.785714         7\n",
       "105          105    8      0          LogisticRegression     NaN  0.724638         8\n",
       "120          120    9      0          LogisticRegression     NaN  0.608696         9\n",
       "135          135   10      0          LogisticRegression     NaN  0.625000        10\n",
       "150          150   11      0          LogisticRegression     NaN  0.693333        11\n",
       "165          165   12      0          LogisticRegression     NaN  0.602564        12\n",
       "180          180   13      0          LogisticRegression     NaN  0.575000        13\n",
       "195          195   14      0          LogisticRegression     NaN  0.612500        14\n",
       "210          210   15      0          LogisticRegression     NaN  0.662500        15\n",
       "225          225   16      0          LogisticRegression     NaN  0.537500        16\n",
       "240          240   17      0          LogisticRegression     NaN  0.675000        17\n",
       "255          255   WC      0          LogisticRegression     NaN  0.550000        18\n",
       "270          270   DV      0          LogisticRegression     NaN  0.700000        19\n",
       "285          285   CC      0          LogisticRegression     NaN  0.500000        20\n",
       "300          300   SB      0          LogisticRegression     NaN  0.400000        21\n",
       "315          315    1      0           BaggingClassifier     NaN  0.612500         1\n",
       "330          330    2      0           BaggingClassifier     NaN  0.645570         2\n",
       "345          345    3      0           BaggingClassifier     NaN  0.571429         3\n",
       "360          360    4      0           BaggingClassifier     NaN  0.657534         4\n",
       "375          375    5      0           BaggingClassifier     NaN  0.563380         5\n",
       "390          390    6      0           BaggingClassifier     NaN  0.471429         6\n",
       "405          405    7      0           BaggingClassifier     NaN  0.785714         7\n",
       "420          420    8      0           BaggingClassifier     NaN  0.724638         8\n",
       "435          435    9      0           BaggingClassifier     NaN  0.623188         9\n",
       "450          450   10      0           BaggingClassifier     NaN  0.666667        10\n",
       "465          465   11      0           BaggingClassifier     NaN  0.693333        11\n",
       "480          480   12      0           BaggingClassifier     NaN  0.602564        12\n",
       "495          495   13      0           BaggingClassifier     NaN  0.587500        13\n",
       "510          510   14      0           BaggingClassifier     NaN  0.612500        14\n",
       "525          525   15      0           BaggingClassifier     NaN  0.662500        15\n",
       "540          540   16      0           BaggingClassifier     NaN  0.537500        16\n",
       "555          555   17      0           BaggingClassifier     NaN  0.675000        17\n",
       "570          570   WC      0           BaggingClassifier     NaN  0.550000        18\n",
       "585          585   DV      0           BaggingClassifier     NaN  0.700000        19\n",
       "600          600   CC      0           BaggingClassifier     NaN  0.400000        20\n",
       "615          615   SB      0           BaggingClassifier     NaN  0.400000        21\n",
       "630          630    1      0      RandomForestClassifier     NaN  0.612500         1\n",
       "645          645    2      0      RandomForestClassifier     NaN  0.645570         2\n",
       "660          660    3      0      RandomForestClassifier     NaN  0.571429         3\n",
       "675          675    4      0      RandomForestClassifier     NaN  0.657534         4\n",
       "690          690    5      0      RandomForestClassifier     NaN  0.563380         5\n",
       "705          705    6      0      RandomForestClassifier     NaN  0.485714         6\n",
       "720          720    7      0      RandomForestClassifier     NaN  0.785714         7\n",
       "735          735    8      0      RandomForestClassifier     NaN  0.724638         8\n",
       "750          750    9      0      RandomForestClassifier     NaN  0.623188         9\n",
       "765          765   10      0      RandomForestClassifier     NaN  0.666667        10\n",
       "780          780   11      0      RandomForestClassifier     NaN  0.680000        11\n",
       "795          795   12      0      RandomForestClassifier     NaN  0.602564        12\n",
       "810          810   13      0      RandomForestClassifier     NaN  0.587500        13\n",
       "825          825   14      0      RandomForestClassifier     NaN  0.612500        14\n",
       "840          840   15      0      RandomForestClassifier     NaN  0.662500        15\n",
       "855          855   16      0      RandomForestClassifier     NaN  0.537500        16\n",
       "870          870   17      0      RandomForestClassifier     NaN  0.675000        17\n",
       "885          885   WC      0      RandomForestClassifier     NaN  0.550000        18\n",
       "900          900   DV      0      RandomForestClassifier     NaN  0.700000        19\n",
       "915          915   CC      0      RandomForestClassifier     NaN  0.400000        20\n",
       "930          930   SB      0      RandomForestClassifier     NaN  0.400000        21\n",
       "945          945    1      0        ExtraTreesClassifier     NaN  0.612500         1\n",
       "960          960    2      0        ExtraTreesClassifier     NaN  0.645570         2\n",
       "975          975    3      0        ExtraTreesClassifier     NaN  0.571429         3\n",
       "990          990    4      0        ExtraTreesClassifier     NaN  0.657534         4\n",
       "1005        1005    5      0        ExtraTreesClassifier     NaN  0.563380         5\n",
       "1020        1020    6      0        ExtraTreesClassifier     NaN  0.471429         6\n",
       "1035        1035    7      0        ExtraTreesClassifier     NaN  0.785714         7\n",
       "1050        1050    8      0        ExtraTreesClassifier     NaN  0.724638         8\n",
       "1065        1065    9      0        ExtraTreesClassifier     NaN  0.608696         9\n",
       "1080        1080   10      0        ExtraTreesClassifier     NaN  0.625000        10\n",
       "1095        1095   11      0        ExtraTreesClassifier     NaN  0.680000        11\n",
       "1110        1110   12      0        ExtraTreesClassifier     NaN  0.602564        12\n",
       "1125        1125   13      0        ExtraTreesClassifier     NaN  0.575000        13\n",
       "1140        1140   14      0        ExtraTreesClassifier     NaN  0.612500        14\n",
       "1155        1155   15      0        ExtraTreesClassifier     NaN  0.662500        15\n",
       "1170        1170   16      0        ExtraTreesClassifier     NaN  0.537500        16\n",
       "1185        1185   17      0        ExtraTreesClassifier     NaN  0.675000        17\n",
       "1200        1200   WC      0        ExtraTreesClassifier     NaN  0.550000        18\n",
       "1215        1215   DV      0        ExtraTreesClassifier     NaN  0.700000        19\n",
       "1230        1230   CC      0        ExtraTreesClassifier     NaN  0.400000        20\n",
       "1245        1245   SB      0        ExtraTreesClassifier     NaN  0.800000        21\n",
       "1260        1260    1      0      DecisionTreeClassifier     NaN  0.612500         1\n",
       "1275        1275    2      0      DecisionTreeClassifier     NaN  0.645570         2\n",
       "1290        1290    3      0      DecisionTreeClassifier     NaN  0.571429         3\n",
       "1305        1305    4      0      DecisionTreeClassifier     NaN  0.657534         4\n",
       "1320        1320    5      0      DecisionTreeClassifier     NaN  0.563380         5\n",
       "1335        1335    6      0      DecisionTreeClassifier     NaN  0.471429         6\n",
       "1350        1350    7      0      DecisionTreeClassifier     NaN  0.785714         7\n",
       "1365        1365    8      0      DecisionTreeClassifier     NaN  0.724638         8\n",
       "1380        1380    9      0      DecisionTreeClassifier     NaN  0.608696         9\n",
       "1395        1395   10      0      DecisionTreeClassifier     NaN  0.625000        10\n",
       "1410        1410   11      0      DecisionTreeClassifier     NaN  0.693333        11\n",
       "1425        1425   12      0      DecisionTreeClassifier     NaN  0.602564        12\n",
       "1440        1440   13      0      DecisionTreeClassifier     NaN  0.575000        13\n",
       "1455        1455   14      0      DecisionTreeClassifier     NaN  0.612500        14\n",
       "1470        1470   15      0      DecisionTreeClassifier     NaN  0.662500        15\n",
       "1485        1485   16      0      DecisionTreeClassifier     NaN  0.537500        16\n",
       "1500        1500   17      0      DecisionTreeClassifier     NaN  0.675000        17\n",
       "1515        1515   WC      0      DecisionTreeClassifier     NaN  0.550000        18\n",
       "1530        1530   DV      0      DecisionTreeClassifier     NaN  0.700000        19\n",
       "1545        1545   CC      0      DecisionTreeClassifier     NaN  0.400000        20\n",
       "1560        1560   SB      0      DecisionTreeClassifier     NaN  0.800000        21\n",
       "1575        1575    1      0        KNeighborsClassifier     NaN  0.650000         1\n",
       "1590        1590    2      0        KNeighborsClassifier     NaN  0.658228         2\n",
       "1605        1605    3      0        KNeighborsClassifier     NaN  0.636364         3\n",
       "1620        1620    4      0        KNeighborsClassifier     NaN  0.657534         4\n",
       "1635        1635    5      0        KNeighborsClassifier     NaN  0.535211         5\n",
       "1650        1650    6      0        KNeighborsClassifier     NaN  0.614286         6\n",
       "1665        1665    7      0        KNeighborsClassifier     NaN  0.785714         7\n",
       "1680        1680    8      0        KNeighborsClassifier     NaN  0.724638         8\n",
       "1695        1695    9      0        KNeighborsClassifier     NaN  0.594203         9\n",
       "1710        1710   10      0        KNeighborsClassifier     NaN  0.513889        10\n",
       "1725        1725   11      0        KNeighborsClassifier     NaN  0.453333        11\n",
       "1740        1740   12      0        KNeighborsClassifier     NaN  0.358974        12\n",
       "1755        1755   13      0        KNeighborsClassifier     NaN  0.475000        13\n",
       "1770        1770   14      0        KNeighborsClassifier     NaN  0.687500        14\n",
       "1785        1785   15      0        KNeighborsClassifier     NaN  0.662500        15\n",
       "1800        1800   16      0        KNeighborsClassifier     NaN  0.575000        16\n",
       "1815        1815   17      0        KNeighborsClassifier     NaN  0.675000        17\n",
       "1830        1830   WC      0        KNeighborsClassifier     NaN  0.450000        18\n",
       "1845        1845   DV      0        KNeighborsClassifier     NaN  0.700000        19\n",
       "1860        1860   CC      0        KNeighborsClassifier     NaN  0.400000        20\n",
       "1875        1875   SB      0        KNeighborsClassifier     NaN  0.400000        21\n",
       "1890        1890    1      0          AdaBoostClassifier     NaN  0.612500         1\n",
       "1905        1905    2      0          AdaBoostClassifier     NaN  0.645570         2\n",
       "1920        1920    3      0          AdaBoostClassifier     NaN  0.571429         3\n",
       "1935        1935    4      0          AdaBoostClassifier     NaN  0.657534         4\n",
       "1950        1950    5      0          AdaBoostClassifier     NaN  0.563380         5\n",
       "1965        1965    6      0          AdaBoostClassifier     NaN  0.485714         6\n",
       "1980        1980    7      0          AdaBoostClassifier     NaN  0.785714         7\n",
       "1995        1995    8      0          AdaBoostClassifier     NaN  0.724638         8\n",
       "2010        2010    9      0          AdaBoostClassifier     NaN  0.608696         9\n",
       "2025        2025   10      0          AdaBoostClassifier     NaN  0.625000        10\n",
       "2040        2040   11      0          AdaBoostClassifier     NaN  0.693333        11\n",
       "2055        2055   12      0          AdaBoostClassifier     NaN  0.602564        12\n",
       "2070        2070   13      0          AdaBoostClassifier     NaN  0.587500        13\n",
       "2085        2085   14      0          AdaBoostClassifier     NaN  0.612500        14\n",
       "2100        2100   15      0          AdaBoostClassifier     NaN  0.662500        15\n",
       "2115        2115   16      0          AdaBoostClassifier     NaN  0.537500        16\n",
       "2130        2130   17      0          AdaBoostClassifier     NaN  0.675000        17\n",
       "2145        2145   WC      0          AdaBoostClassifier     NaN  0.550000        18\n",
       "2160        2160   DV      0          AdaBoostClassifier     NaN  0.750000        19\n",
       "2175        2175   CC      0          AdaBoostClassifier     NaN  0.400000        20\n",
       "2190        2190   SB      0          AdaBoostClassifier     NaN  0.800000        21\n",
       "2205        2205    1      0  GradientBoostingClassifier     NaN  0.612500         1\n",
       "2220        2220    2      0  GradientBoostingClassifier     NaN  0.645570         2\n",
       "2235        2235    3      0  GradientBoostingClassifier     NaN  0.571429         3\n",
       "2250        2250    4      0  GradientBoostingClassifier     NaN  0.657534         4\n",
       "2265        2265    5      0  GradientBoostingClassifier     NaN  0.563380         5\n",
       "2280        2280    6      0  GradientBoostingClassifier     NaN  0.471429         6\n",
       "2295        2295    7      0  GradientBoostingClassifier     NaN  0.785714         7\n",
       "2310        2310    8      0  GradientBoostingClassifier     NaN  0.724638         8\n",
       "2325        2325    9      0  GradientBoostingClassifier     NaN  0.623188         9\n",
       "2340        2340   10      0  GradientBoostingClassifier     NaN  0.625000        10\n",
       "2355        2355   11      0  GradientBoostingClassifier     NaN  0.693333        11\n",
       "2370        2370   12      0  GradientBoostingClassifier     NaN  0.602564        12\n",
       "2385        2385   13      0  GradientBoostingClassifier     NaN  0.575000        13\n",
       "2400        2400   14      0  GradientBoostingClassifier     NaN  0.612500        14\n",
       "2415        2415   15      0  GradientBoostingClassifier     NaN  0.662500        15\n",
       "2430        2430   16      0  GradientBoostingClassifier     NaN  0.537500        16\n",
       "2445        2445   17      0  GradientBoostingClassifier     NaN  0.675000        17\n",
       "2460        2460   WC      0  GradientBoostingClassifier     NaN  0.550000        18\n",
       "2475        2475   DV      0  GradientBoostingClassifier     NaN  0.750000        19\n",
       "2490        2490   CC      0  GradientBoostingClassifier     NaN  0.400000        20\n",
       "2505        2505   SB      0  GradientBoostingClassifier     NaN  0.400000        21\n",
       "2520        2520    1      0        NaiveBayesClassifier     NaN  0.612500         1\n",
       "2535        2535    2      0        NaiveBayesClassifier     NaN  0.645570         2\n",
       "2550        2550    3      0        NaiveBayesClassifier     NaN  0.571429         3\n",
       "2565        2565    4      0        NaiveBayesClassifier     NaN  0.657534         4\n",
       "2580        2580    5      0        NaiveBayesClassifier     NaN  0.563380         5\n",
       "2595        2595    6      0        NaiveBayesClassifier     NaN  0.471429         6\n",
       "2610        2610    7      0        NaiveBayesClassifier     NaN  0.785714         7\n",
       "2625        2625    8      0        NaiveBayesClassifier     NaN  0.724638         8\n",
       "2640        2640    9      0        NaiveBayesClassifier     NaN  0.608696         9\n",
       "2655        2655   10      0        NaiveBayesClassifier     NaN  0.625000        10\n",
       "2670        2670   11      0        NaiveBayesClassifier     NaN  0.693333        11\n",
       "2685        2685   12      0        NaiveBayesClassifier     NaN  0.602564        12\n",
       "2700        2700   13      0        NaiveBayesClassifier     NaN  0.575000        13\n",
       "2715        2715   14      0        NaiveBayesClassifier     NaN  0.612500        14\n",
       "2730        2730   15      0        NaiveBayesClassifier     NaN  0.662500        15\n",
       "2745        2745   16      0        NaiveBayesClassifier     NaN  0.537500        16\n",
       "2760        2760   17      0        NaiveBayesClassifier     NaN  0.675000        17\n",
       "2775        2775   WC      0        NaiveBayesClassifier     NaN  0.550000        18\n",
       "2790        2790   DV      0        NaiveBayesClassifier     NaN  0.700000        19\n",
       "2805        2805   CC      0        NaiveBayesClassifier     NaN  0.500000        20\n",
       "2820        2820   SB      0        NaiveBayesClassifier     NaN  0.400000        21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_C0 = weekly[weekly['Clump'] == 0]\n",
    "weekly_C0['week_int'] = weekly_C0['Week'].map(week_dict)\n",
    "weekly_C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5b571f-6211-41aa-bb39-be5ec22b715e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-f774ff27777e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weekly_C1['week_int'] = weekly_C1['Week'].map(week_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Week</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>week_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>436</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>526</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>541</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>601</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>616</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>706</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>721</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>736</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>751</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>781</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>826</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>856</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>901</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>961</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1036</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1051</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1081</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1096</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1156</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1171</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1186</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1201</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1276</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1321</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1336</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1351</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>1366</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1381</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1396</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1411</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>1426</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1441</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1456</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1486</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1501</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1516</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1531</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1546</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1561</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1576</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1606</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1621</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1636</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>1651</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1666</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1681</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>1711</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1726</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1741</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>1756</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1771</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>1786</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1801</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1816</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>1831</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>1846</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>1861</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1906</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1921</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1951</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>1966</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1981</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2041</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>2056</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2071</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>2101</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>2116</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>2131</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2146</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>2176</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2191</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2221</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2236</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>2251</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>2266</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>2281</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>2296</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2311</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>2326</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>2341</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>2356</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>2371</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2386</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>2416</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2431</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2446</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>2461</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2476</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2491</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>2506</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>2521</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2536</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2551</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>2581</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2596</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2611</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>2641</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2656</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>2671</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>2686</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2701</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>2716</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>2731</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>2746</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>2761</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2776</td>\n",
       "      <td>WC</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>2791</td>\n",
       "      <td>DV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2806</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>2821</td>\n",
       "      <td>SB</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Week  Clump                   Estimator  params  accuracy  week_int\n",
       "1              1    1      1          LogisticRegression     NaN  0.675000         1\n",
       "16            16    2      1          LogisticRegression     NaN  0.569620         2\n",
       "31            31    3      1          LogisticRegression     NaN  0.636364         3\n",
       "46            46    4      1          LogisticRegression     NaN  0.671233         4\n",
       "61            61    5      1          LogisticRegression     NaN  0.704225         5\n",
       "76            76    6      1          LogisticRegression     NaN  0.614286         6\n",
       "91            91    7      1          LogisticRegression     NaN  0.671429         7\n",
       "106          106    8      1          LogisticRegression     NaN  0.623188         8\n",
       "121          121    9      1          LogisticRegression     NaN  0.550725         9\n",
       "136          136   10      1          LogisticRegression     NaN  0.638889        10\n",
       "151          151   11      1          LogisticRegression     NaN  0.706667        11\n",
       "166          166   12      1          LogisticRegression     NaN  0.551282        12\n",
       "181          181   13      1          LogisticRegression     NaN  0.762500        13\n",
       "196          196   14      1          LogisticRegression     NaN  0.762500        14\n",
       "211          211   15      1          LogisticRegression     NaN  0.662500        15\n",
       "226          226   16      1          LogisticRegression     NaN  0.612500        16\n",
       "241          241   17      1          LogisticRegression     NaN  0.675000        17\n",
       "256          256   WC      1          LogisticRegression     NaN  0.600000        18\n",
       "271          271   DV      1          LogisticRegression     NaN  0.500000        19\n",
       "286          286   CC      1          LogisticRegression     NaN  0.500000        20\n",
       "301          301   SB      1          LogisticRegression     NaN  0.400000        21\n",
       "316          316    1      1           BaggingClassifier     NaN  0.675000         1\n",
       "331          331    2      1           BaggingClassifier     NaN  0.569620         2\n",
       "346          346    3      1           BaggingClassifier     NaN  0.636364         3\n",
       "361          361    4      1           BaggingClassifier     NaN  0.561644         4\n",
       "376          376    5      1           BaggingClassifier     NaN  0.704225         5\n",
       "391          391    6      1           BaggingClassifier     NaN  0.614286         6\n",
       "406          406    7      1           BaggingClassifier     NaN  0.671429         7\n",
       "421          421    8      1           BaggingClassifier     NaN  0.623188         8\n",
       "436          436    9      1           BaggingClassifier     NaN  0.550725         9\n",
       "451          451   10      1           BaggingClassifier     NaN  0.638889        10\n",
       "466          466   11      1           BaggingClassifier     NaN  0.706667        11\n",
       "481          481   12      1           BaggingClassifier     NaN  0.551282        12\n",
       "496          496   13      1           BaggingClassifier     NaN  0.762500        13\n",
       "511          511   14      1           BaggingClassifier     NaN  0.762500        14\n",
       "526          526   15      1           BaggingClassifier     NaN  0.662500        15\n",
       "541          541   16      1           BaggingClassifier     NaN  0.612500        16\n",
       "556          556   17      1           BaggingClassifier     NaN  0.675000        17\n",
       "571          571   WC      1           BaggingClassifier     NaN  0.600000        18\n",
       "586          586   DV      1           BaggingClassifier     NaN  0.500000        19\n",
       "601          601   CC      1           BaggingClassifier     NaN  0.500000        20\n",
       "616          616   SB      1           BaggingClassifier     NaN  0.600000        21\n",
       "631          631    1      1      RandomForestClassifier     NaN  0.675000         1\n",
       "646          646    2      1      RandomForestClassifier     NaN  0.569620         2\n",
       "661          661    3      1      RandomForestClassifier     NaN  0.636364         3\n",
       "676          676    4      1      RandomForestClassifier     NaN  0.671233         4\n",
       "691          691    5      1      RandomForestClassifier     NaN  0.704225         5\n",
       "706          706    6      1      RandomForestClassifier     NaN  0.614286         6\n",
       "721          721    7      1      RandomForestClassifier     NaN  0.671429         7\n",
       "736          736    8      1      RandomForestClassifier     NaN  0.623188         8\n",
       "751          751    9      1      RandomForestClassifier     NaN  0.550725         9\n",
       "766          766   10      1      RandomForestClassifier     NaN  0.638889        10\n",
       "781          781   11      1      RandomForestClassifier     NaN  0.706667        11\n",
       "796          796   12      1      RandomForestClassifier     NaN  0.551282        12\n",
       "811          811   13      1      RandomForestClassifier     NaN  0.762500        13\n",
       "826          826   14      1      RandomForestClassifier     NaN  0.762500        14\n",
       "841          841   15      1      RandomForestClassifier     NaN  0.662500        15\n",
       "856          856   16      1      RandomForestClassifier     NaN  0.612500        16\n",
       "871          871   17      1      RandomForestClassifier     NaN  0.675000        17\n",
       "886          886   WC      1      RandomForestClassifier     NaN  0.600000        18\n",
       "901          901   DV      1      RandomForestClassifier     NaN  0.550000        19\n",
       "916          916   CC      1      RandomForestClassifier     NaN  0.500000        20\n",
       "931          931   SB      1      RandomForestClassifier     NaN  0.400000        21\n",
       "946          946    1      1        ExtraTreesClassifier     NaN  0.675000         1\n",
       "961          961    2      1        ExtraTreesClassifier     NaN  0.569620         2\n",
       "976          976    3      1        ExtraTreesClassifier     NaN  0.636364         3\n",
       "991          991    4      1        ExtraTreesClassifier     NaN  0.671233         4\n",
       "1006        1006    5      1        ExtraTreesClassifier     NaN  0.704225         5\n",
       "1021        1021    6      1        ExtraTreesClassifier     NaN  0.614286         6\n",
       "1036        1036    7      1        ExtraTreesClassifier     NaN  0.671429         7\n",
       "1051        1051    8      1        ExtraTreesClassifier     NaN  0.623188         8\n",
       "1066        1066    9      1        ExtraTreesClassifier     NaN  0.550725         9\n",
       "1081        1081   10      1        ExtraTreesClassifier     NaN  0.638889        10\n",
       "1096        1096   11      1        ExtraTreesClassifier     NaN  0.706667        11\n",
       "1111        1111   12      1        ExtraTreesClassifier     NaN  0.551282        12\n",
       "1126        1126   13      1        ExtraTreesClassifier     NaN  0.762500        13\n",
       "1141        1141   14      1        ExtraTreesClassifier     NaN  0.762500        14\n",
       "1156        1156   15      1        ExtraTreesClassifier     NaN  0.662500        15\n",
       "1171        1171   16      1        ExtraTreesClassifier     NaN  0.612500        16\n",
       "1186        1186   17      1        ExtraTreesClassifier     NaN  0.675000        17\n",
       "1201        1201   WC      1        ExtraTreesClassifier     NaN  0.600000        18\n",
       "1216        1216   DV      1        ExtraTreesClassifier     NaN  0.500000        19\n",
       "1231        1231   CC      1        ExtraTreesClassifier     NaN  0.500000        20\n",
       "1246        1246   SB      1        ExtraTreesClassifier     NaN  0.600000        21\n",
       "1261        1261    1      1      DecisionTreeClassifier     NaN  0.675000         1\n",
       "1276        1276    2      1      DecisionTreeClassifier     NaN  0.569620         2\n",
       "1291        1291    3      1      DecisionTreeClassifier     NaN  0.636364         3\n",
       "1306        1306    4      1      DecisionTreeClassifier     NaN  0.671233         4\n",
       "1321        1321    5      1      DecisionTreeClassifier     NaN  0.704225         5\n",
       "1336        1336    6      1      DecisionTreeClassifier     NaN  0.614286         6\n",
       "1351        1351    7      1      DecisionTreeClassifier     NaN  0.671429         7\n",
       "1366        1366    8      1      DecisionTreeClassifier     NaN  0.623188         8\n",
       "1381        1381    9      1      DecisionTreeClassifier     NaN  0.550725         9\n",
       "1396        1396   10      1      DecisionTreeClassifier     NaN  0.638889        10\n",
       "1411        1411   11      1      DecisionTreeClassifier     NaN  0.706667        11\n",
       "1426        1426   12      1      DecisionTreeClassifier     NaN  0.551282        12\n",
       "1441        1441   13      1      DecisionTreeClassifier     NaN  0.762500        13\n",
       "1456        1456   14      1      DecisionTreeClassifier     NaN  0.762500        14\n",
       "1471        1471   15      1      DecisionTreeClassifier     NaN  0.662500        15\n",
       "1486        1486   16      1      DecisionTreeClassifier     NaN  0.612500        16\n",
       "1501        1501   17      1      DecisionTreeClassifier     NaN  0.675000        17\n",
       "1516        1516   WC      1      DecisionTreeClassifier     NaN  0.600000        18\n",
       "1531        1531   DV      1      DecisionTreeClassifier     NaN  0.500000        19\n",
       "1546        1546   CC      1      DecisionTreeClassifier     NaN  0.500000        20\n",
       "1561        1561   SB      1      DecisionTreeClassifier     NaN  0.200000        21\n",
       "1576        1576    1      1        KNeighborsClassifier     NaN  0.675000         1\n",
       "1591        1591    2      1        KNeighborsClassifier     NaN  0.620253         2\n",
       "1606        1606    3      1        KNeighborsClassifier     NaN  0.584416         3\n",
       "1621        1621    4      1        KNeighborsClassifier     NaN  0.589041         4\n",
       "1636        1636    5      1        KNeighborsClassifier     NaN  0.676056         5\n",
       "1651        1651    6      1        KNeighborsClassifier     NaN  0.542857         6\n",
       "1666        1666    7      1        KNeighborsClassifier     NaN  0.671429         7\n",
       "1681        1681    8      1        KNeighborsClassifier     NaN  0.739130         8\n",
       "1696        1696    9      1        KNeighborsClassifier     NaN  0.608696         9\n",
       "1711        1711   10      1        KNeighborsClassifier     NaN  0.541667        10\n",
       "1726        1726   11      1        KNeighborsClassifier     NaN  0.706667        11\n",
       "1741        1741   12      1        KNeighborsClassifier     NaN  0.564103        12\n",
       "1756        1756   13      1        KNeighborsClassifier     NaN  0.762500        13\n",
       "1771        1771   14      1        KNeighborsClassifier     NaN  0.712500        14\n",
       "1786        1786   15      1        KNeighborsClassifier     NaN  0.625000        15\n",
       "1801        1801   16      1        KNeighborsClassifier     NaN  0.550000        16\n",
       "1816        1816   17      1        KNeighborsClassifier     NaN  0.675000        17\n",
       "1831        1831   WC      1        KNeighborsClassifier     NaN  0.500000        18\n",
       "1846        1846   DV      1        KNeighborsClassifier     NaN  0.550000        19\n",
       "1861        1861   CC      1        KNeighborsClassifier     NaN  0.500000        20\n",
       "1876        1876   SB      1        KNeighborsClassifier     NaN  0.400000        21\n",
       "1891        1891    1      1          AdaBoostClassifier     NaN  0.675000         1\n",
       "1906        1906    2      1          AdaBoostClassifier     NaN  0.569620         2\n",
       "1921        1921    3      1          AdaBoostClassifier     NaN  0.636364         3\n",
       "1936        1936    4      1          AdaBoostClassifier     NaN  0.671233         4\n",
       "1951        1951    5      1          AdaBoostClassifier     NaN  0.704225         5\n",
       "1966        1966    6      1          AdaBoostClassifier     NaN  0.614286         6\n",
       "1981        1981    7      1          AdaBoostClassifier     NaN  0.671429         7\n",
       "1996        1996    8      1          AdaBoostClassifier     NaN  0.623188         8\n",
       "2011        2011    9      1          AdaBoostClassifier     NaN  0.550725         9\n",
       "2026        2026   10      1          AdaBoostClassifier     NaN  0.638889        10\n",
       "2041        2041   11      1          AdaBoostClassifier     NaN  0.706667        11\n",
       "2056        2056   12      1          AdaBoostClassifier     NaN  0.551282        12\n",
       "2071        2071   13      1          AdaBoostClassifier     NaN  0.762500        13\n",
       "2086        2086   14      1          AdaBoostClassifier     NaN  0.762500        14\n",
       "2101        2101   15      1          AdaBoostClassifier     NaN  0.662500        15\n",
       "2116        2116   16      1          AdaBoostClassifier     NaN  0.612500        16\n",
       "2131        2131   17      1          AdaBoostClassifier     NaN  0.675000        17\n",
       "2146        2146   WC      1          AdaBoostClassifier     NaN  0.600000        18\n",
       "2161        2161   DV      1          AdaBoostClassifier     NaN  0.550000        19\n",
       "2176        2176   CC      1          AdaBoostClassifier     NaN  0.500000        20\n",
       "2191        2191   SB      1          AdaBoostClassifier     NaN  0.400000        21\n",
       "2206        2206    1      1  GradientBoostingClassifier     NaN  0.675000         1\n",
       "2221        2221    2      1  GradientBoostingClassifier     NaN  0.582278         2\n",
       "2236        2236    3      1  GradientBoostingClassifier     NaN  0.636364         3\n",
       "2251        2251    4      1  GradientBoostingClassifier     NaN  0.671233         4\n",
       "2266        2266    5      1  GradientBoostingClassifier     NaN  0.704225         5\n",
       "2281        2281    6      1  GradientBoostingClassifier     NaN  0.614286         6\n",
       "2296        2296    7      1  GradientBoostingClassifier     NaN  0.671429         7\n",
       "2311        2311    8      1  GradientBoostingClassifier     NaN  0.623188         8\n",
       "2326        2326    9      1  GradientBoostingClassifier     NaN  0.550725         9\n",
       "2341        2341   10      1  GradientBoostingClassifier     NaN  0.638889        10\n",
       "2356        2356   11      1  GradientBoostingClassifier     NaN  0.706667        11\n",
       "2371        2371   12      1  GradientBoostingClassifier     NaN  0.551282        12\n",
       "2386        2386   13      1  GradientBoostingClassifier     NaN  0.762500        13\n",
       "2401        2401   14      1  GradientBoostingClassifier     NaN  0.762500        14\n",
       "2416        2416   15      1  GradientBoostingClassifier     NaN  0.662500        15\n",
       "2431        2431   16      1  GradientBoostingClassifier     NaN  0.612500        16\n",
       "2446        2446   17      1  GradientBoostingClassifier     NaN  0.675000        17\n",
       "2461        2461   WC      1  GradientBoostingClassifier     NaN  0.600000        18\n",
       "2476        2476   DV      1  GradientBoostingClassifier     NaN  0.500000        19\n",
       "2491        2491   CC      1  GradientBoostingClassifier     NaN  0.500000        20\n",
       "2506        2506   SB      1  GradientBoostingClassifier     NaN  0.400000        21\n",
       "2521        2521    1      1        NaiveBayesClassifier     NaN  0.675000         1\n",
       "2536        2536    2      1        NaiveBayesClassifier     NaN  0.569620         2\n",
       "2551        2551    3      1        NaiveBayesClassifier     NaN  0.636364         3\n",
       "2566        2566    4      1        NaiveBayesClassifier     NaN  0.671233         4\n",
       "2581        2581    5      1        NaiveBayesClassifier     NaN  0.704225         5\n",
       "2596        2596    6      1        NaiveBayesClassifier     NaN  0.614286         6\n",
       "2611        2611    7      1        NaiveBayesClassifier     NaN  0.671429         7\n",
       "2626        2626    8      1        NaiveBayesClassifier     NaN  0.623188         8\n",
       "2641        2641    9      1        NaiveBayesClassifier     NaN  0.550725         9\n",
       "2656        2656   10      1        NaiveBayesClassifier     NaN  0.638889        10\n",
       "2671        2671   11      1        NaiveBayesClassifier     NaN  0.706667        11\n",
       "2686        2686   12      1        NaiveBayesClassifier     NaN  0.551282        12\n",
       "2701        2701   13      1        NaiveBayesClassifier     NaN  0.762500        13\n",
       "2716        2716   14      1        NaiveBayesClassifier     NaN  0.762500        14\n",
       "2731        2731   15      1        NaiveBayesClassifier     NaN  0.662500        15\n",
       "2746        2746   16      1        NaiveBayesClassifier     NaN  0.612500        16\n",
       "2761        2761   17      1        NaiveBayesClassifier     NaN  0.675000        17\n",
       "2776        2776   WC      1        NaiveBayesClassifier     NaN  0.600000        18\n",
       "2791        2791   DV      1        NaiveBayesClassifier     NaN  0.500000        19\n",
       "2806        2806   CC      1        NaiveBayesClassifier     NaN  0.500000        20\n",
       "2821        2821   SB      1        NaiveBayesClassifier     NaN  0.400000        21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_C1 = weekly[weekly['Clump'] == 1]\n",
    "weekly_C1['week_int'] = weekly_C1['Week'].map(week_dict)\n",
    "weekly_C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "396e09b4-4666-40b5-b4e8-8878ae03c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-7c14d629317d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weekly_C2['week_int'] = weekly_C2['Week'].map(week_dict)\n"
     ]
    }
   ],
   "source": [
    "weekly_C2 = weekly[weekly['Clump'] == 2]\n",
    "weekly_C2['week_int'] = weekly_C2['Week'].map(week_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f136fc-6753-4c99-99ac-ff3dff5d7b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-2a28b1ae8dc8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weekly_C3['week_int'] = weekly_C3['Week'].map(week_dict)\n"
     ]
    }
   ],
   "source": [
    "weekly_C3 = weekly[weekly['Clump'] == 3]\n",
    "weekly_C3['week_int'] = weekly_C3['Week'].map(week_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5a567c6-dc7f-4028-b934-f388dc202e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make null model for graphing\n",
    "week_null = np.zeros((1,21))\n",
    "week_null  = week_null  + 0.536251\n",
    "week_null.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83c1b605-8e95-4aa1-a777-d4cbbb959628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot - quarterly accuracy scores by week\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(weekly_C0['week_int'].unique(), weekly_C0.groupby('week_int')['accuracy'].mean(), label = \"Qtr 1 Mean accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.plot(weekly_C1['week_int'].unique(), weekly_C1.groupby('week_int')['accuracy'].mean(), label = \"Qtr 2 Mean accuracy\", marker='>',\n",
    "        markersize=10)\n",
    "plt.plot(weekly_C2['week_int'].unique(), weekly_C2.groupby('week_int')['accuracy'].mean(), label = \"Qtr 3 Mean accuracy\", marker='v',\n",
    "        markersize=10)\n",
    "plt.plot(weekly_C3['week_int'].unique(), weekly_C3.groupby('week_int')['accuracy'].mean(), label = \"Qtr 4 Mean accuracy\", marker='<',\n",
    "        markersize=10)\n",
    "plt.plot(weekly_C3['week_int'].unique(), week_null.T, linewidth=5, label=\"Null model\")\n",
    "plt.axvline(x=17.5,linewidth=7, color='black')\n",
    "plt.xlabel(\"Week of Season\", fontsize=40)\n",
    "plt.xticks(np.arange(1, 22, step=1))\n",
    "plt.ylabel(\"Accuracy in percentage\", fontsize=40)\n",
    "plt.grid()\n",
    "fig.patch.set_facecolor('aqua')\n",
    "ax.set_facecolor('palegreen')\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "        #https://www.pauldesalvo.com/convert-y-axis-labels-to-a-percentage-in-python-matplotlib/\n",
    "ax.text(13.75, .78, 'Regular season', fontsize=24)\n",
    "ax.text(17.75, .78, 'Playoffs', fontsize=24)\n",
    "plt.legend(loc=8, fontsize=20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daab1c79-0b02-4de6-b01a-e3c1e8724655",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>156</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>212</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>214</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>230</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>232</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>233</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>252</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>275</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>279</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>283</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>312</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>313</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>316</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>317</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>328</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>331</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>350</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>352</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>353</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>354</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>355</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>363</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>368</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>370</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>372</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>374</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>403</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>417</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>419</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>425</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>427</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>428</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>429</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>434</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>436</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>439</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>440</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>442</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>443</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>444</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>445</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>446</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>447</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>457</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>461</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>468</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>469</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>476</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>514</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>515</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>516</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>517</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>519</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>520</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>521</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>522</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>523</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>526</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>527</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>528</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>537</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>538</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>539</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>541</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>542</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>543</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>544</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>545</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>547</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>548</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>549</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>550</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>551</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>552</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>558</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>559</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>560</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>561</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>562</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>563</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>574</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>575</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>576</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>577</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>580</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>581</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>582</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>587</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>588</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>590</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>593</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>594</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>601</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>611</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>612</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>614</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>616</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>617</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>618</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>619</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>620</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>621</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>622</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>623</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>624</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>626</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>627</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>629</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>632</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>633</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>640</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>642</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>648</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>649</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>650</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>651</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>652</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>654</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>658</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>659</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>660</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>661</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>663</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>664</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>666</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>667</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>668</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>669</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>670</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>671</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>672</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>673</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>677</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>680</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>681</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>683</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>690</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>692</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>693</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>694</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>695</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>696</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>697</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>698</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>699</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>701</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>703</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>704</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>706</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>707</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>710</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>711</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>712</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>717</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>720</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>721</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>722</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>723</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>724</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>726</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>727</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>728</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>729</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>730</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>731</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>732</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>733</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>734</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>735</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>736</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>738</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>744</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>745</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>746</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>747</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>748</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>751</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>752</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>753</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>754</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>755</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>756</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>758</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>759</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>760</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>761</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>762</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>763</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>764</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>765</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>767</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>768</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>769</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>770</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>776</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>777</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>779</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>780</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>781</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>782</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>783</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>784</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>785</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>786</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>787</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>788</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>789</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>790</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>791</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>792</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>793</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>794</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>801</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>802</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>803</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>804</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>805</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>806</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>807</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>809</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>814</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>815</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>816</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>817</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>818</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>819</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>820</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>822</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>823</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>824</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>825</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>826</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>827</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>830</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>831</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>832</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>834</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>838</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>839</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>843</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>844</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>845</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>846</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>847</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>848</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>849</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>850</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>851</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>854</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>856</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>857</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>858</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>859</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>861</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>862</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>863</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>864</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>865</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>866</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>867</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>868</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>872</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>874</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>875</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>876</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>877</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>878</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>879</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>880</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>881</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>882</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>883</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>884</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>891</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>892</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>893</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>894</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>895</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>896</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>897</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>899</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>901</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>902</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>903</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>904</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>906</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>907</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>908</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>909</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>910</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>911</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>919</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>922</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>937</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>943</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>947</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>948</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>949</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>950</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>951</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>952</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>953</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>954</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>955</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>956</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>957</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>958</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>959</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>961</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>962</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>963</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>964</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>965</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>966</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>967</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>968</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>969</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>983</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>984</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>985</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>986</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>987</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>988</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>989</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1008</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1009</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1010</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1011</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1012</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1013</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1014</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1015</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1016</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1017</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1021</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1023</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>1024</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1025</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1027</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1028</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1029</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1030</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>1031</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1032</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1033</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1034</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1036</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1037</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1039</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1040</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1041</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1042</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1043</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1044</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1046</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1047</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>1048</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1049</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1051</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1052</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1053</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1054</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1055</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1056</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1057</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1058</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1059</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1060</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1061</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1062</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1063</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1064</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1067</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1071</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1072</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1073</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>1074</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1075</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>1076</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>1077</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1078</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>1079</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1080</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1081</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1082</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1084</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1085</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1086</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1087</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1088</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1089</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1096</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1097</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1098</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1099</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1100</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1101</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1102</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1103</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1104</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1105</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1106</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1108</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1114</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1115</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>1116</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1117</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1118</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1119</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1120</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1121</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1122</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1123</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1127</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1128</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1129</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1130</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>1131</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>1132</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>1133</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>1134</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1136</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1142</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>1143</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1144</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1145</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1146</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1147</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1148</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1149</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1150</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1151</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1152</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>1153</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>1154</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1156</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1157</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1158</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>1159</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1160</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1161</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1162</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1163</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1164</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1165</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1166</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1167</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1168</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>1169</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1170</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1171</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>1172</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>1173</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>1174</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1175</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1176</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1177</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1178</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1179</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1180</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1181</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1182</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>1183</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1184</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1185</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1186</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>1187</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>1188</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1189</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1190</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>1191</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1192</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>1193</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1194</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1195</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1196</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1197</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1198</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1199</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1201</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1202</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1203</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1204</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>1205</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1206</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1207</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1208</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1209</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1210</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1212</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1214</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1217</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1218</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>1219</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1220</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1227</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1228</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>1229</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1232</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1233</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1234</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1235</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1236</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1237</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1238</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1239</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1240</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1241</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1242</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1243</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1244</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1250</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1252</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1255</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>1256</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1258</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1259</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1261</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1262</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1263</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1264</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1267</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1268</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1269</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1270</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1271</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1272</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1273</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1274</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1275</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1276</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>1278</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1279</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1280</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1281</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1282</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1283</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1284</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1285</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1287</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1288</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1289</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1291</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1295</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1297</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1299</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1301</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1302</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1303</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1304</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1307</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1308</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1309</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1310</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1311</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1312</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1313</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1314</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1315</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1316</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1317</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1319</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1320</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1321</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1322</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1323</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>1324</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>1325</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>1326</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1327</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1328</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1329</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1330</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1331</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1332</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>1333</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1334</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1335</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1336</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1337</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>1338</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1339</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1340</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1341</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>1342</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1343</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1344</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1345</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1346</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1347</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1348</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1350</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1351</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1352</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1353</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>1354</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1355</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1356</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>1357</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1358</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1359</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1360</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1361</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1362</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>1363</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>1364</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1365</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>1366</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1367</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1368</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1369</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1370</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1371</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1372</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1373</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1374</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>1375</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>1376</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>1377</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>1379</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>1380</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1381</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>1382</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1383</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>1384</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1385</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1386</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1387</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1388</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>1389</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1391</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1392</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1393</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1394</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1396</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1397</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1398</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1399</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>1400</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>1401</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1402</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1403</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1404</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1405</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1411</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1412</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1413</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>1414</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>1415</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>1416</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>1417</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>1418</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1419</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1420</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1421</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>1422</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>1423</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>1424</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1425</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>1426</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>1427</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1428</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>1429</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>1430</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1431</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1432</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1433</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1434</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1435</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1436</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1437</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1438</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1439</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1441</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1442</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1443</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1444</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1445</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1446</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1447</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1448</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1449</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1450</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1451</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1452</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1453</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1454</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1455</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1456</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1457</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1458</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1459</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>1460</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1461</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1462</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>1463</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>1464</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1465</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1466</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1467</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1468</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1469</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1470</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1472</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1473</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>1474</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>1476</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1477</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1478</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1479</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1480</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1481</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1482</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1483</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1484</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1485</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1486</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1487</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1488</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1489</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1490</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1491</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1492</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>1493</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1494</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1495</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1496</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1497</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1498</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1499</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1501</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1502</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1503</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1504</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1505</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1506</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1507</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1508</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1509</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1510</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1511</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1512</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1513</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1514</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1515</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1516</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1517</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1518</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>1519</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1520</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1521</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1522</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1523</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1524</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1525</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1526</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1527</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1528</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1529</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1531</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1532</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1533</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>1534</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1535</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1536</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1537</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>1538</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1539</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1540</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1541</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1542</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1543</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1544</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1545</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1546</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>1547</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>1548</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1549</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1550</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>1551</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1552</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>1553</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>1554</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>1555</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1556</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>1557</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>1558</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1559</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1561</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>1562</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>1563</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1564</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>1565</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1566</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1567</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1568</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>1569</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>1570</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>1571</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1572</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>1573</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>1574</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1575</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1576</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1577</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1578</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1579</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1580</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>1581</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1582</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1583</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1584</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1585</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1586</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1587</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1588</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1589</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1590</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1591</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>1592</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1593</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1594</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1595</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1598</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1599</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1600</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1601</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1602</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1603</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1604</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1605</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1606</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1607</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1608</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1609</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1610</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1611</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1612</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1613</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1614</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1615</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1616</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1617</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1618</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1619</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1621</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1622</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1623</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>1624</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>1625</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1626</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1629</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1630</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1631</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1632</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1633</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1634</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1635</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1636</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1637</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1638</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>1640</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1641</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>1642</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>1643</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>1644</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>1645</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1647</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1649</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1650</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>1651</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1652</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1653</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1654</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1655</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1656</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>1658</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1659</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>1660</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1661</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>1662</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1663</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>1664</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1666</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1667</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>1668</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1669</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1670</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1671</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1672</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1673</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1674</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1675</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1676</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1677</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1678</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1679</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1680</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1681</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>1682</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1683</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1684</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1685</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1686</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1687</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1688</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>1689</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>1690</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>1691</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>1692</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>1693</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>1694</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1697</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1698</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>1700</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>1701</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>1702</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1703</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1704</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1705</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1706</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>1707</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>1708</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1709</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>1711</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1713</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1714</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1715</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1716</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>1717</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>1718</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>1719</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1720</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>1721</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>1722</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1723</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1724</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1725</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1726</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1727</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>1728</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>1729</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>1730</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>1731</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>1732</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>1733</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>1734</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>1735</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>1736</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1737</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1738</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1739</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1740</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1741</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1742</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1744</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1747</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>1748</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>1749</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>1750</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1751</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>1752</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>1753</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>1754</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1755</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>1756</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>1757</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>1758</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1759</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1760</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1761</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1762</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>1763</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>1764</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>1765</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1766</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1767</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1768</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>1769</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1770</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1771</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1772</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1773</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1774</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1775</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1776</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1777</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1778</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1779</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1780</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1781</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1782</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1783</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1784</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1785</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>1786</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1787</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1788</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1789</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1791</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>1792</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1793</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1794</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1795</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1796</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1797</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1798</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>1799</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1800</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1801</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>1802</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1803</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>1804</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>1805</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1806</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1807</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1808</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>1809</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>1810</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>1811</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1812</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>1813</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1814</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1815</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1816</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1817</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>1818</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>1819</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1820</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>1821</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>1822</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>1823</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>1824</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>1825</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>1826</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1827</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>1828</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>1829</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>1830</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>1831</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1832</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>1833</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1834</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>1835</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>1836</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>1837</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>1838</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>1839</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>1840</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1841</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>1842</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>1843</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>1844</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>1845</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>1846</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1847</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>1848</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1849</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1850</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1851</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>1852</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>1853</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>1854</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>1855</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>1856</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>1857</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>1858</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>1859</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1860</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>1861</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1862</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1863</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1864</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>1865</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>1866</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1867</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1868</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1869</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1870</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1871</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1872</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1873</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1874</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1875</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1877</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>1878</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1879</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1880</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1881</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1882</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1883</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1884</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>1885</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1886</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>1887</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1888</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>1889</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1890</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1891</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>1892</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1893</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1894</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>1895</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>1896</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>1897</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>1898</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1899</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>1900</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1901</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>1902</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1903</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>1904</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1905</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1906</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>1907</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>1908</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>1909</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1910</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>1911</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>1912</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>1913</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>1914</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>1915</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>1916</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1917</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>1918</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1919</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1920</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1921</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>1922</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>1923</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>1924</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>1925</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>1926</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>1927</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1929</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1930</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>1931</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>1932</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>1933</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1934</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1940</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>1941</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>1942</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1943</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1944</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>1945</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1946</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1947</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>1948</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>1949</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1950</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1951</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>1952</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>1953</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>1954</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1955</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>1956</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>1957</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1958</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>1959</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>1960</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>1961</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>1962</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>1963</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>1964</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1965</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>1966</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1967</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>1968</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>1969</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>1970</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1971</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>1972</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1973</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1974</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>1975</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>1976</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1977</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1978</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1979</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1980</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1981</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1982</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1983</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1984</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1985</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1986</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1988</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1989</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1990</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1991</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1992</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1993</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1994</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2001</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2002</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2003</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2004</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2005</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2006</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2007</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2008</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2009</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2017</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2023</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>2024</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2027</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>2028</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2029</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>2030</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2031</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2032</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2033</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2034</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2035</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2036</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2037</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2038</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2039</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2040</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2041</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>2042</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2043</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2044</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2045</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2046</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2047</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2048</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2049</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2050</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>2051</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>2052</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>2053</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>2054</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>2056</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>2057</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>2058</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2059</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2060</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2061</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>2062</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2063</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2064</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>2065</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2066</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2067</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2068</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>2069</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2070</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2071</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2072</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>2073</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2074</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2075</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2076</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>2077</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2078</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>2079</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>2080</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>2081</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>2082</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>2088</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>2089</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>2090</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>2091</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>2092</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>2093</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2094</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>2095</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2096</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2097</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>2098</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>2099</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2100</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>2101</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>2102</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>2103</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>2104</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2105</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2106</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2107</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2108</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>2109</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>2110</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>2111</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>2112</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>2113</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>2114</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2115</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>2116</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>2117</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>2118</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>2119</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>2120</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>2121</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2122</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>2123</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>2124</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2125</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2126</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2127</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2128</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2129</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2130</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>2131</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>2132</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>2133</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2134</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2135</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2136</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2137</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>2138</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2139</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2140</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>2141</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>2142</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>2143</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>2144</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2145</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>2146</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>2147</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>2148</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>2154</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>2162</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>2163</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2164</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>2165</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>2166</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>2167</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2168</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2169</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2170</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2171</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2172</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2173</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2174</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2175</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>2176</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>2177</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2178</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2179</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2180</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2181</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>2182</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>2183</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>2184</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>2185</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2186</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2187</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2188</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2189</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2191</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2192</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2193</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2194</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2195</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2196</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2197</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2198</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>2199</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2200</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2201</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2202</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2203</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2204</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2205</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2206</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>2207</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>2208</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>2209</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>2210</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>2211</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2212</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>2213</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>2214</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>2215</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>2216</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>2217</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>2218</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>2219</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2220</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2221</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>2222</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2223</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2224</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>2225</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>2226</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>2227</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>2228</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>2229</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2230</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2231</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2232</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2233</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2234</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2235</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2236</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2237</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>2238</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>2239</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>2240</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>2241</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2242</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>2243</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>2244</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2245</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2246</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2247</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>2248</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>2249</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2250</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>2251</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>2252</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>2253</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>2254</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>2255</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>2256</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2257</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2258</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2259</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>2260</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2261</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2262</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2263</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2264</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2265</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>2266</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>2267</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>2268</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2269</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2270</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2271</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2272</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2273</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2274</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2275</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2276</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2277</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>2278</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>2279</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>2280</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>2281</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>2282</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>2283</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2284</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>2285</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>2286</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>2287</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>2288</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>2289</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>2290</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2291</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>2292</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>2293</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>2294</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2295</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>2296</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>2297</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>2298</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>2299</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>2300</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>2301</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>2302</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>2303</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>2304</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>2305</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>2306</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2307</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2308</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>2309</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>2310</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2311</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2312</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>2313</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>2314</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>2315</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>2316</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>2317</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>2318</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>2319</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>2320</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>2321</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>2322</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>2323</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>2324</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2325</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>2326</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>2327</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>2328</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>2329</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>2330</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>2331</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>2332</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>2333</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>2334</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>2335</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2336</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>2337</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>2338</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>2339</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2340</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>2341</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2342</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>2343</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>2344</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>2345</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>2346</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2347</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>2348</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>2349</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>2350</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>2352</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>2353</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>2354</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>2355</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>2356</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>2357</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>2358</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>2359</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>2360</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>2361</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>2363</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2364</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2365</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>2366</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>2367</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>2368</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>2369</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>2370</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>2371</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>2372</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>2373</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2374</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>2375</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>2376</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>2377</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2378</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>2379</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2380</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2381</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2382</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2383</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>2384</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2385</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2386</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2387</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2388</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>2389</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>2390</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>2391</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>2392</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>2393</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2395</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2396</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2397</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2399</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2402</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>2404</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>2405</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>2407</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>2408</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2409</td>\n",
       "      <td>2000</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>2410</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>2411</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2412</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>2413</td>\n",
       "      <td>2000</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>2414</td>\n",
       "      <td>2000</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2415</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>2416</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>2417</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>2418</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2419</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>2420</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>2421</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>2422</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>2423</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>2424</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>2425</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>2426</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>2427</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2428</td>\n",
       "      <td>2001</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>2429</td>\n",
       "      <td>2001</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2430</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2431</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>2432</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>2433</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>2434</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>2435</td>\n",
       "      <td>2002</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>2436</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>2437</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>2438</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>2439</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>2440</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>2441</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>2442</td>\n",
       "      <td>2002</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>2443</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>2444</td>\n",
       "      <td>2002</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>2445</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2446</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2447</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2448</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2449</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>2450</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2451</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>2452</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2453</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>2454</td>\n",
       "      <td>2003</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2455</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>2456</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>2457</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>2458</td>\n",
       "      <td>2003</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>2459</td>\n",
       "      <td>2003</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>2460</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>2461</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>2462</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>2463</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>2464</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>2465</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>2466</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2467</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>2468</td>\n",
       "      <td>2004</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>2469</td>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2470</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2471</td>\n",
       "      <td>2004</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2472</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2473</td>\n",
       "      <td>2004</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2474</td>\n",
       "      <td>2004</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2475</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2476</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2477</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2478</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2479</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2480</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2481</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2482</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2483</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2484</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>2485</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2486</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>2487</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>2488</td>\n",
       "      <td>2005</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>2489</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2490</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2491</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>2492</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>2493</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2494</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>2006</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>2501</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>2502</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>2503</td>\n",
       "      <td>2006</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>2504</td>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>2505</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>2506</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>2507</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>2508</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>2509</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>2510</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2511</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2512</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2513</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2514</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>2515</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>2516</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>2517</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>2518</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2519</td>\n",
       "      <td>2007</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2520</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>2521</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>2522</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>2523</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>2524</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2525</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>2526</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>2527</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>2528</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>2529</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>2530</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2531</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>2532</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2533</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2534</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2535</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2536</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2537</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2538</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>2539</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>2540</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>2541</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>2542</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2543</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>2544</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>2545</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2546</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>2547</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>2548</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>2549</td>\n",
       "      <td>2009</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2551</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>2552</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>2553</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2554</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2555</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2556</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2557</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2558</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2559</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2560</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>2561</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>2562</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2563</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>2564</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>2565</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>2567</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>2568</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>2569</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>2570</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>2571</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>2572</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>2573</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>2574</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2575</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>2576</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2577</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>2578</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2579</td>\n",
       "      <td>2011</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2580</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>2581</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2582</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>2583</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>2584</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>2585</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>2586</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>2587</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2588</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2589</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>2590</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2591</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2592</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>2593</td>\n",
       "      <td>2012</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2594</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2595</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2596</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2597</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2598</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>2599</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2600</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>2601</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>2602</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2603</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>2604</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>2605</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>2606</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>2607</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>2608</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>2609</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2610</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2611</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2612</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>2613</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>2614</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>2615</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>2616</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>2617</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>2618</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>2619</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>2620</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>2621</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>2622</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>2014</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>2624</td>\n",
       "      <td>2014</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>2627</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>2628</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>2629</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>2630</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>2631</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>2632</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2633</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>2634</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>2635</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2636</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2637</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>2638</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>2639</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2640</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>2641</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>2642</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>2643</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>2644</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>2645</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>2646</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2647</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2648</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2649</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2650</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2651</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2652</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2653</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>2654</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2655</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2656</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2657</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2658</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2659</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>2660</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>2661</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>2662</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2663</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2664</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2665</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>2666</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>2667</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>2668</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>2669</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2670</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>2671</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>2672</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>2673</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>2674</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>2675</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>2676</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2677</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>2678</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>2679</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2680</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>2681</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>2682</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>2683</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>2684</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>2685</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>2686</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>2687</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>2688</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>2689</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2690</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2691</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2692</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2693</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2694</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>2695</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>2696</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>2697</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2698</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2699</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Year  Clump                   Estimator  params  accuracy\n",
       "0              0  2000      0          LogisticRegression     NaN  0.634921\n",
       "1              1  2000      1          LogisticRegression     NaN  0.634921\n",
       "2              2  2000      2          LogisticRegression     NaN  0.603175\n",
       "3              3  2000      3          LogisticRegression     NaN  0.666667\n",
       "4              4  2000      4          LogisticRegression     NaN  0.714286\n",
       "5              5  2000      5          LogisticRegression     NaN  0.619048\n",
       "6              6  2000      6          LogisticRegression     NaN  0.650794\n",
       "7              7  2000      7          LogisticRegression     NaN  0.587302\n",
       "8              8  2000      8          LogisticRegression     NaN  0.666667\n",
       "9              9  2000      9          LogisticRegression     NaN  0.714286\n",
       "10            10  2000     10          LogisticRegression     NaN  0.698413\n",
       "11            11  2000     11          LogisticRegression     NaN  0.793651\n",
       "12            12  2000     12          LogisticRegression     NaN  0.809524\n",
       "13            13  2000     13          LogisticRegression     NaN  0.746032\n",
       "14            14  2000     14          LogisticRegression     NaN  0.841270\n",
       "15            15  2001      0          LogisticRegression     NaN  0.633333\n",
       "16            16  2001      1          LogisticRegression     NaN  0.666667\n",
       "17            17  2001      2          LogisticRegression     NaN  0.550000\n",
       "18            18  2001      3          LogisticRegression     NaN  0.650000\n",
       "19            19  2001      4          LogisticRegression     NaN  0.700000\n",
       "20            20  2001      5          LogisticRegression     NaN  0.700000\n",
       "21            21  2001      6          LogisticRegression     NaN  0.666667\n",
       "22            22  2001      7          LogisticRegression     NaN  0.683333\n",
       "23            23  2001      8          LogisticRegression     NaN  0.633333\n",
       "24            24  2001      9          LogisticRegression     NaN  0.716667\n",
       "25            25  2001     10          LogisticRegression     NaN  0.783333\n",
       "26            26  2001     11          LogisticRegression     NaN  0.766667\n",
       "27            27  2001     12          LogisticRegression     NaN  0.733333\n",
       "28            28  2001     13          LogisticRegression     NaN  0.766667\n",
       "29            29  2001     14          LogisticRegression     NaN  0.766667\n",
       "30            30  2002      0          LogisticRegression     NaN  0.690141\n",
       "31            31  2002      1          LogisticRegression     NaN  0.619718\n",
       "32            32  2002      2          LogisticRegression     NaN  0.563380\n",
       "33            33  2002      3          LogisticRegression     NaN  0.605634\n",
       "34            34  2002      4          LogisticRegression     NaN  0.676056\n",
       "35            35  2002      5          LogisticRegression     NaN  0.605634\n",
       "36            36  2002      6          LogisticRegression     NaN  0.661972\n",
       "37            37  2002      7          LogisticRegression     NaN  0.676056\n",
       "38            38  2002      8          LogisticRegression     NaN  0.676056\n",
       "39            39  2002      9          LogisticRegression     NaN  0.633803\n",
       "40            40  2002     10          LogisticRegression     NaN  0.718310\n",
       "41            41  2002     11          LogisticRegression     NaN  0.732394\n",
       "42            42  2002     12          LogisticRegression     NaN  0.718310\n",
       "43            43  2002     13          LogisticRegression     NaN  0.661972\n",
       "44            44  2002     14          LogisticRegression     NaN  0.760563\n",
       "45            45  2003      0          LogisticRegression     NaN  0.656716\n",
       "46            46  2003      1          LogisticRegression     NaN  0.671642\n",
       "47            47  2003      2          LogisticRegression     NaN  0.641791\n",
       "48            48  2003      3          LogisticRegression     NaN  0.582090\n",
       "49            49  2003      4          LogisticRegression     NaN  0.746269\n",
       "50            50  2003      5          LogisticRegression     NaN  0.656716\n",
       "51            51  2003      6          LogisticRegression     NaN  0.731343\n",
       "52            52  2003      7          LogisticRegression     NaN  0.686567\n",
       "53            53  2003      8          LogisticRegression     NaN  0.746269\n",
       "54            54  2003      9          LogisticRegression     NaN  0.746269\n",
       "55            55  2003     10          LogisticRegression     NaN  0.746269\n",
       "56            56  2003     11          LogisticRegression     NaN  0.820896\n",
       "57            57  2003     12          LogisticRegression     NaN  0.805970\n",
       "58            58  2003     13          LogisticRegression     NaN  0.716418\n",
       "59            59  2003     14          LogisticRegression     NaN  0.850746\n",
       "60            60  2004      0          LogisticRegression     NaN  0.619048\n",
       "61            61  2004      1          LogisticRegression     NaN  0.539683\n",
       "62            62  2004      2          LogisticRegression     NaN  0.539683\n",
       "63            63  2004      3          LogisticRegression     NaN  0.650794\n",
       "64            64  2004      4          LogisticRegression     NaN  0.746032\n",
       "65            65  2004      5          LogisticRegression     NaN  0.634921\n",
       "66            66  2004      6          LogisticRegression     NaN  0.634921\n",
       "67            67  2004      7          LogisticRegression     NaN  0.587302\n",
       "68            68  2004      8          LogisticRegression     NaN  0.714286\n",
       "69            69  2004      9          LogisticRegression     NaN  0.666667\n",
       "70            70  2004     10          LogisticRegression     NaN  0.809524\n",
       "71            71  2004     11          LogisticRegression     NaN  0.746032\n",
       "72            72  2004     12          LogisticRegression     NaN  0.746032\n",
       "73            73  2004     13          LogisticRegression     NaN  0.666667\n",
       "74            74  2004     14          LogisticRegression     NaN  0.809524\n",
       "75            75  2005      0          LogisticRegression     NaN  0.617647\n",
       "76            76  2005      1          LogisticRegression     NaN  0.676471\n",
       "77            77  2005      2          LogisticRegression     NaN  0.661765\n",
       "78            78  2005      3          LogisticRegression     NaN  0.470588\n",
       "79            79  2005      4          LogisticRegression     NaN  0.720588\n",
       "80            80  2005      5          LogisticRegression     NaN  0.647059\n",
       "81            81  2005      6          LogisticRegression     NaN  0.647059\n",
       "82            82  2005      7          LogisticRegression     NaN  0.676471\n",
       "83            83  2005      8          LogisticRegression     NaN  0.544118\n",
       "84            84  2005      9          LogisticRegression     NaN  0.647059\n",
       "85            85  2005     10          LogisticRegression     NaN  0.705882\n",
       "86            86  2005     11          LogisticRegression     NaN  0.617647\n",
       "87            87  2005     12          LogisticRegression     NaN  0.691176\n",
       "88            88  2005     13          LogisticRegression     NaN  0.735294\n",
       "89            89  2005     14          LogisticRegression     NaN  0.779412\n",
       "90            90  2006      0          LogisticRegression     NaN  0.746479\n",
       "91            91  2006      1          LogisticRegression     NaN  0.774648\n",
       "92            92  2006      2          LogisticRegression     NaN  0.591549\n",
       "93            93  2006      3          LogisticRegression     NaN  0.647887\n",
       "94            94  2006      4          LogisticRegression     NaN  0.816901\n",
       "95            95  2006      5          LogisticRegression     NaN  0.647887\n",
       "96            96  2006      6          LogisticRegression     NaN  0.647887\n",
       "97            97  2006      7          LogisticRegression     NaN  0.718310\n",
       "98            98  2006      8          LogisticRegression     NaN  0.732394\n",
       "99            99  2006      9          LogisticRegression     NaN  0.732394\n",
       "100          100  2006     10          LogisticRegression     NaN  0.830986\n",
       "101          101  2006     11          LogisticRegression     NaN  0.690141\n",
       "102          102  2006     12          LogisticRegression     NaN  0.788732\n",
       "103          103  2006     13          LogisticRegression     NaN  0.774648\n",
       "104          104  2006     14          LogisticRegression     NaN  0.859155\n",
       "105          105  2007      0          LogisticRegression     NaN  0.582090\n",
       "106          106  2007      1          LogisticRegression     NaN  0.611940\n",
       "107          107  2007      2          LogisticRegression     NaN  0.582090\n",
       "108          108  2007      3          LogisticRegression     NaN  0.641791\n",
       "109          109  2007      4          LogisticRegression     NaN  0.626866\n",
       "110          110  2007      5          LogisticRegression     NaN  0.626866\n",
       "111          111  2007      6          LogisticRegression     NaN  0.641791\n",
       "112          112  2007      7          LogisticRegression     NaN  0.671642\n",
       "113          113  2007      8          LogisticRegression     NaN  0.776119\n",
       "114          114  2007      9          LogisticRegression     NaN  0.761194\n",
       "115          115  2007     10          LogisticRegression     NaN  0.671642\n",
       "116          116  2007     11          LogisticRegression     NaN  0.641791\n",
       "117          117  2007     12          LogisticRegression     NaN  0.761194\n",
       "118          118  2007     13          LogisticRegression     NaN  0.776119\n",
       "119          119  2007     14          LogisticRegression     NaN  0.850746\n",
       "120          120  2008      0          LogisticRegression     NaN  0.552239\n",
       "121          121  2008      1          LogisticRegression     NaN  0.611940\n",
       "122          122  2008      2          LogisticRegression     NaN  0.701493\n",
       "123          123  2008      3          LogisticRegression     NaN  0.656716\n",
       "124          124  2008      4          LogisticRegression     NaN  0.671642\n",
       "125          125  2008      5          LogisticRegression     NaN  0.731343\n",
       "126          126  2008      6          LogisticRegression     NaN  0.776119\n",
       "127          127  2008      7          LogisticRegression     NaN  0.716418\n",
       "128          128  2008      8          LogisticRegression     NaN  0.701493\n",
       "129          129  2008      9          LogisticRegression     NaN  0.701493\n",
       "130          130  2008     10          LogisticRegression     NaN  0.746269\n",
       "131          131  2008     11          LogisticRegression     NaN  0.746269\n",
       "132          132  2008     12          LogisticRegression     NaN  0.716418\n",
       "133          133  2008     13          LogisticRegression     NaN  0.805970\n",
       "134          134  2008     14          LogisticRegression     NaN  0.850746\n",
       "135          135  2009      0          LogisticRegression     NaN  0.650794\n",
       "136          136  2009      1          LogisticRegression     NaN  0.714286\n",
       "137          137  2009      2          LogisticRegression     NaN  0.682540\n",
       "138          138  2009      3          LogisticRegression     NaN  0.698413\n",
       "139          139  2009      4          LogisticRegression     NaN  0.698413\n",
       "140          140  2009      5          LogisticRegression     NaN  0.777778\n",
       "141          141  2009      6          LogisticRegression     NaN  0.761905\n",
       "142          142  2009      7          LogisticRegression     NaN  0.634921\n",
       "143          143  2009      8          LogisticRegression     NaN  0.682540\n",
       "144          144  2009      9          LogisticRegression     NaN  0.777778\n",
       "145          145  2009     10          LogisticRegression     NaN  0.761905\n",
       "146          146  2009     11          LogisticRegression     NaN  0.714286\n",
       "147          147  2009     12          LogisticRegression     NaN  0.730159\n",
       "148          148  2009     13          LogisticRegression     NaN  0.857143\n",
       "149          149  2009     14          LogisticRegression     NaN  0.873016\n",
       "150          150  2010      0          LogisticRegression     NaN  0.731343\n",
       "151          151  2010      1          LogisticRegression     NaN  0.731343\n",
       "152          152  2010      2          LogisticRegression     NaN  0.641791\n",
       "153          153  2010      3          LogisticRegression     NaN  0.671642\n",
       "154          154  2010      4          LogisticRegression     NaN  0.716418\n",
       "155          155  2010      5          LogisticRegression     NaN  0.686567\n",
       "156          156  2010      6          LogisticRegression     NaN  0.701493\n",
       "157          157  2010      7          LogisticRegression     NaN  0.731343\n",
       "158          158  2010      8          LogisticRegression     NaN  0.731343\n",
       "159          159  2010      9          LogisticRegression     NaN  0.671642\n",
       "160          160  2010     10          LogisticRegression     NaN  0.820896\n",
       "161          161  2010     11          LogisticRegression     NaN  0.791045\n",
       "162          162  2010     12          LogisticRegression     NaN  0.805970\n",
       "163          163  2010     13          LogisticRegression     NaN  0.805970\n",
       "164          164  2010     14          LogisticRegression     NaN  0.850746\n",
       "165          165  2011      0          LogisticRegression     NaN  0.552239\n",
       "166          166  2011      1          LogisticRegression     NaN  0.522388\n",
       "167          167  2011      2          LogisticRegression     NaN  0.716418\n",
       "168          168  2011      3          LogisticRegression     NaN  0.567164\n",
       "169          169  2011      4          LogisticRegression     NaN  0.626866\n",
       "170          170  2011      5          LogisticRegression     NaN  0.611940\n",
       "171          171  2011      6          LogisticRegression     NaN  0.716418\n",
       "172          172  2011      7          LogisticRegression     NaN  0.656716\n",
       "173          173  2011      8          LogisticRegression     NaN  0.641791\n",
       "174          174  2011      9          LogisticRegression     NaN  0.597015\n",
       "175          175  2011     10          LogisticRegression     NaN  0.656716\n",
       "176          176  2011     11          LogisticRegression     NaN  0.746269\n",
       "177          177  2011     12          LogisticRegression     NaN  0.641791\n",
       "178          178  2011     13          LogisticRegression     NaN  0.716418\n",
       "179          179  2011     14          LogisticRegression     NaN  0.791045\n",
       "180          180  2012      0          LogisticRegression     NaN  0.521127\n",
       "181          181  2012      1          LogisticRegression     NaN  0.661972\n",
       "182          182  2012      2          LogisticRegression     NaN  0.577465\n",
       "183          183  2012      3          LogisticRegression     NaN  0.690141\n",
       "184          184  2012      4          LogisticRegression     NaN  0.647887\n",
       "185          185  2012      5          LogisticRegression     NaN  0.676056\n",
       "186          186  2012      6          LogisticRegression     NaN  0.704225\n",
       "187          187  2012      7          LogisticRegression     NaN  0.619718\n",
       "188          188  2012      8          LogisticRegression     NaN  0.647887\n",
       "189          189  2012      9          LogisticRegression     NaN  0.676056\n",
       "190          190  2012     10          LogisticRegression     NaN  0.633803\n",
       "191          191  2012     11          LogisticRegression     NaN  0.718310\n",
       "192          192  2012     12          LogisticRegression     NaN  0.732394\n",
       "193          193  2012     13          LogisticRegression     NaN  0.760563\n",
       "194          194  2012     14          LogisticRegression     NaN  0.774648\n",
       "195          195  2013      0          LogisticRegression     NaN  0.507463\n",
       "196          196  2013      1          LogisticRegression     NaN  0.611940\n",
       "197          197  2013      2          LogisticRegression     NaN  0.552239\n",
       "198          198  2013      3          LogisticRegression     NaN  0.597015\n",
       "199          199  2013      4          LogisticRegression     NaN  0.641791\n",
       "200          200  2013      5          LogisticRegression     NaN  0.671642\n",
       "201          201  2013      6          LogisticRegression     NaN  0.716418\n",
       "202          202  2013      7          LogisticRegression     NaN  0.611940\n",
       "203          203  2013      8          LogisticRegression     NaN  0.656716\n",
       "204          204  2013      9          LogisticRegression     NaN  0.656716\n",
       "205          205  2013     10          LogisticRegression     NaN  0.656716\n",
       "206          206  2013     11          LogisticRegression     NaN  0.746269\n",
       "207          207  2013     12          LogisticRegression     NaN  0.731343\n",
       "208          208  2013     13          LogisticRegression     NaN  0.761194\n",
       "209          209  2013     14          LogisticRegression     NaN  0.820896\n",
       "210          210  2014      0          LogisticRegression     NaN  0.641791\n",
       "211          211  2014      1          LogisticRegression     NaN  0.611940\n",
       "212          212  2014      2          LogisticRegression     NaN  0.701493\n",
       "213          213  2014      3          LogisticRegression     NaN  0.671642\n",
       "214          214  2014      4          LogisticRegression     NaN  0.656716\n",
       "215          215  2014      5          LogisticRegression     NaN  0.746269\n",
       "216          216  2014      6          LogisticRegression     NaN  0.791045\n",
       "217          217  2014      7          LogisticRegression     NaN  0.716418\n",
       "218          218  2014      8          LogisticRegression     NaN  0.731343\n",
       "219          219  2014      9          LogisticRegression     NaN  0.701493\n",
       "220          220  2014     10          LogisticRegression     NaN  0.805970\n",
       "221          221  2014     11          LogisticRegression     NaN  0.805970\n",
       "222          222  2014     12          LogisticRegression     NaN  0.761194\n",
       "223          223  2014     13          LogisticRegression     NaN  0.791045\n",
       "224          224  2014     14          LogisticRegression     NaN  0.865672\n",
       "225          225  2015      0          LogisticRegression     NaN  0.628571\n",
       "226          226  2015      1          LogisticRegression     NaN  0.685714\n",
       "227          227  2015      2          LogisticRegression     NaN  0.614286\n",
       "228          228  2015      3          LogisticRegression     NaN  0.671429\n",
       "229          229  2015      4          LogisticRegression     NaN  0.700000\n",
       "230          230  2015      5          LogisticRegression     NaN  0.685714\n",
       "231          231  2015      6          LogisticRegression     NaN  0.700000\n",
       "232          232  2015      7          LogisticRegression     NaN  0.657143\n",
       "233          233  2015      8          LogisticRegression     NaN  0.700000\n",
       "234          234  2015      9          LogisticRegression     NaN  0.757143\n",
       "235          235  2015     10          LogisticRegression     NaN  0.757143\n",
       "236          236  2015     11          LogisticRegression     NaN  0.742857\n",
       "237          237  2015     12          LogisticRegression     NaN  0.842857\n",
       "238          238  2015     13          LogisticRegression     NaN  0.742857\n",
       "239          239  2015     14          LogisticRegression     NaN  0.828571\n",
       "240          240  2016      0          LogisticRegression     NaN  0.641791\n",
       "241          241  2016      1          LogisticRegression     NaN  0.746269\n",
       "242          242  2016      2          LogisticRegression     NaN  0.641791\n",
       "243          243  2016      3          LogisticRegression     NaN  0.611940\n",
       "244          244  2016      4          LogisticRegression     NaN  0.761194\n",
       "245          245  2016      5          LogisticRegression     NaN  0.746269\n",
       "246          246  2016      6          LogisticRegression     NaN  0.656716\n",
       "247          247  2016      7          LogisticRegression     NaN  0.731343\n",
       "248          248  2016      8          LogisticRegression     NaN  0.686567\n",
       "249          249  2016      9          LogisticRegression     NaN  0.791045\n",
       "250          250  2016     10          LogisticRegression     NaN  0.776119\n",
       "251          251  2016     11          LogisticRegression     NaN  0.716418\n",
       "252          252  2016     12          LogisticRegression     NaN  0.820896\n",
       "253          253  2016     13          LogisticRegression     NaN  0.761194\n",
       "254          254  2016     14          LogisticRegression     NaN  0.835821\n",
       "255          255  2017      0          LogisticRegression     NaN  0.671642\n",
       "256          256  2017      1          LogisticRegression     NaN  0.701493\n",
       "257          257  2017      2          LogisticRegression     NaN  0.701493\n",
       "258          258  2017      3          LogisticRegression     NaN  0.641791\n",
       "259          259  2017      4          LogisticRegression     NaN  0.656716\n",
       "260          260  2017      5          LogisticRegression     NaN  0.656716\n",
       "261          261  2017      6          LogisticRegression     NaN  0.686567\n",
       "262          262  2017      7          LogisticRegression     NaN  0.686567\n",
       "263          263  2017      8          LogisticRegression     NaN  0.761194\n",
       "264          264  2017      9          LogisticRegression     NaN  0.731343\n",
       "265          265  2017     10          LogisticRegression     NaN  0.731343\n",
       "266          266  2017     11          LogisticRegression     NaN  0.776119\n",
       "267          267  2017     12          LogisticRegression     NaN  0.791045\n",
       "268          268  2017     13          LogisticRegression     NaN  0.805970\n",
       "269          269  2017     14          LogisticRegression     NaN  0.850746\n",
       "270          270  2018      0          LogisticRegression     NaN  0.537313\n",
       "271          271  2018      1          LogisticRegression     NaN  0.641791\n",
       "272          272  2018      2          LogisticRegression     NaN  0.477612\n",
       "273          273  2018      3          LogisticRegression     NaN  0.537313\n",
       "274          274  2018      4          LogisticRegression     NaN  0.626866\n",
       "275          275  2018      5          LogisticRegression     NaN  0.671642\n",
       "276          276  2018      6          LogisticRegression     NaN  0.537313\n",
       "277          277  2018      7          LogisticRegression     NaN  0.626866\n",
       "278          278  2018      8          LogisticRegression     NaN  0.567164\n",
       "279          279  2018      9          LogisticRegression     NaN  0.671642\n",
       "280          280  2018     10          LogisticRegression     NaN  0.701493\n",
       "281          281  2018     11          LogisticRegression     NaN  0.626866\n",
       "282          282  2018     12          LogisticRegression     NaN  0.716418\n",
       "283          283  2018     13          LogisticRegression     NaN  0.731343\n",
       "284          284  2018     14          LogisticRegression     NaN  0.791045\n",
       "285          285  2019      0          LogisticRegression     NaN  0.597015\n",
       "286          286  2019      1          LogisticRegression     NaN  0.686567\n",
       "287          287  2019      2          LogisticRegression     NaN  0.597015\n",
       "288          288  2019      3          LogisticRegression     NaN  0.701493\n",
       "289          289  2019      4          LogisticRegression     NaN  0.701493\n",
       "290          290  2019      5          LogisticRegression     NaN  0.701493\n",
       "291          291  2019      6          LogisticRegression     NaN  0.731343\n",
       "292          292  2019      7          LogisticRegression     NaN  0.686567\n",
       "293          293  2019      8          LogisticRegression     NaN  0.761194\n",
       "294          294  2019      9          LogisticRegression     NaN  0.776119\n",
       "295          295  2019     10          LogisticRegression     NaN  0.716418\n",
       "296          296  2019     11          LogisticRegression     NaN  0.791045\n",
       "297          297  2019     12          LogisticRegression     NaN  0.776119\n",
       "298          298  2019     13          LogisticRegression     NaN  0.761194\n",
       "299          299  2019     14          LogisticRegression     NaN  0.835821\n",
       "300          300  2000      0           BaggingClassifier     NaN  0.634921\n",
       "301          301  2000      1           BaggingClassifier     NaN  0.634921\n",
       "302          302  2000      2           BaggingClassifier     NaN  0.603175\n",
       "303          303  2000      3           BaggingClassifier     NaN  0.666667\n",
       "304          304  2000      4           BaggingClassifier     NaN  0.634921\n",
       "305          305  2000      5           BaggingClassifier     NaN  0.666667\n",
       "306          306  2000      6           BaggingClassifier     NaN  0.619048\n",
       "307          307  2000      7           BaggingClassifier     NaN  0.666667\n",
       "308          308  2000      8           BaggingClassifier     NaN  0.698413\n",
       "309          309  2000      9           BaggingClassifier     NaN  0.714286\n",
       "310          310  2000     10           BaggingClassifier     NaN  0.650794\n",
       "311          311  2000     11           BaggingClassifier     NaN  0.682540\n",
       "312          312  2000     12           BaggingClassifier     NaN  0.730159\n",
       "313          313  2000     13           BaggingClassifier     NaN  0.714286\n",
       "314          314  2000     14           BaggingClassifier     NaN  0.714286\n",
       "315          315  2001      0           BaggingClassifier     NaN  0.633333\n",
       "316          316  2001      1           BaggingClassifier     NaN  0.666667\n",
       "317          317  2001      2           BaggingClassifier     NaN  0.550000\n",
       "318          318  2001      3           BaggingClassifier     NaN  0.650000\n",
       "319          319  2001      4           BaggingClassifier     NaN  0.683333\n",
       "320          320  2001      5           BaggingClassifier     NaN  0.650000\n",
       "321          321  2001      6           BaggingClassifier     NaN  0.583333\n",
       "322          322  2001      7           BaggingClassifier     NaN  0.650000\n",
       "323          323  2001      8           BaggingClassifier     NaN  0.683333\n",
       "324          324  2001      9           BaggingClassifier     NaN  0.716667\n",
       "325          325  2001     10           BaggingClassifier     NaN  0.666667\n",
       "326          326  2001     11           BaggingClassifier     NaN  0.683333\n",
       "327          327  2001     12           BaggingClassifier     NaN  0.633333\n",
       "328          328  2001     13           BaggingClassifier     NaN  0.650000\n",
       "329          329  2001     14           BaggingClassifier     NaN  0.700000\n",
       "330          330  2002      0           BaggingClassifier     NaN  0.690141\n",
       "331          331  2002      1           BaggingClassifier     NaN  0.619718\n",
       "332          332  2002      2           BaggingClassifier     NaN  0.563380\n",
       "333          333  2002      3           BaggingClassifier     NaN  0.605634\n",
       "334          334  2002      4           BaggingClassifier     NaN  0.647887\n",
       "335          335  2002      5           BaggingClassifier     NaN  0.633803\n",
       "336          336  2002      6           BaggingClassifier     NaN  0.591549\n",
       "337          337  2002      7           BaggingClassifier     NaN  0.661972\n",
       "338          338  2002      8           BaggingClassifier     NaN  0.704225\n",
       "339          339  2002      9           BaggingClassifier     NaN  0.619718\n",
       "340          340  2002     10           BaggingClassifier     NaN  0.676056\n",
       "341          341  2002     11           BaggingClassifier     NaN  0.563380\n",
       "342          342  2002     12           BaggingClassifier     NaN  0.704225\n",
       "343          343  2002     13           BaggingClassifier     NaN  0.563380\n",
       "344          344  2002     14           BaggingClassifier     NaN  0.690141\n",
       "345          345  2003      0           BaggingClassifier     NaN  0.656716\n",
       "346          346  2003      1           BaggingClassifier     NaN  0.567164\n",
       "347          347  2003      2           BaggingClassifier     NaN  0.641791\n",
       "348          348  2003      3           BaggingClassifier     NaN  0.582090\n",
       "349          349  2003      4           BaggingClassifier     NaN  0.716418\n",
       "350          350  2003      5           BaggingClassifier     NaN  0.597015\n",
       "351          351  2003      6           BaggingClassifier     NaN  0.626866\n",
       "352          352  2003      7           BaggingClassifier     NaN  0.656716\n",
       "353          353  2003      8           BaggingClassifier     NaN  0.656716\n",
       "354          354  2003      9           BaggingClassifier     NaN  0.686567\n",
       "355          355  2003     10           BaggingClassifier     NaN  0.626866\n",
       "356          356  2003     11           BaggingClassifier     NaN  0.701493\n",
       "357          357  2003     12           BaggingClassifier     NaN  0.656716\n",
       "358          358  2003     13           BaggingClassifier     NaN  0.686567\n",
       "359          359  2003     14           BaggingClassifier     NaN  0.701493\n",
       "360          360  2004      0           BaggingClassifier     NaN  0.619048\n",
       "361          361  2004      1           BaggingClassifier     NaN  0.619048\n",
       "362          362  2004      2           BaggingClassifier     NaN  0.539683\n",
       "363          363  2004      3           BaggingClassifier     NaN  0.650794\n",
       "364          364  2004      4           BaggingClassifier     NaN  0.682540\n",
       "365          365  2004      5           BaggingClassifier     NaN  0.634921\n",
       "366          366  2004      6           BaggingClassifier     NaN  0.634921\n",
       "367          367  2004      7           BaggingClassifier     NaN  0.539683\n",
       "368          368  2004      8           BaggingClassifier     NaN  0.714286\n",
       "369          369  2004      9           BaggingClassifier     NaN  0.666667\n",
       "370          370  2004     10           BaggingClassifier     NaN  0.746032\n",
       "371          371  2004     11           BaggingClassifier     NaN  0.682540\n",
       "372          372  2004     12           BaggingClassifier     NaN  0.761905\n",
       "373          373  2004     13           BaggingClassifier     NaN  0.682540\n",
       "374          374  2004     14           BaggingClassifier     NaN  0.746032\n",
       "375          375  2005      0           BaggingClassifier     NaN  0.617647\n",
       "376          376  2005      1           BaggingClassifier     NaN  0.676471\n",
       "377          377  2005      2           BaggingClassifier     NaN  0.661765\n",
       "378          378  2005      3           BaggingClassifier     NaN  0.470588\n",
       "379          379  2005      4           BaggingClassifier     NaN  0.676471\n",
       "380          380  2005      5           BaggingClassifier     NaN  0.647059\n",
       "381          381  2005      6           BaggingClassifier     NaN  0.647059\n",
       "382          382  2005      7           BaggingClassifier     NaN  0.617647\n",
       "383          383  2005      8           BaggingClassifier     NaN  0.529412\n",
       "384          384  2005      9           BaggingClassifier     NaN  0.632353\n",
       "385          385  2005     10           BaggingClassifier     NaN  0.647059\n",
       "386          386  2005     11           BaggingClassifier     NaN  0.617647\n",
       "387          387  2005     12           BaggingClassifier     NaN  0.632353\n",
       "388          388  2005     13           BaggingClassifier     NaN  0.691176\n",
       "389          389  2005     14           BaggingClassifier     NaN  0.661765\n",
       "390          390  2006      0           BaggingClassifier     NaN  0.746479\n",
       "391          391  2006      1           BaggingClassifier     NaN  0.774648\n",
       "392          392  2006      2           BaggingClassifier     NaN  0.591549\n",
       "393          393  2006      3           BaggingClassifier     NaN  0.647887\n",
       "394          394  2006      4           BaggingClassifier     NaN  0.788732\n",
       "395          395  2006      5           BaggingClassifier     NaN  0.647887\n",
       "396          396  2006      6           BaggingClassifier     NaN  0.633803\n",
       "397          397  2006      7           BaggingClassifier     NaN  0.718310\n",
       "398          398  2006      8           BaggingClassifier     NaN  0.718310\n",
       "399          399  2006      9           BaggingClassifier     NaN  0.732394\n",
       "400          400  2006     10           BaggingClassifier     NaN  0.816901\n",
       "401          401  2006     11           BaggingClassifier     NaN  0.647887\n",
       "402          402  2006     12           BaggingClassifier     NaN  0.802817\n",
       "403          403  2006     13           BaggingClassifier     NaN  0.704225\n",
       "404          404  2006     14           BaggingClassifier     NaN  0.774648\n",
       "405          405  2007      0           BaggingClassifier     NaN  0.582090\n",
       "406          406  2007      1           BaggingClassifier     NaN  0.611940\n",
       "407          407  2007      2           BaggingClassifier     NaN  0.582090\n",
       "408          408  2007      3           BaggingClassifier     NaN  0.641791\n",
       "409          409  2007      4           BaggingClassifier     NaN  0.626866\n",
       "410          410  2007      5           BaggingClassifier     NaN  0.656716\n",
       "411          411  2007      6           BaggingClassifier     NaN  0.582090\n",
       "412          412  2007      7           BaggingClassifier     NaN  0.656716\n",
       "413          413  2007      8           BaggingClassifier     NaN  0.746269\n",
       "414          414  2007      9           BaggingClassifier     NaN  0.626866\n",
       "415          415  2007     10           BaggingClassifier     NaN  0.641791\n",
       "416          416  2007     11           BaggingClassifier     NaN  0.671642\n",
       "417          417  2007     12           BaggingClassifier     NaN  0.656716\n",
       "418          418  2007     13           BaggingClassifier     NaN  0.731343\n",
       "419          419  2007     14           BaggingClassifier     NaN  0.776119\n",
       "420          420  2008      0           BaggingClassifier     NaN  0.552239\n",
       "421          421  2008      1           BaggingClassifier     NaN  0.611940\n",
       "422          422  2008      2           BaggingClassifier     NaN  0.701493\n",
       "423          423  2008      3           BaggingClassifier     NaN  0.582090\n",
       "424          424  2008      4           BaggingClassifier     NaN  0.686567\n",
       "425          425  2008      5           BaggingClassifier     NaN  0.626866\n",
       "426          426  2008      6           BaggingClassifier     NaN  0.701493\n",
       "427          427  2008      7           BaggingClassifier     NaN  0.626866\n",
       "428          428  2008      8           BaggingClassifier     NaN  0.597015\n",
       "429          429  2008      9           BaggingClassifier     NaN  0.641791\n",
       "430          430  2008     10           BaggingClassifier     NaN  0.716418\n",
       "431          431  2008     11           BaggingClassifier     NaN  0.701493\n",
       "432          432  2008     12           BaggingClassifier     NaN  0.671642\n",
       "433          433  2008     13           BaggingClassifier     NaN  0.701493\n",
       "434          434  2008     14           BaggingClassifier     NaN  0.746269\n",
       "435          435  2009      0           BaggingClassifier     NaN  0.523810\n",
       "436          436  2009      1           BaggingClassifier     NaN  0.714286\n",
       "437          437  2009      2           BaggingClassifier     NaN  0.682540\n",
       "438          438  2009      3           BaggingClassifier     NaN  0.650794\n",
       "439          439  2009      4           BaggingClassifier     NaN  0.603175\n",
       "440          440  2009      5           BaggingClassifier     NaN  0.746032\n",
       "441          441  2009      6           BaggingClassifier     NaN  0.714286\n",
       "442          442  2009      7           BaggingClassifier     NaN  0.698413\n",
       "443          443  2009      8           BaggingClassifier     NaN  0.587302\n",
       "444          444  2009      9           BaggingClassifier     NaN  0.761905\n",
       "445          445  2009     10           BaggingClassifier     NaN  0.619048\n",
       "446          446  2009     11           BaggingClassifier     NaN  0.603175\n",
       "447          447  2009     12           BaggingClassifier     NaN  0.698413\n",
       "448          448  2009     13           BaggingClassifier     NaN  0.746032\n",
       "449          449  2009     14           BaggingClassifier     NaN  0.698413\n",
       "450          450  2010      0           BaggingClassifier     NaN  0.731343\n",
       "451          451  2010      1           BaggingClassifier     NaN  0.731343\n",
       "452          452  2010      2           BaggingClassifier     NaN  0.641791\n",
       "453          453  2010      3           BaggingClassifier     NaN  0.671642\n",
       "454          454  2010      4           BaggingClassifier     NaN  0.701493\n",
       "455          455  2010      5           BaggingClassifier     NaN  0.656716\n",
       "456          456  2010      6           BaggingClassifier     NaN  0.611940\n",
       "457          457  2010      7           BaggingClassifier     NaN  0.716418\n",
       "458          458  2010      8           BaggingClassifier     NaN  0.686567\n",
       "459          459  2010      9           BaggingClassifier     NaN  0.686567\n",
       "460          460  2010     10           BaggingClassifier     NaN  0.746269\n",
       "461          461  2010     11           BaggingClassifier     NaN  0.686567\n",
       "462          462  2010     12           BaggingClassifier     NaN  0.686567\n",
       "463          463  2010     13           BaggingClassifier     NaN  0.686567\n",
       "464          464  2010     14           BaggingClassifier     NaN  0.716418\n",
       "465          465  2011      0           BaggingClassifier     NaN  0.552239\n",
       "466          466  2011      1           BaggingClassifier     NaN  0.507463\n",
       "467          467  2011      2           BaggingClassifier     NaN  0.552239\n",
       "468          468  2011      3           BaggingClassifier     NaN  0.567164\n",
       "469          469  2011      4           BaggingClassifier     NaN  0.656716\n",
       "470          470  2011      5           BaggingClassifier     NaN  0.611940\n",
       "471          471  2011      6           BaggingClassifier     NaN  0.567164\n",
       "472          472  2011      7           BaggingClassifier     NaN  0.626866\n",
       "473          473  2011      8           BaggingClassifier     NaN  0.597015\n",
       "474          474  2011      9           BaggingClassifier     NaN  0.537313\n",
       "475          475  2011     10           BaggingClassifier     NaN  0.701493\n",
       "476          476  2011     11           BaggingClassifier     NaN  0.686567\n",
       "477          477  2011     12           BaggingClassifier     NaN  0.611940\n",
       "478          478  2011     13           BaggingClassifier     NaN  0.641791\n",
       "479          479  2011     14           BaggingClassifier     NaN  0.641791\n",
       "480          480  2012      0           BaggingClassifier     NaN  0.521127\n",
       "481          481  2012      1           BaggingClassifier     NaN  0.661972\n",
       "482          482  2012      2           BaggingClassifier     NaN  0.647887\n",
       "483          483  2012      3           BaggingClassifier     NaN  0.690141\n",
       "484          484  2012      4           BaggingClassifier     NaN  0.647887\n",
       "485          485  2012      5           BaggingClassifier     NaN  0.633803\n",
       "486          486  2012      6           BaggingClassifier     NaN  0.690141\n",
       "487          487  2012      7           BaggingClassifier     NaN  0.661972\n",
       "488          488  2012      8           BaggingClassifier     NaN  0.507042\n",
       "489          489  2012      9           BaggingClassifier     NaN  0.676056\n",
       "490          490  2012     10           BaggingClassifier     NaN  0.661972\n",
       "491          491  2012     11           BaggingClassifier     NaN  0.633803\n",
       "492          492  2012     12           BaggingClassifier     NaN  0.633803\n",
       "493          493  2012     13           BaggingClassifier     NaN  0.704225\n",
       "494          494  2012     14           BaggingClassifier     NaN  0.732394\n",
       "495          495  2013      0           BaggingClassifier     NaN  0.507463\n",
       "496          496  2013      1           BaggingClassifier     NaN  0.611940\n",
       "497          497  2013      2           BaggingClassifier     NaN  0.626866\n",
       "498          498  2013      3           BaggingClassifier     NaN  0.671642\n",
       "499          499  2013      4           BaggingClassifier     NaN  0.641791\n",
       "500          500  2013      5           BaggingClassifier     NaN  0.641791\n",
       "501          501  2013      6           BaggingClassifier     NaN  0.686567\n",
       "502          502  2013      7           BaggingClassifier     NaN  0.597015\n",
       "503          503  2013      8           BaggingClassifier     NaN  0.552239\n",
       "504          504  2013      9           BaggingClassifier     NaN  0.626866\n",
       "505          505  2013     10           BaggingClassifier     NaN  0.641791\n",
       "506          506  2013     11           BaggingClassifier     NaN  0.686567\n",
       "507          507  2013     12           BaggingClassifier     NaN  0.611940\n",
       "508          508  2013     13           BaggingClassifier     NaN  0.671642\n",
       "509          509  2013     14           BaggingClassifier     NaN  0.671642\n",
       "510          510  2014      0           BaggingClassifier     NaN  0.641791\n",
       "511          511  2014      1           BaggingClassifier     NaN  0.611940\n",
       "512          512  2014      2           BaggingClassifier     NaN  0.686567\n",
       "513          513  2014      3           BaggingClassifier     NaN  0.671642\n",
       "514          514  2014      4           BaggingClassifier     NaN  0.597015\n",
       "515          515  2014      5           BaggingClassifier     NaN  0.791045\n",
       "516          516  2014      6           BaggingClassifier     NaN  0.791045\n",
       "517          517  2014      7           BaggingClassifier     NaN  0.686567\n",
       "518          518  2014      8           BaggingClassifier     NaN  0.686567\n",
       "519          519  2014      9           BaggingClassifier     NaN  0.656716\n",
       "520          520  2014     10           BaggingClassifier     NaN  0.791045\n",
       "521          521  2014     11           BaggingClassifier     NaN  0.746269\n",
       "522          522  2014     12           BaggingClassifier     NaN  0.686567\n",
       "523          523  2014     13           BaggingClassifier     NaN  0.776119\n",
       "524          524  2014     14           BaggingClassifier     NaN  0.820896\n",
       "525          525  2015      0           BaggingClassifier     NaN  0.628571\n",
       "526          526  2015      1           BaggingClassifier     NaN  0.685714\n",
       "527          527  2015      2           BaggingClassifier     NaN  0.614286\n",
       "528          528  2015      3           BaggingClassifier     NaN  0.671429\n",
       "529          529  2015      4           BaggingClassifier     NaN  0.642857\n",
       "530          530  2015      5           BaggingClassifier     NaN  0.671429\n",
       "531          531  2015      6           BaggingClassifier     NaN  0.714286\n",
       "532          532  2015      7           BaggingClassifier     NaN  0.642857\n",
       "533          533  2015      8           BaggingClassifier     NaN  0.642857\n",
       "534          534  2015      9           BaggingClassifier     NaN  0.700000\n",
       "535          535  2015     10           BaggingClassifier     NaN  0.700000\n",
       "536          536  2015     11           BaggingClassifier     NaN  0.671429\n",
       "537          537  2015     12           BaggingClassifier     NaN  0.685714\n",
       "538          538  2015     13           BaggingClassifier     NaN  0.742857\n",
       "539          539  2015     14           BaggingClassifier     NaN  0.757143\n",
       "540          540  2016      0           BaggingClassifier     NaN  0.641791\n",
       "541          541  2016      1           BaggingClassifier     NaN  0.746269\n",
       "542          542  2016      2           BaggingClassifier     NaN  0.641791\n",
       "543          543  2016      3           BaggingClassifier     NaN  0.611940\n",
       "544          544  2016      4           BaggingClassifier     NaN  0.761194\n",
       "545          545  2016      5           BaggingClassifier     NaN  0.686567\n",
       "546          546  2016      6           BaggingClassifier     NaN  0.626866\n",
       "547          547  2016      7           BaggingClassifier     NaN  0.701493\n",
       "548          548  2016      8           BaggingClassifier     NaN  0.611940\n",
       "549          549  2016      9           BaggingClassifier     NaN  0.776119\n",
       "550          550  2016     10           BaggingClassifier     NaN  0.731343\n",
       "551          551  2016     11           BaggingClassifier     NaN  0.716418\n",
       "552          552  2016     12           BaggingClassifier     NaN  0.776119\n",
       "553          553  2016     13           BaggingClassifier     NaN  0.731343\n",
       "554          554  2016     14           BaggingClassifier     NaN  0.746269\n",
       "555          555  2017      0           BaggingClassifier     NaN  0.671642\n",
       "556          556  2017      1           BaggingClassifier     NaN  0.701493\n",
       "557          557  2017      2           BaggingClassifier     NaN  0.701493\n",
       "558          558  2017      3           BaggingClassifier     NaN  0.641791\n",
       "559          559  2017      4           BaggingClassifier     NaN  0.656716\n",
       "560          560  2017      5           BaggingClassifier     NaN  0.716418\n",
       "561          561  2017      6           BaggingClassifier     NaN  0.701493\n",
       "562          562  2017      7           BaggingClassifier     NaN  0.701493\n",
       "563          563  2017      8           BaggingClassifier     NaN  0.761194\n",
       "564          564  2017      9           BaggingClassifier     NaN  0.746269\n",
       "565          565  2017     10           BaggingClassifier     NaN  0.761194\n",
       "566          566  2017     11           BaggingClassifier     NaN  0.746269\n",
       "567          567  2017     12           BaggingClassifier     NaN  0.746269\n",
       "568          568  2017     13           BaggingClassifier     NaN  0.761194\n",
       "569          569  2017     14           BaggingClassifier     NaN  0.791045\n",
       "570          570  2018      0           BaggingClassifier     NaN  0.537313\n",
       "571          571  2018      1           BaggingClassifier     NaN  0.641791\n",
       "572          572  2018      2           BaggingClassifier     NaN  0.477612\n",
       "573          573  2018      3           BaggingClassifier     NaN  0.537313\n",
       "574          574  2018      4           BaggingClassifier     NaN  0.641791\n",
       "575          575  2018      5           BaggingClassifier     NaN  0.731343\n",
       "576          576  2018      6           BaggingClassifier     NaN  0.626866\n",
       "577          577  2018      7           BaggingClassifier     NaN  0.537313\n",
       "578          578  2018      8           BaggingClassifier     NaN  0.611940\n",
       "579          579  2018      9           BaggingClassifier     NaN  0.611940\n",
       "580          580  2018     10           BaggingClassifier     NaN  0.686567\n",
       "581          581  2018     11           BaggingClassifier     NaN  0.537313\n",
       "582          582  2018     12           BaggingClassifier     NaN  0.731343\n",
       "583          583  2018     13           BaggingClassifier     NaN  0.656716\n",
       "584          584  2018     14           BaggingClassifier     NaN  0.701493\n",
       "585          585  2019      0           BaggingClassifier     NaN  0.597015\n",
       "586          586  2019      1           BaggingClassifier     NaN  0.686567\n",
       "587          587  2019      2           BaggingClassifier     NaN  0.597015\n",
       "588          588  2019      3           BaggingClassifier     NaN  0.671642\n",
       "589          589  2019      4           BaggingClassifier     NaN  0.641791\n",
       "590          590  2019      5           BaggingClassifier     NaN  0.671642\n",
       "591          591  2019      6           BaggingClassifier     NaN  0.731343\n",
       "592          592  2019      7           BaggingClassifier     NaN  0.701493\n",
       "593          593  2019      8           BaggingClassifier     NaN  0.701493\n",
       "594          594  2019      9           BaggingClassifier     NaN  0.746269\n",
       "595          595  2019     10           BaggingClassifier     NaN  0.701493\n",
       "596          596  2019     11           BaggingClassifier     NaN  0.701493\n",
       "597          597  2019     12           BaggingClassifier     NaN  0.761194\n",
       "598          598  2019     13           BaggingClassifier     NaN  0.701493\n",
       "599          599  2019     14           BaggingClassifier     NaN  0.791045\n",
       "600          600  2000      0      RandomForestClassifier     NaN  0.634921\n",
       "601          601  2000      1      RandomForestClassifier     NaN  0.634921\n",
       "602          602  2000      2      RandomForestClassifier     NaN  0.603175\n",
       "603          603  2000      3      RandomForestClassifier     NaN  0.666667\n",
       "604          604  2000      4      RandomForestClassifier     NaN  0.634921\n",
       "605          605  2000      5      RandomForestClassifier     NaN  0.666667\n",
       "606          606  2000      6      RandomForestClassifier     NaN  0.619048\n",
       "607          607  2000      7      RandomForestClassifier     NaN  0.619048\n",
       "608          608  2000      8      RandomForestClassifier     NaN  0.714286\n",
       "609          609  2000      9      RandomForestClassifier     NaN  0.714286\n",
       "610          610  2000     10      RandomForestClassifier     NaN  0.666667\n",
       "611          611  2000     11      RandomForestClassifier     NaN  0.730159\n",
       "612          612  2000     12      RandomForestClassifier     NaN  0.777778\n",
       "613          613  2000     13      RandomForestClassifier     NaN  0.698413\n",
       "614          614  2000     14      RandomForestClassifier     NaN  0.746032\n",
       "615          615  2001      0      RandomForestClassifier     NaN  0.633333\n",
       "616          616  2001      1      RandomForestClassifier     NaN  0.666667\n",
       "617          617  2001      2      RandomForestClassifier     NaN  0.550000\n",
       "618          618  2001      3      RandomForestClassifier     NaN  0.650000\n",
       "619          619  2001      4      RandomForestClassifier     NaN  0.700000\n",
       "620          620  2001      5      RandomForestClassifier     NaN  0.650000\n",
       "621          621  2001      6      RandomForestClassifier     NaN  0.533333\n",
       "622          622  2001      7      RandomForestClassifier     NaN  0.650000\n",
       "623          623  2001      8      RandomForestClassifier     NaN  0.666667\n",
       "624          624  2001      9      RandomForestClassifier     NaN  0.700000\n",
       "625          625  2001     10      RandomForestClassifier     NaN  0.750000\n",
       "626          626  2001     11      RandomForestClassifier     NaN  0.716667\n",
       "627          627  2001     12      RandomForestClassifier     NaN  0.700000\n",
       "628          628  2001     13      RandomForestClassifier     NaN  0.600000\n",
       "629          629  2001     14      RandomForestClassifier     NaN  0.700000\n",
       "630          630  2002      0      RandomForestClassifier     NaN  0.690141\n",
       "631          631  2002      1      RandomForestClassifier     NaN  0.619718\n",
       "632          632  2002      2      RandomForestClassifier     NaN  0.563380\n",
       "633          633  2002      3      RandomForestClassifier     NaN  0.605634\n",
       "634          634  2002      4      RandomForestClassifier     NaN  0.647887\n",
       "635          635  2002      5      RandomForestClassifier     NaN  0.633803\n",
       "636          636  2002      6      RandomForestClassifier     NaN  0.605634\n",
       "637          637  2002      7      RandomForestClassifier     NaN  0.676056\n",
       "638          638  2002      8      RandomForestClassifier     NaN  0.718310\n",
       "639          639  2002      9      RandomForestClassifier     NaN  0.633803\n",
       "640          640  2002     10      RandomForestClassifier     NaN  0.704225\n",
       "641          641  2002     11      RandomForestClassifier     NaN  0.619718\n",
       "642          642  2002     12      RandomForestClassifier     NaN  0.704225\n",
       "643          643  2002     13      RandomForestClassifier     NaN  0.549296\n",
       "644          644  2002     14      RandomForestClassifier     NaN  0.704225\n",
       "645          645  2003      0      RandomForestClassifier     NaN  0.656716\n",
       "646          646  2003      1      RandomForestClassifier     NaN  0.671642\n",
       "647          647  2003      2      RandomForestClassifier     NaN  0.641791\n",
       "648          648  2003      3      RandomForestClassifier     NaN  0.626866\n",
       "649          649  2003      4      RandomForestClassifier     NaN  0.731343\n",
       "650          650  2003      5      RandomForestClassifier     NaN  0.626866\n",
       "651          651  2003      6      RandomForestClassifier     NaN  0.611940\n",
       "652          652  2003      7      RandomForestClassifier     NaN  0.686567\n",
       "653          653  2003      8      RandomForestClassifier     NaN  0.671642\n",
       "654          654  2003      9      RandomForestClassifier     NaN  0.656716\n",
       "655          655  2003     10      RandomForestClassifier     NaN  0.641791\n",
       "656          656  2003     11      RandomForestClassifier     NaN  0.746269\n",
       "657          657  2003     12      RandomForestClassifier     NaN  0.701493\n",
       "658          658  2003     13      RandomForestClassifier     NaN  0.671642\n",
       "659          659  2003     14      RandomForestClassifier     NaN  0.716418\n",
       "660          660  2004      0      RandomForestClassifier     NaN  0.619048\n",
       "661          661  2004      1      RandomForestClassifier     NaN  0.539683\n",
       "662          662  2004      2      RandomForestClassifier     NaN  0.539683\n",
       "663          663  2004      3      RandomForestClassifier     NaN  0.650794\n",
       "664          664  2004      4      RandomForestClassifier     NaN  0.682540\n",
       "665          665  2004      5      RandomForestClassifier     NaN  0.619048\n",
       "666          666  2004      6      RandomForestClassifier     NaN  0.698413\n",
       "667          667  2004      7      RandomForestClassifier     NaN  0.492063\n",
       "668          668  2004      8      RandomForestClassifier     NaN  0.746032\n",
       "669          669  2004      9      RandomForestClassifier     NaN  0.650794\n",
       "670          670  2004     10      RandomForestClassifier     NaN  0.698413\n",
       "671          671  2004     11      RandomForestClassifier     NaN  0.682540\n",
       "672          672  2004     12      RandomForestClassifier     NaN  0.761905\n",
       "673          673  2004     13      RandomForestClassifier     NaN  0.714286\n",
       "674          674  2004     14      RandomForestClassifier     NaN  0.761905\n",
       "675          675  2005      0      RandomForestClassifier     NaN  0.617647\n",
       "676          676  2005      1      RandomForestClassifier     NaN  0.676471\n",
       "677          677  2005      2      RandomForestClassifier     NaN  0.661765\n",
       "678          678  2005      3      RandomForestClassifier     NaN  0.470588\n",
       "679          679  2005      4      RandomForestClassifier     NaN  0.676471\n",
       "680          680  2005      5      RandomForestClassifier     NaN  0.661765\n",
       "681          681  2005      6      RandomForestClassifier     NaN  0.632353\n",
       "682          682  2005      7      RandomForestClassifier     NaN  0.588235\n",
       "683          683  2005      8      RandomForestClassifier     NaN  0.544118\n",
       "684          684  2005      9      RandomForestClassifier     NaN  0.647059\n",
       "685          685  2005     10      RandomForestClassifier     NaN  0.691176\n",
       "686          686  2005     11      RandomForestClassifier     NaN  0.617647\n",
       "687          687  2005     12      RandomForestClassifier     NaN  0.602941\n",
       "688          688  2005     13      RandomForestClassifier     NaN  0.705882\n",
       "689          689  2005     14      RandomForestClassifier     NaN  0.676471\n",
       "690          690  2006      0      RandomForestClassifier     NaN  0.746479\n",
       "691          691  2006      1      RandomForestClassifier     NaN  0.774648\n",
       "692          692  2006      2      RandomForestClassifier     NaN  0.591549\n",
       "693          693  2006      3      RandomForestClassifier     NaN  0.647887\n",
       "694          694  2006      4      RandomForestClassifier     NaN  0.788732\n",
       "695          695  2006      5      RandomForestClassifier     NaN  0.661972\n",
       "696          696  2006      6      RandomForestClassifier     NaN  0.647887\n",
       "697          697  2006      7      RandomForestClassifier     NaN  0.704225\n",
       "698          698  2006      8      RandomForestClassifier     NaN  0.718310\n",
       "699          699  2006      9      RandomForestClassifier     NaN  0.718310\n",
       "700          700  2006     10      RandomForestClassifier     NaN  0.802817\n",
       "701          701  2006     11      RandomForestClassifier     NaN  0.690141\n",
       "702          702  2006     12      RandomForestClassifier     NaN  0.774648\n",
       "703          703  2006     13      RandomForestClassifier     NaN  0.704225\n",
       "704          704  2006     14      RandomForestClassifier     NaN  0.760563\n",
       "705          705  2007      0      RandomForestClassifier     NaN  0.582090\n",
       "706          706  2007      1      RandomForestClassifier     NaN  0.611940\n",
       "707          707  2007      2      RandomForestClassifier     NaN  0.582090\n",
       "708          708  2007      3      RandomForestClassifier     NaN  0.641791\n",
       "709          709  2007      4      RandomForestClassifier     NaN  0.567164\n",
       "710          710  2007      5      RandomForestClassifier     NaN  0.656716\n",
       "711          711  2007      6      RandomForestClassifier     NaN  0.597015\n",
       "712          712  2007      7      RandomForestClassifier     NaN  0.671642\n",
       "713          713  2007      8      RandomForestClassifier     NaN  0.701493\n",
       "714          714  2007      9      RandomForestClassifier     NaN  0.701493\n",
       "715          715  2007     10      RandomForestClassifier     NaN  0.671642\n",
       "716          716  2007     11      RandomForestClassifier     NaN  0.656716\n",
       "717          717  2007     12      RandomForestClassifier     NaN  0.701493\n",
       "718          718  2007     13      RandomForestClassifier     NaN  0.731343\n",
       "719          719  2007     14      RandomForestClassifier     NaN  0.805970\n",
       "720          720  2008      0      RandomForestClassifier     NaN  0.552239\n",
       "721          721  2008      1      RandomForestClassifier     NaN  0.611940\n",
       "722          722  2008      2      RandomForestClassifier     NaN  0.701493\n",
       "723          723  2008      3      RandomForestClassifier     NaN  0.656716\n",
       "724          724  2008      4      RandomForestClassifier     NaN  0.671642\n",
       "725          725  2008      5      RandomForestClassifier     NaN  0.656716\n",
       "726          726  2008      6      RandomForestClassifier     NaN  0.686567\n",
       "727          727  2008      7      RandomForestClassifier     NaN  0.656716\n",
       "728          728  2008      8      RandomForestClassifier     NaN  0.641791\n",
       "729          729  2008      9      RandomForestClassifier     NaN  0.641791\n",
       "730          730  2008     10      RandomForestClassifier     NaN  0.716418\n",
       "731          731  2008     11      RandomForestClassifier     NaN  0.731343\n",
       "732          732  2008     12      RandomForestClassifier     NaN  0.656716\n",
       "733          733  2008     13      RandomForestClassifier     NaN  0.686567\n",
       "734          734  2008     14      RandomForestClassifier     NaN  0.776119\n",
       "735          735  2009      0      RandomForestClassifier     NaN  0.650794\n",
       "736          736  2009      1      RandomForestClassifier     NaN  0.714286\n",
       "737          737  2009      2      RandomForestClassifier     NaN  0.682540\n",
       "738          738  2009      3      RandomForestClassifier     NaN  0.650794\n",
       "739          739  2009      4      RandomForestClassifier     NaN  0.603175\n",
       "740          740  2009      5      RandomForestClassifier     NaN  0.746032\n",
       "741          741  2009      6      RandomForestClassifier     NaN  0.698413\n",
       "742          742  2009      7      RandomForestClassifier     NaN  0.666667\n",
       "743          743  2009      8      RandomForestClassifier     NaN  0.619048\n",
       "744          744  2009      9      RandomForestClassifier     NaN  0.730159\n",
       "745          745  2009     10      RandomForestClassifier     NaN  0.698413\n",
       "746          746  2009     11      RandomForestClassifier     NaN  0.634921\n",
       "747          747  2009     12      RandomForestClassifier     NaN  0.714286\n",
       "748          748  2009     13      RandomForestClassifier     NaN  0.746032\n",
       "749          749  2009     14      RandomForestClassifier     NaN  0.761905\n",
       "750          750  2010      0      RandomForestClassifier     NaN  0.731343\n",
       "751          751  2010      1      RandomForestClassifier     NaN  0.731343\n",
       "752          752  2010      2      RandomForestClassifier     NaN  0.641791\n",
       "753          753  2010      3      RandomForestClassifier     NaN  0.671642\n",
       "754          754  2010      4      RandomForestClassifier     NaN  0.716418\n",
       "755          755  2010      5      RandomForestClassifier     NaN  0.686567\n",
       "756          756  2010      6      RandomForestClassifier     NaN  0.597015\n",
       "757          757  2010      7      RandomForestClassifier     NaN  0.716418\n",
       "758          758  2010      8      RandomForestClassifier     NaN  0.686567\n",
       "759          759  2010      9      RandomForestClassifier     NaN  0.716418\n",
       "760          760  2010     10      RandomForestClassifier     NaN  0.716418\n",
       "761          761  2010     11      RandomForestClassifier     NaN  0.701493\n",
       "762          762  2010     12      RandomForestClassifier     NaN  0.731343\n",
       "763          763  2010     13      RandomForestClassifier     NaN  0.731343\n",
       "764          764  2010     14      RandomForestClassifier     NaN  0.791045\n",
       "765          765  2011      0      RandomForestClassifier     NaN  0.552239\n",
       "766          766  2011      1      RandomForestClassifier     NaN  0.522388\n",
       "767          767  2011      2      RandomForestClassifier     NaN  0.716418\n",
       "768          768  2011      3      RandomForestClassifier     NaN  0.582090\n",
       "769          769  2011      4      RandomForestClassifier     NaN  0.611940\n",
       "770          770  2011      5      RandomForestClassifier     NaN  0.611940\n",
       "771          771  2011      6      RandomForestClassifier     NaN  0.701493\n",
       "772          772  2011      7      RandomForestClassifier     NaN  0.731343\n",
       "773          773  2011      8      RandomForestClassifier     NaN  0.611940\n",
       "774          774  2011      9      RandomForestClassifier     NaN  0.582090\n",
       "775          775  2011     10      RandomForestClassifier     NaN  0.671642\n",
       "776          776  2011     11      RandomForestClassifier     NaN  0.671642\n",
       "777          777  2011     12      RandomForestClassifier     NaN  0.597015\n",
       "778          778  2011     13      RandomForestClassifier     NaN  0.686567\n",
       "779          779  2011     14      RandomForestClassifier     NaN  0.686567\n",
       "780          780  2012      0      RandomForestClassifier     NaN  0.521127\n",
       "781          781  2012      1      RandomForestClassifier     NaN  0.661972\n",
       "782          782  2012      2      RandomForestClassifier     NaN  0.577465\n",
       "783          783  2012      3      RandomForestClassifier     NaN  0.690141\n",
       "784          784  2012      4      RandomForestClassifier     NaN  0.647887\n",
       "785          785  2012      5      RandomForestClassifier     NaN  0.633803\n",
       "786          786  2012      6      RandomForestClassifier     NaN  0.690141\n",
       "787          787  2012      7      RandomForestClassifier     NaN  0.661972\n",
       "788          788  2012      8      RandomForestClassifier     NaN  0.563380\n",
       "789          789  2012      9      RandomForestClassifier     NaN  0.676056\n",
       "790          790  2012     10      RandomForestClassifier     NaN  0.647887\n",
       "791          791  2012     11      RandomForestClassifier     NaN  0.732394\n",
       "792          792  2012     12      RandomForestClassifier     NaN  0.633803\n",
       "793          793  2012     13      RandomForestClassifier     NaN  0.676056\n",
       "794          794  2012     14      RandomForestClassifier     NaN  0.690141\n",
       "795          795  2013      0      RandomForestClassifier     NaN  0.477612\n",
       "796          796  2013      1      RandomForestClassifier     NaN  0.611940\n",
       "797          797  2013      2      RandomForestClassifier     NaN  0.552239\n",
       "798          798  2013      3      RandomForestClassifier     NaN  0.597015\n",
       "799          799  2013      4      RandomForestClassifier     NaN  0.611940\n",
       "800          800  2013      5      RandomForestClassifier     NaN  0.641791\n",
       "801          801  2013      6      RandomForestClassifier     NaN  0.716418\n",
       "802          802  2013      7      RandomForestClassifier     NaN  0.597015\n",
       "803          803  2013      8      RandomForestClassifier     NaN  0.567164\n",
       "804          804  2013      9      RandomForestClassifier     NaN  0.626866\n",
       "805          805  2013     10      RandomForestClassifier     NaN  0.522388\n",
       "806          806  2013     11      RandomForestClassifier     NaN  0.701493\n",
       "807          807  2013     12      RandomForestClassifier     NaN  0.611940\n",
       "808          808  2013     13      RandomForestClassifier     NaN  0.656716\n",
       "809          809  2013     14      RandomForestClassifier     NaN  0.686567\n",
       "810          810  2014      0      RandomForestClassifier     NaN  0.641791\n",
       "811          811  2014      1      RandomForestClassifier     NaN  0.611940\n",
       "812          812  2014      2      RandomForestClassifier     NaN  0.701493\n",
       "813          813  2014      3      RandomForestClassifier     NaN  0.671642\n",
       "814          814  2014      4      RandomForestClassifier     NaN  0.641791\n",
       "815          815  2014      5      RandomForestClassifier     NaN  0.776119\n",
       "816          816  2014      6      RandomForestClassifier     NaN  0.776119\n",
       "817          817  2014      7      RandomForestClassifier     NaN  0.716418\n",
       "818          818  2014      8      RandomForestClassifier     NaN  0.686567\n",
       "819          819  2014      9      RandomForestClassifier     NaN  0.701493\n",
       "820          820  2014     10      RandomForestClassifier     NaN  0.776119\n",
       "821          821  2014     11      RandomForestClassifier     NaN  0.791045\n",
       "822          822  2014     12      RandomForestClassifier     NaN  0.671642\n",
       "823          823  2014     13      RandomForestClassifier     NaN  0.791045\n",
       "824          824  2014     14      RandomForestClassifier     NaN  0.835821\n",
       "825          825  2015      0      RandomForestClassifier     NaN  0.628571\n",
       "826          826  2015      1      RandomForestClassifier     NaN  0.685714\n",
       "827          827  2015      2      RandomForestClassifier     NaN  0.614286\n",
       "828          828  2015      3      RandomForestClassifier     NaN  0.671429\n",
       "829          829  2015      4      RandomForestClassifier     NaN  0.657143\n",
       "830          830  2015      5      RandomForestClassifier     NaN  0.714286\n",
       "831          831  2015      6      RandomForestClassifier     NaN  0.714286\n",
       "832          832  2015      7      RandomForestClassifier     NaN  0.642857\n",
       "833          833  2015      8      RandomForestClassifier     NaN  0.628571\n",
       "834          834  2015      9      RandomForestClassifier     NaN  0.728571\n",
       "835          835  2015     10      RandomForestClassifier     NaN  0.728571\n",
       "836          836  2015     11      RandomForestClassifier     NaN  0.728571\n",
       "837          837  2015     12      RandomForestClassifier     NaN  0.728571\n",
       "838          838  2015     13      RandomForestClassifier     NaN  0.757143\n",
       "839          839  2015     14      RandomForestClassifier     NaN  0.800000\n",
       "840          840  2016      0      RandomForestClassifier     NaN  0.641791\n",
       "841          841  2016      1      RandomForestClassifier     NaN  0.746269\n",
       "842          842  2016      2      RandomForestClassifier     NaN  0.641791\n",
       "843          843  2016      3      RandomForestClassifier     NaN  0.611940\n",
       "844          844  2016      4      RandomForestClassifier     NaN  0.761194\n",
       "845          845  2016      5      RandomForestClassifier     NaN  0.746269\n",
       "846          846  2016      6      RandomForestClassifier     NaN  0.626866\n",
       "847          847  2016      7      RandomForestClassifier     NaN  0.716418\n",
       "848          848  2016      8      RandomForestClassifier     NaN  0.671642\n",
       "849          849  2016      9      RandomForestClassifier     NaN  0.701493\n",
       "850          850  2016     10      RandomForestClassifier     NaN  0.776119\n",
       "851          851  2016     11      RandomForestClassifier     NaN  0.701493\n",
       "852          852  2016     12      RandomForestClassifier     NaN  0.731343\n",
       "853          853  2016     13      RandomForestClassifier     NaN  0.746269\n",
       "854          854  2016     14      RandomForestClassifier     NaN  0.850746\n",
       "855          855  2017      0      RandomForestClassifier     NaN  0.671642\n",
       "856          856  2017      1      RandomForestClassifier     NaN  0.701493\n",
       "857          857  2017      2      RandomForestClassifier     NaN  0.701493\n",
       "858          858  2017      3      RandomForestClassifier     NaN  0.641791\n",
       "859          859  2017      4      RandomForestClassifier     NaN  0.656716\n",
       "860          860  2017      5      RandomForestClassifier     NaN  0.671642\n",
       "861          861  2017      6      RandomForestClassifier     NaN  0.641791\n",
       "862          862  2017      7      RandomForestClassifier     NaN  0.716418\n",
       "863          863  2017      8      RandomForestClassifier     NaN  0.791045\n",
       "864          864  2017      9      RandomForestClassifier     NaN  0.746269\n",
       "865          865  2017     10      RandomForestClassifier     NaN  0.746269\n",
       "866          866  2017     11      RandomForestClassifier     NaN  0.776119\n",
       "867          867  2017     12      RandomForestClassifier     NaN  0.776119\n",
       "868          868  2017     13      RandomForestClassifier     NaN  0.746269\n",
       "869          869  2017     14      RandomForestClassifier     NaN  0.746269\n",
       "870          870  2018      0      RandomForestClassifier     NaN  0.537313\n",
       "871          871  2018      1      RandomForestClassifier     NaN  0.641791\n",
       "872          872  2018      2      RandomForestClassifier     NaN  0.477612\n",
       "873          873  2018      3      RandomForestClassifier     NaN  0.537313\n",
       "874          874  2018      4      RandomForestClassifier     NaN  0.641791\n",
       "875          875  2018      5      RandomForestClassifier     NaN  0.701493\n",
       "876          876  2018      6      RandomForestClassifier     NaN  0.641791\n",
       "877          877  2018      7      RandomForestClassifier     NaN  0.522388\n",
       "878          878  2018      8      RandomForestClassifier     NaN  0.671642\n",
       "879          879  2018      9      RandomForestClassifier     NaN  0.611940\n",
       "880          880  2018     10      RandomForestClassifier     NaN  0.656716\n",
       "881          881  2018     11      RandomForestClassifier     NaN  0.537313\n",
       "882          882  2018     12      RandomForestClassifier     NaN  0.686567\n",
       "883          883  2018     13      RandomForestClassifier     NaN  0.671642\n",
       "884          884  2018     14      RandomForestClassifier     NaN  0.731343\n",
       "885          885  2019      0      RandomForestClassifier     NaN  0.597015\n",
       "886          886  2019      1      RandomForestClassifier     NaN  0.686567\n",
       "887          887  2019      2      RandomForestClassifier     NaN  0.597015\n",
       "888          888  2019      3      RandomForestClassifier     NaN  0.671642\n",
       "889          889  2019      4      RandomForestClassifier     NaN  0.656716\n",
       "890          890  2019      5      RandomForestClassifier     NaN  0.656716\n",
       "891          891  2019      6      RandomForestClassifier     NaN  0.716418\n",
       "892          892  2019      7      RandomForestClassifier     NaN  0.686567\n",
       "893          893  2019      8      RandomForestClassifier     NaN  0.761194\n",
       "894          894  2019      9      RandomForestClassifier     NaN  0.686567\n",
       "895          895  2019     10      RandomForestClassifier     NaN  0.731343\n",
       "896          896  2019     11      RandomForestClassifier     NaN  0.716418\n",
       "897          897  2019     12      RandomForestClassifier     NaN  0.805970\n",
       "898          898  2019     13      RandomForestClassifier     NaN  0.716418\n",
       "899          899  2019     14      RandomForestClassifier     NaN  0.761194\n",
       "900          900  2000      0        ExtraTreesClassifier     NaN  0.634921\n",
       "901          901  2000      1        ExtraTreesClassifier     NaN  0.634921\n",
       "902          902  2000      2        ExtraTreesClassifier     NaN  0.603175\n",
       "903          903  2000      3        ExtraTreesClassifier     NaN  0.666667\n",
       "904          904  2000      4        ExtraTreesClassifier     NaN  0.666667\n",
       "905          905  2000      5        ExtraTreesClassifier     NaN  0.634921\n",
       "906          906  2000      6        ExtraTreesClassifier     NaN  0.619048\n",
       "907          907  2000      7        ExtraTreesClassifier     NaN  0.603175\n",
       "908          908  2000      8        ExtraTreesClassifier     NaN  0.714286\n",
       "909          909  2000      9        ExtraTreesClassifier     NaN  0.698413\n",
       "910          910  2000     10        ExtraTreesClassifier     NaN  0.619048\n",
       "911          911  2000     11        ExtraTreesClassifier     NaN  0.730159\n",
       "912          912  2000     12        ExtraTreesClassifier     NaN  0.777778\n",
       "913          913  2000     13        ExtraTreesClassifier     NaN  0.698413\n",
       "914          914  2000     14        ExtraTreesClassifier     NaN  0.809524\n",
       "915          915  2001      0        ExtraTreesClassifier     NaN  0.633333\n",
       "916          916  2001      1        ExtraTreesClassifier     NaN  0.666667\n",
       "917          917  2001      2        ExtraTreesClassifier     NaN  0.550000\n",
       "918          918  2001      3        ExtraTreesClassifier     NaN  0.650000\n",
       "919          919  2001      4        ExtraTreesClassifier     NaN  0.700000\n",
       "920          920  2001      5        ExtraTreesClassifier     NaN  0.650000\n",
       "921          921  2001      6        ExtraTreesClassifier     NaN  0.500000\n",
       "922          922  2001      7        ExtraTreesClassifier     NaN  0.650000\n",
       "923          923  2001      8        ExtraTreesClassifier     NaN  0.666667\n",
       "924          924  2001      9        ExtraTreesClassifier     NaN  0.700000\n",
       "925          925  2001     10        ExtraTreesClassifier     NaN  0.766667\n",
       "926          926  2001     11        ExtraTreesClassifier     NaN  0.700000\n",
       "927          927  2001     12        ExtraTreesClassifier     NaN  0.666667\n",
       "928          928  2001     13        ExtraTreesClassifier     NaN  0.550000\n",
       "929          929  2001     14        ExtraTreesClassifier     NaN  0.683333\n",
       "930          930  2002      0        ExtraTreesClassifier     NaN  0.690141\n",
       "931          931  2002      1        ExtraTreesClassifier     NaN  0.619718\n",
       "932          932  2002      2        ExtraTreesClassifier     NaN  0.563380\n",
       "933          933  2002      3        ExtraTreesClassifier     NaN  0.605634\n",
       "934          934  2002      4        ExtraTreesClassifier     NaN  0.676056\n",
       "935          935  2002      5        ExtraTreesClassifier     NaN  0.633803\n",
       "936          936  2002      6        ExtraTreesClassifier     NaN  0.605634\n",
       "937          937  2002      7        ExtraTreesClassifier     NaN  0.676056\n",
       "938          938  2002      8        ExtraTreesClassifier     NaN  0.732394\n",
       "939          939  2002      9        ExtraTreesClassifier     NaN  0.605634\n",
       "940          940  2002     10        ExtraTreesClassifier     NaN  0.690141\n",
       "941          941  2002     11        ExtraTreesClassifier     NaN  0.591549\n",
       "942          942  2002     12        ExtraTreesClassifier     NaN  0.704225\n",
       "943          943  2002     13        ExtraTreesClassifier     NaN  0.563380\n",
       "944          944  2002     14        ExtraTreesClassifier     NaN  0.690141\n",
       "945          945  2003      0        ExtraTreesClassifier     NaN  0.656716\n",
       "946          946  2003      1        ExtraTreesClassifier     NaN  0.671642\n",
       "947          947  2003      2        ExtraTreesClassifier     NaN  0.641791\n",
       "948          948  2003      3        ExtraTreesClassifier     NaN  0.582090\n",
       "949          949  2003      4        ExtraTreesClassifier     NaN  0.746269\n",
       "950          950  2003      5        ExtraTreesClassifier     NaN  0.582090\n",
       "951          951  2003      6        ExtraTreesClassifier     NaN  0.611940\n",
       "952          952  2003      7        ExtraTreesClassifier     NaN  0.701493\n",
       "953          953  2003      8        ExtraTreesClassifier     NaN  0.656716\n",
       "954          954  2003      9        ExtraTreesClassifier     NaN  0.716418\n",
       "955          955  2003     10        ExtraTreesClassifier     NaN  0.641791\n",
       "956          956  2003     11        ExtraTreesClassifier     NaN  0.671642\n",
       "957          957  2003     12        ExtraTreesClassifier     NaN  0.686567\n",
       "958          958  2003     13        ExtraTreesClassifier     NaN  0.746269\n",
       "959          959  2003     14        ExtraTreesClassifier     NaN  0.686567\n",
       "960          960  2004      0        ExtraTreesClassifier     NaN  0.619048\n",
       "961          961  2004      1        ExtraTreesClassifier     NaN  0.539683\n",
       "962          962  2004      2        ExtraTreesClassifier     NaN  0.539683\n",
       "963          963  2004      3        ExtraTreesClassifier     NaN  0.650794\n",
       "964          964  2004      4        ExtraTreesClassifier     NaN  0.682540\n",
       "965          965  2004      5        ExtraTreesClassifier     NaN  0.619048\n",
       "966          966  2004      6        ExtraTreesClassifier     NaN  0.714286\n",
       "967          967  2004      7        ExtraTreesClassifier     NaN  0.555556\n",
       "968          968  2004      8        ExtraTreesClassifier     NaN  0.746032\n",
       "969          969  2004      9        ExtraTreesClassifier     NaN  0.666667\n",
       "970          970  2004     10        ExtraTreesClassifier     NaN  0.746032\n",
       "971          971  2004     11        ExtraTreesClassifier     NaN  0.666667\n",
       "972          972  2004     12        ExtraTreesClassifier     NaN  0.793651\n",
       "973          973  2004     13        ExtraTreesClassifier     NaN  0.682540\n",
       "974          974  2004     14        ExtraTreesClassifier     NaN  0.761905\n",
       "975          975  2005      0        ExtraTreesClassifier     NaN  0.617647\n",
       "976          976  2005      1        ExtraTreesClassifier     NaN  0.676471\n",
       "977          977  2005      2        ExtraTreesClassifier     NaN  0.661765\n",
       "978          978  2005      3        ExtraTreesClassifier     NaN  0.470588\n",
       "979          979  2005      4        ExtraTreesClassifier     NaN  0.676471\n",
       "980          980  2005      5        ExtraTreesClassifier     NaN  0.661765\n",
       "981          981  2005      6        ExtraTreesClassifier     NaN  0.617647\n",
       "982          982  2005      7        ExtraTreesClassifier     NaN  0.558824\n",
       "983          983  2005      8        ExtraTreesClassifier     NaN  0.558824\n",
       "984          984  2005      9        ExtraTreesClassifier     NaN  0.632353\n",
       "985          985  2005     10        ExtraTreesClassifier     NaN  0.676471\n",
       "986          986  2005     11        ExtraTreesClassifier     NaN  0.617647\n",
       "987          987  2005     12        ExtraTreesClassifier     NaN  0.617647\n",
       "988          988  2005     13        ExtraTreesClassifier     NaN  0.691176\n",
       "989          989  2005     14        ExtraTreesClassifier     NaN  0.720588\n",
       "990          990  2006      0        ExtraTreesClassifier     NaN  0.746479\n",
       "991          991  2006      1        ExtraTreesClassifier     NaN  0.774648\n",
       "992          992  2006      2        ExtraTreesClassifier     NaN  0.591549\n",
       "993          993  2006      3        ExtraTreesClassifier     NaN  0.647887\n",
       "994          994  2006      4        ExtraTreesClassifier     NaN  0.788732\n",
       "995          995  2006      5        ExtraTreesClassifier     NaN  0.647887\n",
       "996          996  2006      6        ExtraTreesClassifier     NaN  0.633803\n",
       "997          997  2006      7        ExtraTreesClassifier     NaN  0.746479\n",
       "998          998  2006      8        ExtraTreesClassifier     NaN  0.718310\n",
       "999          999  2006      9        ExtraTreesClassifier     NaN  0.732394\n",
       "1000        1000  2006     10        ExtraTreesClassifier     NaN  0.830986\n",
       "1001        1001  2006     11        ExtraTreesClassifier     NaN  0.704225\n",
       "1002        1002  2006     12        ExtraTreesClassifier     NaN  0.746479\n",
       "1003        1003  2006     13        ExtraTreesClassifier     NaN  0.704225\n",
       "1004        1004  2006     14        ExtraTreesClassifier     NaN  0.845070\n",
       "1005        1005  2007      0        ExtraTreesClassifier     NaN  0.582090\n",
       "1006        1006  2007      1        ExtraTreesClassifier     NaN  0.611940\n",
       "1007        1007  2007      2        ExtraTreesClassifier     NaN  0.582090\n",
       "1008        1008  2007      3        ExtraTreesClassifier     NaN  0.641791\n",
       "1009        1009  2007      4        ExtraTreesClassifier     NaN  0.597015\n",
       "1010        1010  2007      5        ExtraTreesClassifier     NaN  0.641791\n",
       "1011        1011  2007      6        ExtraTreesClassifier     NaN  0.597015\n",
       "1012        1012  2007      7        ExtraTreesClassifier     NaN  0.671642\n",
       "1013        1013  2007      8        ExtraTreesClassifier     NaN  0.731343\n",
       "1014        1014  2007      9        ExtraTreesClassifier     NaN  0.686567\n",
       "1015        1015  2007     10        ExtraTreesClassifier     NaN  0.626866\n",
       "1016        1016  2007     11        ExtraTreesClassifier     NaN  0.686567\n",
       "1017        1017  2007     12        ExtraTreesClassifier     NaN  0.686567\n",
       "1018        1018  2007     13        ExtraTreesClassifier     NaN  0.716418\n",
       "1019        1019  2007     14        ExtraTreesClassifier     NaN  0.805970\n",
       "1020        1020  2008      0        ExtraTreesClassifier     NaN  0.552239\n",
       "1021        1021  2008      1        ExtraTreesClassifier     NaN  0.611940\n",
       "1022        1022  2008      2        ExtraTreesClassifier     NaN  0.701493\n",
       "1023        1023  2008      3        ExtraTreesClassifier     NaN  0.656716\n",
       "1024        1024  2008      4        ExtraTreesClassifier     NaN  0.671642\n",
       "1025        1025  2008      5        ExtraTreesClassifier     NaN  0.597015\n",
       "1026        1026  2008      6        ExtraTreesClassifier     NaN  0.776119\n",
       "1027        1027  2008      7        ExtraTreesClassifier     NaN  0.626866\n",
       "1028        1028  2008      8        ExtraTreesClassifier     NaN  0.656716\n",
       "1029        1029  2008      9        ExtraTreesClassifier     NaN  0.641791\n",
       "1030        1030  2008     10        ExtraTreesClassifier     NaN  0.716418\n",
       "1031        1031  2008     11        ExtraTreesClassifier     NaN  0.761194\n",
       "1032        1032  2008     12        ExtraTreesClassifier     NaN  0.656716\n",
       "1033        1033  2008     13        ExtraTreesClassifier     NaN  0.716418\n",
       "1034        1034  2008     14        ExtraTreesClassifier     NaN  0.776119\n",
       "1035        1035  2009      0        ExtraTreesClassifier     NaN  0.650794\n",
       "1036        1036  2009      1        ExtraTreesClassifier     NaN  0.714286\n",
       "1037        1037  2009      2        ExtraTreesClassifier     NaN  0.682540\n",
       "1038        1038  2009      3        ExtraTreesClassifier     NaN  0.650794\n",
       "1039        1039  2009      4        ExtraTreesClassifier     NaN  0.603175\n",
       "1040        1040  2009      5        ExtraTreesClassifier     NaN  0.746032\n",
       "1041        1041  2009      6        ExtraTreesClassifier     NaN  0.714286\n",
       "1042        1042  2009      7        ExtraTreesClassifier     NaN  0.666667\n",
       "1043        1043  2009      8        ExtraTreesClassifier     NaN  0.619048\n",
       "1044        1044  2009      9        ExtraTreesClassifier     NaN  0.730159\n",
       "1045        1045  2009     10        ExtraTreesClassifier     NaN  0.650794\n",
       "1046        1046  2009     11        ExtraTreesClassifier     NaN  0.650794\n",
       "1047        1047  2009     12        ExtraTreesClassifier     NaN  0.682540\n",
       "1048        1048  2009     13        ExtraTreesClassifier     NaN  0.730159\n",
       "1049        1049  2009     14        ExtraTreesClassifier     NaN  0.730159\n",
       "1050        1050  2010      0        ExtraTreesClassifier     NaN  0.731343\n",
       "1051        1051  2010      1        ExtraTreesClassifier     NaN  0.731343\n",
       "1052        1052  2010      2        ExtraTreesClassifier     NaN  0.641791\n",
       "1053        1053  2010      3        ExtraTreesClassifier     NaN  0.671642\n",
       "1054        1054  2010      4        ExtraTreesClassifier     NaN  0.686567\n",
       "1055        1055  2010      5        ExtraTreesClassifier     NaN  0.731343\n",
       "1056        1056  2010      6        ExtraTreesClassifier     NaN  0.641791\n",
       "1057        1057  2010      7        ExtraTreesClassifier     NaN  0.701493\n",
       "1058        1058  2010      8        ExtraTreesClassifier     NaN  0.701493\n",
       "1059        1059  2010      9        ExtraTreesClassifier     NaN  0.686567\n",
       "1060        1060  2010     10        ExtraTreesClassifier     NaN  0.716418\n",
       "1061        1061  2010     11        ExtraTreesClassifier     NaN  0.701493\n",
       "1062        1062  2010     12        ExtraTreesClassifier     NaN  0.731343\n",
       "1063        1063  2010     13        ExtraTreesClassifier     NaN  0.716418\n",
       "1064        1064  2010     14        ExtraTreesClassifier     NaN  0.731343\n",
       "1065        1065  2011      0        ExtraTreesClassifier     NaN  0.552239\n",
       "1066        1066  2011      1        ExtraTreesClassifier     NaN  0.522388\n",
       "1067        1067  2011      2        ExtraTreesClassifier     NaN  0.716418\n",
       "1068        1068  2011      3        ExtraTreesClassifier     NaN  0.567164\n",
       "1069        1069  2011      4        ExtraTreesClassifier     NaN  0.626866\n",
       "1070        1070  2011      5        ExtraTreesClassifier     NaN  0.611940\n",
       "1071        1071  2011      6        ExtraTreesClassifier     NaN  0.686567\n",
       "1072        1072  2011      7        ExtraTreesClassifier     NaN  0.641791\n",
       "1073        1073  2011      8        ExtraTreesClassifier     NaN  0.582090\n",
       "1074        1074  2011      9        ExtraTreesClassifier     NaN  0.522388\n",
       "1075        1075  2011     10        ExtraTreesClassifier     NaN  0.656716\n",
       "1076        1076  2011     11        ExtraTreesClassifier     NaN  0.656716\n",
       "1077        1077  2011     12        ExtraTreesClassifier     NaN  0.597015\n",
       "1078        1078  2011     13        ExtraTreesClassifier     NaN  0.686567\n",
       "1079        1079  2011     14        ExtraTreesClassifier     NaN  0.641791\n",
       "1080        1080  2012      0        ExtraTreesClassifier     NaN  0.521127\n",
       "1081        1081  2012      1        ExtraTreesClassifier     NaN  0.661972\n",
       "1082        1082  2012      2        ExtraTreesClassifier     NaN  0.577465\n",
       "1083        1083  2012      3        ExtraTreesClassifier     NaN  0.690141\n",
       "1084        1084  2012      4        ExtraTreesClassifier     NaN  0.647887\n",
       "1085        1085  2012      5        ExtraTreesClassifier     NaN  0.661972\n",
       "1086        1086  2012      6        ExtraTreesClassifier     NaN  0.690141\n",
       "1087        1087  2012      7        ExtraTreesClassifier     NaN  0.676056\n",
       "1088        1088  2012      8        ExtraTreesClassifier     NaN  0.591549\n",
       "1089        1089  2012      9        ExtraTreesClassifier     NaN  0.676056\n",
       "1090        1090  2012     10        ExtraTreesClassifier     NaN  0.661972\n",
       "1091        1091  2012     11        ExtraTreesClassifier     NaN  0.732394\n",
       "1092        1092  2012     12        ExtraTreesClassifier     NaN  0.647887\n",
       "1093        1093  2012     13        ExtraTreesClassifier     NaN  0.690141\n",
       "1094        1094  2012     14        ExtraTreesClassifier     NaN  0.690141\n",
       "1095        1095  2013      0        ExtraTreesClassifier     NaN  0.507463\n",
       "1096        1096  2013      1        ExtraTreesClassifier     NaN  0.611940\n",
       "1097        1097  2013      2        ExtraTreesClassifier     NaN  0.552239\n",
       "1098        1098  2013      3        ExtraTreesClassifier     NaN  0.597015\n",
       "1099        1099  2013      4        ExtraTreesClassifier     NaN  0.626866\n",
       "1100        1100  2013      5        ExtraTreesClassifier     NaN  0.597015\n",
       "1101        1101  2013      6        ExtraTreesClassifier     NaN  0.716418\n",
       "1102        1102  2013      7        ExtraTreesClassifier     NaN  0.567164\n",
       "1103        1103  2013      8        ExtraTreesClassifier     NaN  0.597015\n",
       "1104        1104  2013      9        ExtraTreesClassifier     NaN  0.611940\n",
       "1105        1105  2013     10        ExtraTreesClassifier     NaN  0.567164\n",
       "1106        1106  2013     11        ExtraTreesClassifier     NaN  0.701493\n",
       "1107        1107  2013     12        ExtraTreesClassifier     NaN  0.626866\n",
       "1108        1108  2013     13        ExtraTreesClassifier     NaN  0.597015\n",
       "1109        1109  2013     14        ExtraTreesClassifier     NaN  0.641791\n",
       "1110        1110  2014      0        ExtraTreesClassifier     NaN  0.641791\n",
       "1111        1111  2014      1        ExtraTreesClassifier     NaN  0.611940\n",
       "1112        1112  2014      2        ExtraTreesClassifier     NaN  0.701493\n",
       "1113        1113  2014      3        ExtraTreesClassifier     NaN  0.671642\n",
       "1114        1114  2014      4        ExtraTreesClassifier     NaN  0.641791\n",
       "1115        1115  2014      5        ExtraTreesClassifier     NaN  0.776119\n",
       "1116        1116  2014      6        ExtraTreesClassifier     NaN  0.776119\n",
       "1117        1117  2014      7        ExtraTreesClassifier     NaN  0.656716\n",
       "1118        1118  2014      8        ExtraTreesClassifier     NaN  0.686567\n",
       "1119        1119  2014      9        ExtraTreesClassifier     NaN  0.686567\n",
       "1120        1120  2014     10        ExtraTreesClassifier     NaN  0.746269\n",
       "1121        1121  2014     11        ExtraTreesClassifier     NaN  0.791045\n",
       "1122        1122  2014     12        ExtraTreesClassifier     NaN  0.701493\n",
       "1123        1123  2014     13        ExtraTreesClassifier     NaN  0.820896\n",
       "1124        1124  2014     14        ExtraTreesClassifier     NaN  0.865672\n",
       "1125        1125  2015      0        ExtraTreesClassifier     NaN  0.628571\n",
       "1126        1126  2015      1        ExtraTreesClassifier     NaN  0.685714\n",
       "1127        1127  2015      2        ExtraTreesClassifier     NaN  0.614286\n",
       "1128        1128  2015      3        ExtraTreesClassifier     NaN  0.671429\n",
       "1129        1129  2015      4        ExtraTreesClassifier     NaN  0.671429\n",
       "1130        1130  2015      5        ExtraTreesClassifier     NaN  0.657143\n",
       "1131        1131  2015      6        ExtraTreesClassifier     NaN  0.714286\n",
       "1132        1132  2015      7        ExtraTreesClassifier     NaN  0.642857\n",
       "1133        1133  2015      8        ExtraTreesClassifier     NaN  0.671429\n",
       "1134        1134  2015      9        ExtraTreesClassifier     NaN  0.700000\n",
       "1135        1135  2015     10        ExtraTreesClassifier     NaN  0.685714\n",
       "1136        1136  2015     11        ExtraTreesClassifier     NaN  0.685714\n",
       "1137        1137  2015     12        ExtraTreesClassifier     NaN  0.728571\n",
       "1138        1138  2015     13        ExtraTreesClassifier     NaN  0.714286\n",
       "1139        1139  2015     14        ExtraTreesClassifier     NaN  0.814286\n",
       "1140        1140  2016      0        ExtraTreesClassifier     NaN  0.641791\n",
       "1141        1141  2016      1        ExtraTreesClassifier     NaN  0.746269\n",
       "1142        1142  2016      2        ExtraTreesClassifier     NaN  0.641791\n",
       "1143        1143  2016      3        ExtraTreesClassifier     NaN  0.611940\n",
       "1144        1144  2016      4        ExtraTreesClassifier     NaN  0.761194\n",
       "1145        1145  2016      5        ExtraTreesClassifier     NaN  0.701493\n",
       "1146        1146  2016      6        ExtraTreesClassifier     NaN  0.611940\n",
       "1147        1147  2016      7        ExtraTreesClassifier     NaN  0.716418\n",
       "1148        1148  2016      8        ExtraTreesClassifier     NaN  0.671642\n",
       "1149        1149  2016      9        ExtraTreesClassifier     NaN  0.716418\n",
       "1150        1150  2016     10        ExtraTreesClassifier     NaN  0.791045\n",
       "1151        1151  2016     11        ExtraTreesClassifier     NaN  0.701493\n",
       "1152        1152  2016     12        ExtraTreesClassifier     NaN  0.731343\n",
       "1153        1153  2016     13        ExtraTreesClassifier     NaN  0.716418\n",
       "1154        1154  2016     14        ExtraTreesClassifier     NaN  0.761194\n",
       "1155        1155  2017      0        ExtraTreesClassifier     NaN  0.671642\n",
       "1156        1156  2017      1        ExtraTreesClassifier     NaN  0.701493\n",
       "1157        1157  2017      2        ExtraTreesClassifier     NaN  0.701493\n",
       "1158        1158  2017      3        ExtraTreesClassifier     NaN  0.641791\n",
       "1159        1159  2017      4        ExtraTreesClassifier     NaN  0.656716\n",
       "1160        1160  2017      5        ExtraTreesClassifier     NaN  0.686567\n",
       "1161        1161  2017      6        ExtraTreesClassifier     NaN  0.701493\n",
       "1162        1162  2017      7        ExtraTreesClassifier     NaN  0.716418\n",
       "1163        1163  2017      8        ExtraTreesClassifier     NaN  0.776119\n",
       "1164        1164  2017      9        ExtraTreesClassifier     NaN  0.731343\n",
       "1165        1165  2017     10        ExtraTreesClassifier     NaN  0.746269\n",
       "1166        1166  2017     11        ExtraTreesClassifier     NaN  0.805970\n",
       "1167        1167  2017     12        ExtraTreesClassifier     NaN  0.761194\n",
       "1168        1168  2017     13        ExtraTreesClassifier     NaN  0.746269\n",
       "1169        1169  2017     14        ExtraTreesClassifier     NaN  0.776119\n",
       "1170        1170  2018      0        ExtraTreesClassifier     NaN  0.537313\n",
       "1171        1171  2018      1        ExtraTreesClassifier     NaN  0.641791\n",
       "1172        1172  2018      2        ExtraTreesClassifier     NaN  0.477612\n",
       "1173        1173  2018      3        ExtraTreesClassifier     NaN  0.537313\n",
       "1174        1174  2018      4        ExtraTreesClassifier     NaN  0.641791\n",
       "1175        1175  2018      5        ExtraTreesClassifier     NaN  0.671642\n",
       "1176        1176  2018      6        ExtraTreesClassifier     NaN  0.626866\n",
       "1177        1177  2018      7        ExtraTreesClassifier     NaN  0.582090\n",
       "1178        1178  2018      8        ExtraTreesClassifier     NaN  0.597015\n",
       "1179        1179  2018      9        ExtraTreesClassifier     NaN  0.641791\n",
       "1180        1180  2018     10        ExtraTreesClassifier     NaN  0.716418\n",
       "1181        1181  2018     11        ExtraTreesClassifier     NaN  0.552239\n",
       "1182        1182  2018     12        ExtraTreesClassifier     NaN  0.716418\n",
       "1183        1183  2018     13        ExtraTreesClassifier     NaN  0.686567\n",
       "1184        1184  2018     14        ExtraTreesClassifier     NaN  0.731343\n",
       "1185        1185  2019      0        ExtraTreesClassifier     NaN  0.597015\n",
       "1186        1186  2019      1        ExtraTreesClassifier     NaN  0.686567\n",
       "1187        1187  2019      2        ExtraTreesClassifier     NaN  0.597015\n",
       "1188        1188  2019      3        ExtraTreesClassifier     NaN  0.701493\n",
       "1189        1189  2019      4        ExtraTreesClassifier     NaN  0.641791\n",
       "1190        1190  2019      5        ExtraTreesClassifier     NaN  0.656716\n",
       "1191        1191  2019      6        ExtraTreesClassifier     NaN  0.716418\n",
       "1192        1192  2019      7        ExtraTreesClassifier     NaN  0.671642\n",
       "1193        1193  2019      8        ExtraTreesClassifier     NaN  0.731343\n",
       "1194        1194  2019      9        ExtraTreesClassifier     NaN  0.746269\n",
       "1195        1195  2019     10        ExtraTreesClassifier     NaN  0.731343\n",
       "1196        1196  2019     11        ExtraTreesClassifier     NaN  0.716418\n",
       "1197        1197  2019     12        ExtraTreesClassifier     NaN  0.776119\n",
       "1198        1198  2019     13        ExtraTreesClassifier     NaN  0.701493\n",
       "1199        1199  2019     14        ExtraTreesClassifier     NaN  0.791045\n",
       "1200        1200  2000      0        KNeighborsClassifier     NaN  0.634921\n",
       "1201        1201  2000      1        KNeighborsClassifier     NaN  0.571429\n",
       "1202        1202  2000      2        KNeighborsClassifier     NaN  0.603175\n",
       "1203        1203  2000      3        KNeighborsClassifier     NaN  0.714286\n",
       "1204        1204  2000      4        KNeighborsClassifier     NaN  0.650794\n",
       "1205        1205  2000      5        KNeighborsClassifier     NaN  0.603175\n",
       "1206        1206  2000      6        KNeighborsClassifier     NaN  0.619048\n",
       "1207        1207  2000      7        KNeighborsClassifier     NaN  0.666667\n",
       "1208        1208  2000      8        KNeighborsClassifier     NaN  0.682540\n",
       "1209        1209  2000      9        KNeighborsClassifier     NaN  0.698413\n",
       "1210        1210  2000     10        KNeighborsClassifier     NaN  0.650794\n",
       "1211        1211  2000     11        KNeighborsClassifier     NaN  0.666667\n",
       "1212        1212  2000     12        KNeighborsClassifier     NaN  0.730159\n",
       "1213        1213  2000     13        KNeighborsClassifier     NaN  0.682540\n",
       "1214        1214  2000     14        KNeighborsClassifier     NaN  0.650794\n",
       "1215        1215  2001      0        KNeighborsClassifier     NaN  0.633333\n",
       "1216        1216  2001      1        KNeighborsClassifier     NaN  0.666667\n",
       "1217        1217  2001      2        KNeighborsClassifier     NaN  0.550000\n",
       "1218        1218  2001      3        KNeighborsClassifier     NaN  0.483333\n",
       "1219        1219  2001      4        KNeighborsClassifier     NaN  0.666667\n",
       "1220        1220  2001      5        KNeighborsClassifier     NaN  0.516667\n",
       "1221        1221  2001      6        KNeighborsClassifier     NaN  0.550000\n",
       "1222        1222  2001      7        KNeighborsClassifier     NaN  0.650000\n",
       "1223        1223  2001      8        KNeighborsClassifier     NaN  0.533333\n",
       "1224        1224  2001      9        KNeighborsClassifier     NaN  0.616667\n",
       "1225        1225  2001     10        KNeighborsClassifier     NaN  0.716667\n",
       "1226        1226  2001     11        KNeighborsClassifier     NaN  0.700000\n",
       "1227        1227  2001     12        KNeighborsClassifier     NaN  0.750000\n",
       "1228        1228  2001     13        KNeighborsClassifier     NaN  0.550000\n",
       "1229        1229  2001     14        KNeighborsClassifier     NaN  0.633333\n",
       "1230        1230  2002      0        KNeighborsClassifier     NaN  0.605634\n",
       "1231        1231  2002      1        KNeighborsClassifier     NaN  0.436620\n",
       "1232        1232  2002      2        KNeighborsClassifier     NaN  0.521127\n",
       "1233        1233  2002      3        KNeighborsClassifier     NaN  0.605634\n",
       "1234        1234  2002      4        KNeighborsClassifier     NaN  0.647887\n",
       "1235        1235  2002      5        KNeighborsClassifier     NaN  0.619718\n",
       "1236        1236  2002      6        KNeighborsClassifier     NaN  0.492958\n",
       "1237        1237  2002      7        KNeighborsClassifier     NaN  0.535211\n",
       "1238        1238  2002      8        KNeighborsClassifier     NaN  0.676056\n",
       "1239        1239  2002      9        KNeighborsClassifier     NaN  0.577465\n",
       "1240        1240  2002     10        KNeighborsClassifier     NaN  0.633803\n",
       "1241        1241  2002     11        KNeighborsClassifier     NaN  0.690141\n",
       "1242        1242  2002     12        KNeighborsClassifier     NaN  0.718310\n",
       "1243        1243  2002     13        KNeighborsClassifier     NaN  0.591549\n",
       "1244        1244  2002     14        KNeighborsClassifier     NaN  0.718310\n",
       "1245        1245  2003      0        KNeighborsClassifier     NaN  0.552239\n",
       "1246        1246  2003      1        KNeighborsClassifier     NaN  0.552239\n",
       "1247        1247  2003      2        KNeighborsClassifier     NaN  0.597015\n",
       "1248        1248  2003      3        KNeighborsClassifier     NaN  0.597015\n",
       "1249        1249  2003      4        KNeighborsClassifier     NaN  0.746269\n",
       "1250        1250  2003      5        KNeighborsClassifier     NaN  0.597015\n",
       "1251        1251  2003      6        KNeighborsClassifier     NaN  0.552239\n",
       "1252        1252  2003      7        KNeighborsClassifier     NaN  0.686567\n",
       "1253        1253  2003      8        KNeighborsClassifier     NaN  0.731343\n",
       "1254        1254  2003      9        KNeighborsClassifier     NaN  0.597015\n",
       "1255        1255  2003     10        KNeighborsClassifier     NaN  0.716418\n",
       "1256        1256  2003     11        KNeighborsClassifier     NaN  0.671642\n",
       "1257        1257  2003     12        KNeighborsClassifier     NaN  0.641791\n",
       "1258        1258  2003     13        KNeighborsClassifier     NaN  0.641791\n",
       "1259        1259  2003     14        KNeighborsClassifier     NaN  0.671642\n",
       "1260        1260  2004      0        KNeighborsClassifier     NaN  0.571429\n",
       "1261        1261  2004      1        KNeighborsClassifier     NaN  0.460317\n",
       "1262        1262  2004      2        KNeighborsClassifier     NaN  0.571429\n",
       "1263        1263  2004      3        KNeighborsClassifier     NaN  0.603175\n",
       "1264        1264  2004      4        KNeighborsClassifier     NaN  0.603175\n",
       "1265        1265  2004      5        KNeighborsClassifier     NaN  0.682540\n",
       "1266        1266  2004      6        KNeighborsClassifier     NaN  0.619048\n",
       "1267        1267  2004      7        KNeighborsClassifier     NaN  0.523810\n",
       "1268        1268  2004      8        KNeighborsClassifier     NaN  0.746032\n",
       "1269        1269  2004      9        KNeighborsClassifier     NaN  0.619048\n",
       "1270        1270  2004     10        KNeighborsClassifier     NaN  0.698413\n",
       "1271        1271  2004     11        KNeighborsClassifier     NaN  0.761905\n",
       "1272        1272  2004     12        KNeighborsClassifier     NaN  0.666667\n",
       "1273        1273  2004     13        KNeighborsClassifier     NaN  0.634921\n",
       "1274        1274  2004     14        KNeighborsClassifier     NaN  0.746032\n",
       "1275        1275  2005      0        KNeighborsClassifier     NaN  0.470588\n",
       "1276        1276  2005      1        KNeighborsClassifier     NaN  0.676471\n",
       "1277        1277  2005      2        KNeighborsClassifier     NaN  0.676471\n",
       "1278        1278  2005      3        KNeighborsClassifier     NaN  0.470588\n",
       "1279        1279  2005      4        KNeighborsClassifier     NaN  0.676471\n",
       "1280        1280  2005      5        KNeighborsClassifier     NaN  0.617647\n",
       "1281        1281  2005      6        KNeighborsClassifier     NaN  0.588235\n",
       "1282        1282  2005      7        KNeighborsClassifier     NaN  0.647059\n",
       "1283        1283  2005      8        KNeighborsClassifier     NaN  0.558824\n",
       "1284        1284  2005      9        KNeighborsClassifier     NaN  0.632353\n",
       "1285        1285  2005     10        KNeighborsClassifier     NaN  0.588235\n",
       "1286        1286  2005     11        KNeighborsClassifier     NaN  0.514706\n",
       "1287        1287  2005     12        KNeighborsClassifier     NaN  0.558824\n",
       "1288        1288  2005     13        KNeighborsClassifier     NaN  0.647059\n",
       "1289        1289  2005     14        KNeighborsClassifier     NaN  0.661765\n",
       "1290        1290  2006      0        KNeighborsClassifier     NaN  0.718310\n",
       "1291        1291  2006      1        KNeighborsClassifier     NaN  0.690141\n",
       "1292        1292  2006      2        KNeighborsClassifier     NaN  0.619718\n",
       "1293        1293  2006      3        KNeighborsClassifier     NaN  0.633803\n",
       "1294        1294  2006      4        KNeighborsClassifier     NaN  0.760563\n",
       "1295        1295  2006      5        KNeighborsClassifier     NaN  0.591549\n",
       "1296        1296  2006      6        KNeighborsClassifier     NaN  0.647887\n",
       "1297        1297  2006      7        KNeighborsClassifier     NaN  0.690141\n",
       "1298        1298  2006      8        KNeighborsClassifier     NaN  0.774648\n",
       "1299        1299  2006      9        KNeighborsClassifier     NaN  0.661972\n",
       "1300        1300  2006     10        KNeighborsClassifier     NaN  0.718310\n",
       "1301        1301  2006     11        KNeighborsClassifier     NaN  0.676056\n",
       "1302        1302  2006     12        KNeighborsClassifier     NaN  0.774648\n",
       "1303        1303  2006     13        KNeighborsClassifier     NaN  0.704225\n",
       "1304        1304  2006     14        KNeighborsClassifier     NaN  0.704225\n",
       "1305        1305  2007      0        KNeighborsClassifier     NaN  0.552239\n",
       "1306        1306  2007      1        KNeighborsClassifier     NaN  0.343284\n",
       "1307        1307  2007      2        KNeighborsClassifier     NaN  0.268657\n",
       "1308        1308  2007      3        KNeighborsClassifier     NaN  0.641791\n",
       "1309        1309  2007      4        KNeighborsClassifier     NaN  0.582090\n",
       "1310        1310  2007      5        KNeighborsClassifier     NaN  0.567164\n",
       "1311        1311  2007      6        KNeighborsClassifier     NaN  0.597015\n",
       "1312        1312  2007      7        KNeighborsClassifier     NaN  0.716418\n",
       "1313        1313  2007      8        KNeighborsClassifier     NaN  0.686567\n",
       "1314        1314  2007      9        KNeighborsClassifier     NaN  0.597015\n",
       "1315        1315  2007     10        KNeighborsClassifier     NaN  0.671642\n",
       "1316        1316  2007     11        KNeighborsClassifier     NaN  0.611940\n",
       "1317        1317  2007     12        KNeighborsClassifier     NaN  0.686567\n",
       "1318        1318  2007     13        KNeighborsClassifier     NaN  0.701493\n",
       "1319        1319  2007     14        KNeighborsClassifier     NaN  0.686567\n",
       "1320        1320  2008      0        KNeighborsClassifier     NaN  0.582090\n",
       "1321        1321  2008      1        KNeighborsClassifier     NaN  0.552239\n",
       "1322        1322  2008      2        KNeighborsClassifier     NaN  0.701493\n",
       "1323        1323  2008      3        KNeighborsClassifier     NaN  0.656716\n",
       "1324        1324  2008      4        KNeighborsClassifier     NaN  0.686567\n",
       "1325        1325  2008      5        KNeighborsClassifier     NaN  0.656716\n",
       "1326        1326  2008      6        KNeighborsClassifier     NaN  0.686567\n",
       "1327        1327  2008      7        KNeighborsClassifier     NaN  0.701493\n",
       "1328        1328  2008      8        KNeighborsClassifier     NaN  0.597015\n",
       "1329        1329  2008      9        KNeighborsClassifier     NaN  0.626866\n",
       "1330        1330  2008     10        KNeighborsClassifier     NaN  0.686567\n",
       "1331        1331  2008     11        KNeighborsClassifier     NaN  0.641791\n",
       "1332        1332  2008     12        KNeighborsClassifier     NaN  0.611940\n",
       "1333        1333  2008     13        KNeighborsClassifier     NaN  0.686567\n",
       "1334        1334  2008     14        KNeighborsClassifier     NaN  0.761194\n",
       "1335        1335  2009      0        KNeighborsClassifier     NaN  0.650794\n",
       "1336        1336  2009      1        KNeighborsClassifier     NaN  0.619048\n",
       "1337        1337  2009      2        KNeighborsClassifier     NaN  0.682540\n",
       "1338        1338  2009      3        KNeighborsClassifier     NaN  0.650794\n",
       "1339        1339  2009      4        KNeighborsClassifier     NaN  0.603175\n",
       "1340        1340  2009      5        KNeighborsClassifier     NaN  0.666667\n",
       "1341        1341  2009      6        KNeighborsClassifier     NaN  0.666667\n",
       "1342        1342  2009      7        KNeighborsClassifier     NaN  0.650794\n",
       "1343        1343  2009      8        KNeighborsClassifier     NaN  0.666667\n",
       "1344        1344  2009      9        KNeighborsClassifier     NaN  0.746032\n",
       "1345        1345  2009     10        KNeighborsClassifier     NaN  0.698413\n",
       "1346        1346  2009     11        KNeighborsClassifier     NaN  0.619048\n",
       "1347        1347  2009     12        KNeighborsClassifier     NaN  0.666667\n",
       "1348        1348  2009     13        KNeighborsClassifier     NaN  0.777778\n",
       "1349        1349  2009     14        KNeighborsClassifier     NaN  0.666667\n",
       "1350        1350  2010      0        KNeighborsClassifier     NaN  0.671642\n",
       "1351        1351  2010      1        KNeighborsClassifier     NaN  0.641791\n",
       "1352        1352  2010      2        KNeighborsClassifier     NaN  0.656716\n",
       "1353        1353  2010      3        KNeighborsClassifier     NaN  0.388060\n",
       "1354        1354  2010      4        KNeighborsClassifier     NaN  0.686567\n",
       "1355        1355  2010      5        KNeighborsClassifier     NaN  0.686567\n",
       "1356        1356  2010      6        KNeighborsClassifier     NaN  0.597015\n",
       "1357        1357  2010      7        KNeighborsClassifier     NaN  0.552239\n",
       "1358        1358  2010      8        KNeighborsClassifier     NaN  0.731343\n",
       "1359        1359  2010      9        KNeighborsClassifier     NaN  0.701493\n",
       "1360        1360  2010     10        KNeighborsClassifier     NaN  0.731343\n",
       "1361        1361  2010     11        KNeighborsClassifier     NaN  0.746269\n",
       "1362        1362  2010     12        KNeighborsClassifier     NaN  0.716418\n",
       "1363        1363  2010     13        KNeighborsClassifier     NaN  0.716418\n",
       "1364        1364  2010     14        KNeighborsClassifier     NaN  0.805970\n",
       "1365        1365  2011      0        KNeighborsClassifier     NaN  0.582090\n",
       "1366        1366  2011      1        KNeighborsClassifier     NaN  0.507463\n",
       "1367        1367  2011      2        KNeighborsClassifier     NaN  0.716418\n",
       "1368        1368  2011      3        KNeighborsClassifier     NaN  0.537313\n",
       "1369        1369  2011      4        KNeighborsClassifier     NaN  0.597015\n",
       "1370        1370  2011      5        KNeighborsClassifier     NaN  0.552239\n",
       "1371        1371  2011      6        KNeighborsClassifier     NaN  0.626866\n",
       "1372        1372  2011      7        KNeighborsClassifier     NaN  0.626866\n",
       "1373        1373  2011      8        KNeighborsClassifier     NaN  0.611940\n",
       "1374        1374  2011      9        KNeighborsClassifier     NaN  0.597015\n",
       "1375        1375  2011     10        KNeighborsClassifier     NaN  0.656716\n",
       "1376        1376  2011     11        KNeighborsClassifier     NaN  0.641791\n",
       "1377        1377  2011     12        KNeighborsClassifier     NaN  0.641791\n",
       "1378        1378  2011     13        KNeighborsClassifier     NaN  0.597015\n",
       "1379        1379  2011     14        KNeighborsClassifier     NaN  0.671642\n",
       "1380        1380  2012      0        KNeighborsClassifier     NaN  0.549296\n",
       "1381        1381  2012      1        KNeighborsClassifier     NaN  0.661972\n",
       "1382        1382  2012      2        KNeighborsClassifier     NaN  0.647887\n",
       "1383        1383  2012      3        KNeighborsClassifier     NaN  0.619718\n",
       "1384        1384  2012      4        KNeighborsClassifier     NaN  0.605634\n",
       "1385        1385  2012      5        KNeighborsClassifier     NaN  0.647887\n",
       "1386        1386  2012      6        KNeighborsClassifier     NaN  0.661972\n",
       "1387        1387  2012      7        KNeighborsClassifier     NaN  0.661972\n",
       "1388        1388  2012      8        KNeighborsClassifier     NaN  0.577465\n",
       "1389        1389  2012      9        KNeighborsClassifier     NaN  0.704225\n",
       "1390        1390  2012     10        KNeighborsClassifier     NaN  0.577465\n",
       "1391        1391  2012     11        KNeighborsClassifier     NaN  0.577465\n",
       "1392        1392  2012     12        KNeighborsClassifier     NaN  0.605634\n",
       "1393        1393  2012     13        KNeighborsClassifier     NaN  0.661972\n",
       "1394        1394  2012     14        KNeighborsClassifier     NaN  0.619718\n",
       "1395        1395  2013      0        KNeighborsClassifier     NaN  0.477612\n",
       "1396        1396  2013      1        KNeighborsClassifier     NaN  0.507463\n",
       "1397        1397  2013      2        KNeighborsClassifier     NaN  0.522388\n",
       "1398        1398  2013      3        KNeighborsClassifier     NaN  0.671642\n",
       "1399        1399  2013      4        KNeighborsClassifier     NaN  0.507463\n",
       "1400        1400  2013      5        KNeighborsClassifier     NaN  0.597015\n",
       "1401        1401  2013      6        KNeighborsClassifier     NaN  0.671642\n",
       "1402        1402  2013      7        KNeighborsClassifier     NaN  0.552239\n",
       "1403        1403  2013      8        KNeighborsClassifier     NaN  0.597015\n",
       "1404        1404  2013      9        KNeighborsClassifier     NaN  0.611940\n",
       "1405        1405  2013     10        KNeighborsClassifier     NaN  0.507463\n",
       "1406        1406  2013     11        KNeighborsClassifier     NaN  0.641791\n",
       "1407        1407  2013     12        KNeighborsClassifier     NaN  0.626866\n",
       "1408        1408  2013     13        KNeighborsClassifier     NaN  0.641791\n",
       "1409        1409  2013     14        KNeighborsClassifier     NaN  0.611940\n",
       "1410        1410  2014      0        KNeighborsClassifier     NaN  0.641791\n",
       "1411        1411  2014      1        KNeighborsClassifier     NaN  0.641791\n",
       "1412        1412  2014      2        KNeighborsClassifier     NaN  0.626866\n",
       "1413        1413  2014      3        KNeighborsClassifier     NaN  0.641791\n",
       "1414        1414  2014      4        KNeighborsClassifier     NaN  0.582090\n",
       "1415        1415  2014      5        KNeighborsClassifier     NaN  0.761194\n",
       "1416        1416  2014      6        KNeighborsClassifier     NaN  0.716418\n",
       "1417        1417  2014      7        KNeighborsClassifier     NaN  0.686567\n",
       "1418        1418  2014      8        KNeighborsClassifier     NaN  0.701493\n",
       "1419        1419  2014      9        KNeighborsClassifier     NaN  0.731343\n",
       "1420        1420  2014     10        KNeighborsClassifier     NaN  0.820896\n",
       "1421        1421  2014     11        KNeighborsClassifier     NaN  0.716418\n",
       "1422        1422  2014     12        KNeighborsClassifier     NaN  0.701493\n",
       "1423        1423  2014     13        KNeighborsClassifier     NaN  0.805970\n",
       "1424        1424  2014     14        KNeighborsClassifier     NaN  0.791045\n",
       "1425        1425  2015      0        KNeighborsClassifier     NaN  0.500000\n",
       "1426        1426  2015      1        KNeighborsClassifier     NaN  0.542857\n",
       "1427        1427  2015      2        KNeighborsClassifier     NaN  0.585714\n",
       "1428        1428  2015      3        KNeighborsClassifier     NaN  0.585714\n",
       "1429        1429  2015      4        KNeighborsClassifier     NaN  0.642857\n",
       "1430        1430  2015      5        KNeighborsClassifier     NaN  0.642857\n",
       "1431        1431  2015      6        KNeighborsClassifier     NaN  0.728571\n",
       "1432        1432  2015      7        KNeighborsClassifier     NaN  0.628571\n",
       "1433        1433  2015      8        KNeighborsClassifier     NaN  0.714286\n",
       "1434        1434  2015      9        KNeighborsClassifier     NaN  0.671429\n",
       "1435        1435  2015     10        KNeighborsClassifier     NaN  0.728571\n",
       "1436        1436  2015     11        KNeighborsClassifier     NaN  0.685714\n",
       "1437        1437  2015     12        KNeighborsClassifier     NaN  0.671429\n",
       "1438        1438  2015     13        KNeighborsClassifier     NaN  0.742857\n",
       "1439        1439  2015     14        KNeighborsClassifier     NaN  0.742857\n",
       "1440        1440  2016      0        KNeighborsClassifier     NaN  0.641791\n",
       "1441        1441  2016      1        KNeighborsClassifier     NaN  0.746269\n",
       "1442        1442  2016      2        KNeighborsClassifier     NaN  0.537313\n",
       "1443        1443  2016      3        KNeighborsClassifier     NaN  0.447761\n",
       "1444        1444  2016      4        KNeighborsClassifier     NaN  0.731343\n",
       "1445        1445  2016      5        KNeighborsClassifier     NaN  0.731343\n",
       "1446        1446  2016      6        KNeighborsClassifier     NaN  0.626866\n",
       "1447        1447  2016      7        KNeighborsClassifier     NaN  0.746269\n",
       "1448        1448  2016      8        KNeighborsClassifier     NaN  0.641791\n",
       "1449        1449  2016      9        KNeighborsClassifier     NaN  0.761194\n",
       "1450        1450  2016     10        KNeighborsClassifier     NaN  0.746269\n",
       "1451        1451  2016     11        KNeighborsClassifier     NaN  0.701493\n",
       "1452        1452  2016     12        KNeighborsClassifier     NaN  0.761194\n",
       "1453        1453  2016     13        KNeighborsClassifier     NaN  0.761194\n",
       "1454        1454  2016     14        KNeighborsClassifier     NaN  0.776119\n",
       "1455        1455  2017      0        KNeighborsClassifier     NaN  0.656716\n",
       "1456        1456  2017      1        KNeighborsClassifier     NaN  0.477612\n",
       "1457        1457  2017      2        KNeighborsClassifier     NaN  0.701493\n",
       "1458        1458  2017      3        KNeighborsClassifier     NaN  0.611940\n",
       "1459        1459  2017      4        KNeighborsClassifier     NaN  0.626866\n",
       "1460        1460  2017      5        KNeighborsClassifier     NaN  0.716418\n",
       "1461        1461  2017      6        KNeighborsClassifier     NaN  0.671642\n",
       "1462        1462  2017      7        KNeighborsClassifier     NaN  0.656716\n",
       "1463        1463  2017      8        KNeighborsClassifier     NaN  0.746269\n",
       "1464        1464  2017      9        KNeighborsClassifier     NaN  0.686567\n",
       "1465        1465  2017     10        KNeighborsClassifier     NaN  0.656716\n",
       "1466        1466  2017     11        KNeighborsClassifier     NaN  0.701493\n",
       "1467        1467  2017     12        KNeighborsClassifier     NaN  0.776119\n",
       "1468        1468  2017     13        KNeighborsClassifier     NaN  0.776119\n",
       "1469        1469  2017     14        KNeighborsClassifier     NaN  0.761194\n",
       "1470        1470  2018      0        KNeighborsClassifier     NaN  0.447761\n",
       "1471        1471  2018      1        KNeighborsClassifier     NaN  0.611940\n",
       "1472        1472  2018      2        KNeighborsClassifier     NaN  0.417910\n",
       "1473        1473  2018      3        KNeighborsClassifier     NaN  0.537313\n",
       "1474        1474  2018      4        KNeighborsClassifier     NaN  0.626866\n",
       "1475        1475  2018      5        KNeighborsClassifier     NaN  0.671642\n",
       "1476        1476  2018      6        KNeighborsClassifier     NaN  0.552239\n",
       "1477        1477  2018      7        KNeighborsClassifier     NaN  0.507463\n",
       "1478        1478  2018      8        KNeighborsClassifier     NaN  0.671642\n",
       "1479        1479  2018      9        KNeighborsClassifier     NaN  0.626866\n",
       "1480        1480  2018     10        KNeighborsClassifier     NaN  0.641791\n",
       "1481        1481  2018     11        KNeighborsClassifier     NaN  0.641791\n",
       "1482        1482  2018     12        KNeighborsClassifier     NaN  0.611940\n",
       "1483        1483  2018     13        KNeighborsClassifier     NaN  0.641791\n",
       "1484        1484  2018     14        KNeighborsClassifier     NaN  0.686567\n",
       "1485        1485  2019      0        KNeighborsClassifier     NaN  0.477612\n",
       "1486        1486  2019      1        KNeighborsClassifier     NaN  0.686567\n",
       "1487        1487  2019      2        KNeighborsClassifier     NaN  0.552239\n",
       "1488        1488  2019      3        KNeighborsClassifier     NaN  0.552239\n",
       "1489        1489  2019      4        KNeighborsClassifier     NaN  0.626866\n",
       "1490        1490  2019      5        KNeighborsClassifier     NaN  0.686567\n",
       "1491        1491  2019      6        KNeighborsClassifier     NaN  0.597015\n",
       "1492        1492  2019      7        KNeighborsClassifier     NaN  0.761194\n",
       "1493        1493  2019      8        KNeighborsClassifier     NaN  0.716418\n",
       "1494        1494  2019      9        KNeighborsClassifier     NaN  0.626866\n",
       "1495        1495  2019     10        KNeighborsClassifier     NaN  0.671642\n",
       "1496        1496  2019     11        KNeighborsClassifier     NaN  0.686567\n",
       "1497        1497  2019     12        KNeighborsClassifier     NaN  0.701493\n",
       "1498        1498  2019     13        KNeighborsClassifier     NaN  0.686567\n",
       "1499        1499  2019     14        KNeighborsClassifier     NaN  0.761194\n",
       "1500        1500  2000      0      DecisionTreeClassifier     NaN  0.634921\n",
       "1501        1501  2000      1      DecisionTreeClassifier     NaN  0.634921\n",
       "1502        1502  2000      2      DecisionTreeClassifier     NaN  0.603175\n",
       "1503        1503  2000      3      DecisionTreeClassifier     NaN  0.666667\n",
       "1504        1504  2000      4      DecisionTreeClassifier     NaN  0.666667\n",
       "1505        1505  2000      5      DecisionTreeClassifier     NaN  0.650794\n",
       "1506        1506  2000      6      DecisionTreeClassifier     NaN  0.619048\n",
       "1507        1507  2000      7      DecisionTreeClassifier     NaN  0.603175\n",
       "1508        1508  2000      8      DecisionTreeClassifier     NaN  0.714286\n",
       "1509        1509  2000      9      DecisionTreeClassifier     NaN  0.682540\n",
       "1510        1510  2000     10      DecisionTreeClassifier     NaN  0.603175\n",
       "1511        1511  2000     11      DecisionTreeClassifier     NaN  0.761905\n",
       "1512        1512  2000     12      DecisionTreeClassifier     NaN  0.698413\n",
       "1513        1513  2000     13      DecisionTreeClassifier     NaN  0.666667\n",
       "1514        1514  2000     14      DecisionTreeClassifier     NaN  0.698413\n",
       "1515        1515  2001      0      DecisionTreeClassifier     NaN  0.633333\n",
       "1516        1516  2001      1      DecisionTreeClassifier     NaN  0.666667\n",
       "1517        1517  2001      2      DecisionTreeClassifier     NaN  0.550000\n",
       "1518        1518  2001      3      DecisionTreeClassifier     NaN  0.650000\n",
       "1519        1519  2001      4      DecisionTreeClassifier     NaN  0.700000\n",
       "1520        1520  2001      5      DecisionTreeClassifier     NaN  0.650000\n",
       "1521        1521  2001      6      DecisionTreeClassifier     NaN  0.500000\n",
       "1522        1522  2001      7      DecisionTreeClassifier     NaN  0.650000\n",
       "1523        1523  2001      8      DecisionTreeClassifier     NaN  0.650000\n",
       "1524        1524  2001      9      DecisionTreeClassifier     NaN  0.650000\n",
       "1525        1525  2001     10      DecisionTreeClassifier     NaN  0.700000\n",
       "1526        1526  2001     11      DecisionTreeClassifier     NaN  0.650000\n",
       "1527        1527  2001     12      DecisionTreeClassifier     NaN  0.616667\n",
       "1528        1528  2001     13      DecisionTreeClassifier     NaN  0.516667\n",
       "1529        1529  2001     14      DecisionTreeClassifier     NaN  0.566667\n",
       "1530        1530  2002      0      DecisionTreeClassifier     NaN  0.690141\n",
       "1531        1531  2002      1      DecisionTreeClassifier     NaN  0.619718\n",
       "1532        1532  2002      2      DecisionTreeClassifier     NaN  0.563380\n",
       "1533        1533  2002      3      DecisionTreeClassifier     NaN  0.605634\n",
       "1534        1534  2002      4      DecisionTreeClassifier     NaN  0.676056\n",
       "1535        1535  2002      5      DecisionTreeClassifier     NaN  0.633803\n",
       "1536        1536  2002      6      DecisionTreeClassifier     NaN  0.605634\n",
       "1537        1537  2002      7      DecisionTreeClassifier     NaN  0.676056\n",
       "1538        1538  2002      8      DecisionTreeClassifier     NaN  0.704225\n",
       "1539        1539  2002      9      DecisionTreeClassifier     NaN  0.605634\n",
       "1540        1540  2002     10      DecisionTreeClassifier     NaN  0.661972\n",
       "1541        1541  2002     11      DecisionTreeClassifier     NaN  0.535211\n",
       "1542        1542  2002     12      DecisionTreeClassifier     NaN  0.690141\n",
       "1543        1543  2002     13      DecisionTreeClassifier     NaN  0.549296\n",
       "1544        1544  2002     14      DecisionTreeClassifier     NaN  0.619718\n",
       "1545        1545  2003      0      DecisionTreeClassifier     NaN  0.656716\n",
       "1546        1546  2003      1      DecisionTreeClassifier     NaN  0.671642\n",
       "1547        1547  2003      2      DecisionTreeClassifier     NaN  0.641791\n",
       "1548        1548  2003      3      DecisionTreeClassifier     NaN  0.582090\n",
       "1549        1549  2003      4      DecisionTreeClassifier     NaN  0.746269\n",
       "1550        1550  2003      5      DecisionTreeClassifier     NaN  0.582090\n",
       "1551        1551  2003      6      DecisionTreeClassifier     NaN  0.582090\n",
       "1552        1552  2003      7      DecisionTreeClassifier     NaN  0.686567\n",
       "1553        1553  2003      8      DecisionTreeClassifier     NaN  0.656716\n",
       "1554        1554  2003      9      DecisionTreeClassifier     NaN  0.716418\n",
       "1555        1555  2003     10      DecisionTreeClassifier     NaN  0.611940\n",
       "1556        1556  2003     11      DecisionTreeClassifier     NaN  0.686567\n",
       "1557        1557  2003     12      DecisionTreeClassifier     NaN  0.701493\n",
       "1558        1558  2003     13      DecisionTreeClassifier     NaN  0.686567\n",
       "1559        1559  2003     14      DecisionTreeClassifier     NaN  0.716418\n",
       "1560        1560  2004      0      DecisionTreeClassifier     NaN  0.619048\n",
       "1561        1561  2004      1      DecisionTreeClassifier     NaN  0.539683\n",
       "1562        1562  2004      2      DecisionTreeClassifier     NaN  0.555556\n",
       "1563        1563  2004      3      DecisionTreeClassifier     NaN  0.650794\n",
       "1564        1564  2004      4      DecisionTreeClassifier     NaN  0.682540\n",
       "1565        1565  2004      5      DecisionTreeClassifier     NaN  0.634921\n",
       "1566        1566  2004      6      DecisionTreeClassifier     NaN  0.714286\n",
       "1567        1567  2004      7      DecisionTreeClassifier     NaN  0.539683\n",
       "1568        1568  2004      8      DecisionTreeClassifier     NaN  0.746032\n",
       "1569        1569  2004      9      DecisionTreeClassifier     NaN  0.666667\n",
       "1570        1570  2004     10      DecisionTreeClassifier     NaN  0.730159\n",
       "1571        1571  2004     11      DecisionTreeClassifier     NaN  0.666667\n",
       "1572        1572  2004     12      DecisionTreeClassifier     NaN  0.761905\n",
       "1573        1573  2004     13      DecisionTreeClassifier     NaN  0.698413\n",
       "1574        1574  2004     14      DecisionTreeClassifier     NaN  0.698413\n",
       "1575        1575  2005      0      DecisionTreeClassifier     NaN  0.617647\n",
       "1576        1576  2005      1      DecisionTreeClassifier     NaN  0.676471\n",
       "1577        1577  2005      2      DecisionTreeClassifier     NaN  0.661765\n",
       "1578        1578  2005      3      DecisionTreeClassifier     NaN  0.470588\n",
       "1579        1579  2005      4      DecisionTreeClassifier     NaN  0.632353\n",
       "1580        1580  2005      5      DecisionTreeClassifier     NaN  0.661765\n",
       "1581        1581  2005      6      DecisionTreeClassifier     NaN  0.632353\n",
       "1582        1582  2005      7      DecisionTreeClassifier     NaN  0.558824\n",
       "1583        1583  2005      8      DecisionTreeClassifier     NaN  0.558824\n",
       "1584        1584  2005      9      DecisionTreeClassifier     NaN  0.632353\n",
       "1585        1585  2005     10      DecisionTreeClassifier     NaN  0.632353\n",
       "1586        1586  2005     11      DecisionTreeClassifier     NaN  0.602941\n",
       "1587        1587  2005     12      DecisionTreeClassifier     NaN  0.632353\n",
       "1588        1588  2005     13      DecisionTreeClassifier     NaN  0.691176\n",
       "1589        1589  2005     14      DecisionTreeClassifier     NaN  0.661765\n",
       "1590        1590  2006      0      DecisionTreeClassifier     NaN  0.746479\n",
       "1591        1591  2006      1      DecisionTreeClassifier     NaN  0.774648\n",
       "1592        1592  2006      2      DecisionTreeClassifier     NaN  0.591549\n",
       "1593        1593  2006      3      DecisionTreeClassifier     NaN  0.647887\n",
       "1594        1594  2006      4      DecisionTreeClassifier     NaN  0.788732\n",
       "1595        1595  2006      5      DecisionTreeClassifier     NaN  0.647887\n",
       "1596        1596  2006      6      DecisionTreeClassifier     NaN  0.633803\n",
       "1597        1597  2006      7      DecisionTreeClassifier     NaN  0.746479\n",
       "1598        1598  2006      8      DecisionTreeClassifier     NaN  0.718310\n",
       "1599        1599  2006      9      DecisionTreeClassifier     NaN  0.732394\n",
       "1600        1600  2006     10      DecisionTreeClassifier     NaN  0.830986\n",
       "1601        1601  2006     11      DecisionTreeClassifier     NaN  0.676056\n",
       "1602        1602  2006     12      DecisionTreeClassifier     NaN  0.732394\n",
       "1603        1603  2006     13      DecisionTreeClassifier     NaN  0.732394\n",
       "1604        1604  2006     14      DecisionTreeClassifier     NaN  0.774648\n",
       "1605        1605  2007      0      DecisionTreeClassifier     NaN  0.582090\n",
       "1606        1606  2007      1      DecisionTreeClassifier     NaN  0.611940\n",
       "1607        1607  2007      2      DecisionTreeClassifier     NaN  0.582090\n",
       "1608        1608  2007      3      DecisionTreeClassifier     NaN  0.641791\n",
       "1609        1609  2007      4      DecisionTreeClassifier     NaN  0.597015\n",
       "1610        1610  2007      5      DecisionTreeClassifier     NaN  0.656716\n",
       "1611        1611  2007      6      DecisionTreeClassifier     NaN  0.597015\n",
       "1612        1612  2007      7      DecisionTreeClassifier     NaN  0.671642\n",
       "1613        1613  2007      8      DecisionTreeClassifier     NaN  0.746269\n",
       "1614        1614  2007      9      DecisionTreeClassifier     NaN  0.686567\n",
       "1615        1615  2007     10      DecisionTreeClassifier     NaN  0.611940\n",
       "1616        1616  2007     11      DecisionTreeClassifier     NaN  0.686567\n",
       "1617        1617  2007     12      DecisionTreeClassifier     NaN  0.656716\n",
       "1618        1618  2007     13      DecisionTreeClassifier     NaN  0.716418\n",
       "1619        1619  2007     14      DecisionTreeClassifier     NaN  0.791045\n",
       "1620        1620  2008      0      DecisionTreeClassifier     NaN  0.552239\n",
       "1621        1621  2008      1      DecisionTreeClassifier     NaN  0.611940\n",
       "1622        1622  2008      2      DecisionTreeClassifier     NaN  0.701493\n",
       "1623        1623  2008      3      DecisionTreeClassifier     NaN  0.656716\n",
       "1624        1624  2008      4      DecisionTreeClassifier     NaN  0.671642\n",
       "1625        1625  2008      5      DecisionTreeClassifier     NaN  0.582090\n",
       "1626        1626  2008      6      DecisionTreeClassifier     NaN  0.776119\n",
       "1627        1627  2008      7      DecisionTreeClassifier     NaN  0.626866\n",
       "1628        1628  2008      8      DecisionTreeClassifier     NaN  0.641791\n",
       "1629        1629  2008      9      DecisionTreeClassifier     NaN  0.626866\n",
       "1630        1630  2008     10      DecisionTreeClassifier     NaN  0.701493\n",
       "1631        1631  2008     11      DecisionTreeClassifier     NaN  0.746269\n",
       "1632        1632  2008     12      DecisionTreeClassifier     NaN  0.626866\n",
       "1633        1633  2008     13      DecisionTreeClassifier     NaN  0.716418\n",
       "1634        1634  2008     14      DecisionTreeClassifier     NaN  0.791045\n",
       "1635        1635  2009      0      DecisionTreeClassifier     NaN  0.650794\n",
       "1636        1636  2009      1      DecisionTreeClassifier     NaN  0.714286\n",
       "1637        1637  2009      2      DecisionTreeClassifier     NaN  0.682540\n",
       "1638        1638  2009      3      DecisionTreeClassifier     NaN  0.650794\n",
       "1639        1639  2009      4      DecisionTreeClassifier     NaN  0.587302\n",
       "1640        1640  2009      5      DecisionTreeClassifier     NaN  0.714286\n",
       "1641        1641  2009      6      DecisionTreeClassifier     NaN  0.698413\n",
       "1642        1642  2009      7      DecisionTreeClassifier     NaN  0.666667\n",
       "1643        1643  2009      8      DecisionTreeClassifier     NaN  0.603175\n",
       "1644        1644  2009      9      DecisionTreeClassifier     NaN  0.730159\n",
       "1645        1645  2009     10      DecisionTreeClassifier     NaN  0.603175\n",
       "1646        1646  2009     11      DecisionTreeClassifier     NaN  0.650794\n",
       "1647        1647  2009     12      DecisionTreeClassifier     NaN  0.634921\n",
       "1648        1648  2009     13      DecisionTreeClassifier     NaN  0.682540\n",
       "1649        1649  2009     14      DecisionTreeClassifier     NaN  0.634921\n",
       "1650        1650  2010      0      DecisionTreeClassifier     NaN  0.731343\n",
       "1651        1651  2010      1      DecisionTreeClassifier     NaN  0.731343\n",
       "1652        1652  2010      2      DecisionTreeClassifier     NaN  0.641791\n",
       "1653        1653  2010      3      DecisionTreeClassifier     NaN  0.671642\n",
       "1654        1654  2010      4      DecisionTreeClassifier     NaN  0.686567\n",
       "1655        1655  2010      5      DecisionTreeClassifier     NaN  0.731343\n",
       "1656        1656  2010      6      DecisionTreeClassifier     NaN  0.641791\n",
       "1657        1657  2010      7      DecisionTreeClassifier     NaN  0.701493\n",
       "1658        1658  2010      8      DecisionTreeClassifier     NaN  0.701493\n",
       "1659        1659  2010      9      DecisionTreeClassifier     NaN  0.686567\n",
       "1660        1660  2010     10      DecisionTreeClassifier     NaN  0.671642\n",
       "1661        1661  2010     11      DecisionTreeClassifier     NaN  0.686567\n",
       "1662        1662  2010     12      DecisionTreeClassifier     NaN  0.701493\n",
       "1663        1663  2010     13      DecisionTreeClassifier     NaN  0.671642\n",
       "1664        1664  2010     14      DecisionTreeClassifier     NaN  0.656716\n",
       "1665        1665  2011      0      DecisionTreeClassifier     NaN  0.552239\n",
       "1666        1666  2011      1      DecisionTreeClassifier     NaN  0.522388\n",
       "1667        1667  2011      2      DecisionTreeClassifier     NaN  0.716418\n",
       "1668        1668  2011      3      DecisionTreeClassifier     NaN  0.567164\n",
       "1669        1669  2011      4      DecisionTreeClassifier     NaN  0.626866\n",
       "1670        1670  2011      5      DecisionTreeClassifier     NaN  0.611940\n",
       "1671        1671  2011      6      DecisionTreeClassifier     NaN  0.686567\n",
       "1672        1672  2011      7      DecisionTreeClassifier     NaN  0.656716\n",
       "1673        1673  2011      8      DecisionTreeClassifier     NaN  0.582090\n",
       "1674        1674  2011      9      DecisionTreeClassifier     NaN  0.507463\n",
       "1675        1675  2011     10      DecisionTreeClassifier     NaN  0.671642\n",
       "1676        1676  2011     11      DecisionTreeClassifier     NaN  0.686567\n",
       "1677        1677  2011     12      DecisionTreeClassifier     NaN  0.611940\n",
       "1678        1678  2011     13      DecisionTreeClassifier     NaN  0.671642\n",
       "1679        1679  2011     14      DecisionTreeClassifier     NaN  0.641791\n",
       "1680        1680  2012      0      DecisionTreeClassifier     NaN  0.521127\n",
       "1681        1681  2012      1      DecisionTreeClassifier     NaN  0.661972\n",
       "1682        1682  2012      2      DecisionTreeClassifier     NaN  0.577465\n",
       "1683        1683  2012      3      DecisionTreeClassifier     NaN  0.690141\n",
       "1684        1684  2012      4      DecisionTreeClassifier     NaN  0.647887\n",
       "1685        1685  2012      5      DecisionTreeClassifier     NaN  0.633803\n",
       "1686        1686  2012      6      DecisionTreeClassifier     NaN  0.690141\n",
       "1687        1687  2012      7      DecisionTreeClassifier     NaN  0.676056\n",
       "1688        1688  2012      8      DecisionTreeClassifier     NaN  0.577465\n",
       "1689        1689  2012      9      DecisionTreeClassifier     NaN  0.676056\n",
       "1690        1690  2012     10      DecisionTreeClassifier     NaN  0.647887\n",
       "1691        1691  2012     11      DecisionTreeClassifier     NaN  0.661972\n",
       "1692        1692  2012     12      DecisionTreeClassifier     NaN  0.690141\n",
       "1693        1693  2012     13      DecisionTreeClassifier     NaN  0.676056\n",
       "1694        1694  2012     14      DecisionTreeClassifier     NaN  0.661972\n",
       "1695        1695  2013      0      DecisionTreeClassifier     NaN  0.507463\n",
       "1696        1696  2013      1      DecisionTreeClassifier     NaN  0.611940\n",
       "1697        1697  2013      2      DecisionTreeClassifier     NaN  0.552239\n",
       "1698        1698  2013      3      DecisionTreeClassifier     NaN  0.597015\n",
       "1699        1699  2013      4      DecisionTreeClassifier     NaN  0.626866\n",
       "1700        1700  2013      5      DecisionTreeClassifier     NaN  0.582090\n",
       "1701        1701  2013      6      DecisionTreeClassifier     NaN  0.716418\n",
       "1702        1702  2013      7      DecisionTreeClassifier     NaN  0.552239\n",
       "1703        1703  2013      8      DecisionTreeClassifier     NaN  0.567164\n",
       "1704        1704  2013      9      DecisionTreeClassifier     NaN  0.597015\n",
       "1705        1705  2013     10      DecisionTreeClassifier     NaN  0.567164\n",
       "1706        1706  2013     11      DecisionTreeClassifier     NaN  0.656716\n",
       "1707        1707  2013     12      DecisionTreeClassifier     NaN  0.597015\n",
       "1708        1708  2013     13      DecisionTreeClassifier     NaN  0.641791\n",
       "1709        1709  2013     14      DecisionTreeClassifier     NaN  0.686567\n",
       "1710        1710  2014      0      DecisionTreeClassifier     NaN  0.641791\n",
       "1711        1711  2014      1      DecisionTreeClassifier     NaN  0.611940\n",
       "1712        1712  2014      2      DecisionTreeClassifier     NaN  0.701493\n",
       "1713        1713  2014      3      DecisionTreeClassifier     NaN  0.671642\n",
       "1714        1714  2014      4      DecisionTreeClassifier     NaN  0.641791\n",
       "1715        1715  2014      5      DecisionTreeClassifier     NaN  0.776119\n",
       "1716        1716  2014      6      DecisionTreeClassifier     NaN  0.776119\n",
       "1717        1717  2014      7      DecisionTreeClassifier     NaN  0.656716\n",
       "1718        1718  2014      8      DecisionTreeClassifier     NaN  0.671642\n",
       "1719        1719  2014      9      DecisionTreeClassifier     NaN  0.686567\n",
       "1720        1720  2014     10      DecisionTreeClassifier     NaN  0.731343\n",
       "1721        1721  2014     11      DecisionTreeClassifier     NaN  0.761194\n",
       "1722        1722  2014     12      DecisionTreeClassifier     NaN  0.671642\n",
       "1723        1723  2014     13      DecisionTreeClassifier     NaN  0.776119\n",
       "1724        1724  2014     14      DecisionTreeClassifier     NaN  0.776119\n",
       "1725        1725  2015      0      DecisionTreeClassifier     NaN  0.628571\n",
       "1726        1726  2015      1      DecisionTreeClassifier     NaN  0.685714\n",
       "1727        1727  2015      2      DecisionTreeClassifier     NaN  0.628571\n",
       "1728        1728  2015      3      DecisionTreeClassifier     NaN  0.671429\n",
       "1729        1729  2015      4      DecisionTreeClassifier     NaN  0.671429\n",
       "1730        1730  2015      5      DecisionTreeClassifier     NaN  0.671429\n",
       "1731        1731  2015      6      DecisionTreeClassifier     NaN  0.700000\n",
       "1732        1732  2015      7      DecisionTreeClassifier     NaN  0.642857\n",
       "1733        1733  2015      8      DecisionTreeClassifier     NaN  0.671429\n",
       "1734        1734  2015      9      DecisionTreeClassifier     NaN  0.700000\n",
       "1735        1735  2015     10      DecisionTreeClassifier     NaN  0.685714\n",
       "1736        1736  2015     11      DecisionTreeClassifier     NaN  0.642857\n",
       "1737        1737  2015     12      DecisionTreeClassifier     NaN  0.671429\n",
       "1738        1738  2015     13      DecisionTreeClassifier     NaN  0.728571\n",
       "1739        1739  2015     14      DecisionTreeClassifier     NaN  0.714286\n",
       "1740        1740  2016      0      DecisionTreeClassifier     NaN  0.641791\n",
       "1741        1741  2016      1      DecisionTreeClassifier     NaN  0.746269\n",
       "1742        1742  2016      2      DecisionTreeClassifier     NaN  0.641791\n",
       "1743        1743  2016      3      DecisionTreeClassifier     NaN  0.611940\n",
       "1744        1744  2016      4      DecisionTreeClassifier     NaN  0.761194\n",
       "1745        1745  2016      5      DecisionTreeClassifier     NaN  0.686567\n",
       "1746        1746  2016      6      DecisionTreeClassifier     NaN  0.611940\n",
       "1747        1747  2016      7      DecisionTreeClassifier     NaN  0.701493\n",
       "1748        1748  2016      8      DecisionTreeClassifier     NaN  0.671642\n",
       "1749        1749  2016      9      DecisionTreeClassifier     NaN  0.716418\n",
       "1750        1750  2016     10      DecisionTreeClassifier     NaN  0.746269\n",
       "1751        1751  2016     11      DecisionTreeClassifier     NaN  0.671642\n",
       "1752        1752  2016     12      DecisionTreeClassifier     NaN  0.716418\n",
       "1753        1753  2016     13      DecisionTreeClassifier     NaN  0.671642\n",
       "1754        1754  2016     14      DecisionTreeClassifier     NaN  0.701493\n",
       "1755        1755  2017      0      DecisionTreeClassifier     NaN  0.671642\n",
       "1756        1756  2017      1      DecisionTreeClassifier     NaN  0.701493\n",
       "1757        1757  2017      2      DecisionTreeClassifier     NaN  0.701493\n",
       "1758        1758  2017      3      DecisionTreeClassifier     NaN  0.641791\n",
       "1759        1759  2017      4      DecisionTreeClassifier     NaN  0.656716\n",
       "1760        1760  2017      5      DecisionTreeClassifier     NaN  0.701493\n",
       "1761        1761  2017      6      DecisionTreeClassifier     NaN  0.701493\n",
       "1762        1762  2017      7      DecisionTreeClassifier     NaN  0.731343\n",
       "1763        1763  2017      8      DecisionTreeClassifier     NaN  0.761194\n",
       "1764        1764  2017      9      DecisionTreeClassifier     NaN  0.731343\n",
       "1765        1765  2017     10      DecisionTreeClassifier     NaN  0.776119\n",
       "1766        1766  2017     11      DecisionTreeClassifier     NaN  0.776119\n",
       "1767        1767  2017     12      DecisionTreeClassifier     NaN  0.746269\n",
       "1768        1768  2017     13      DecisionTreeClassifier     NaN  0.746269\n",
       "1769        1769  2017     14      DecisionTreeClassifier     NaN  0.731343\n",
       "1770        1770  2018      0      DecisionTreeClassifier     NaN  0.537313\n",
       "1771        1771  2018      1      DecisionTreeClassifier     NaN  0.641791\n",
       "1772        1772  2018      2      DecisionTreeClassifier     NaN  0.477612\n",
       "1773        1773  2018      3      DecisionTreeClassifier     NaN  0.537313\n",
       "1774        1774  2018      4      DecisionTreeClassifier     NaN  0.641791\n",
       "1775        1775  2018      5      DecisionTreeClassifier     NaN  0.656716\n",
       "1776        1776  2018      6      DecisionTreeClassifier     NaN  0.626866\n",
       "1777        1777  2018      7      DecisionTreeClassifier     NaN  0.567164\n",
       "1778        1778  2018      8      DecisionTreeClassifier     NaN  0.597015\n",
       "1779        1779  2018      9      DecisionTreeClassifier     NaN  0.626866\n",
       "1780        1780  2018     10      DecisionTreeClassifier     NaN  0.641791\n",
       "1781        1781  2018     11      DecisionTreeClassifier     NaN  0.567164\n",
       "1782        1782  2018     12      DecisionTreeClassifier     NaN  0.656716\n",
       "1783        1783  2018     13      DecisionTreeClassifier     NaN  0.686567\n",
       "1784        1784  2018     14      DecisionTreeClassifier     NaN  0.686567\n",
       "1785        1785  2019      0      DecisionTreeClassifier     NaN  0.597015\n",
       "1786        1786  2019      1      DecisionTreeClassifier     NaN  0.686567\n",
       "1787        1787  2019      2      DecisionTreeClassifier     NaN  0.597015\n",
       "1788        1788  2019      3      DecisionTreeClassifier     NaN  0.701493\n",
       "1789        1789  2019      4      DecisionTreeClassifier     NaN  0.671642\n",
       "1790        1790  2019      5      DecisionTreeClassifier     NaN  0.656716\n",
       "1791        1791  2019      6      DecisionTreeClassifier     NaN  0.716418\n",
       "1792        1792  2019      7      DecisionTreeClassifier     NaN  0.686567\n",
       "1793        1793  2019      8      DecisionTreeClassifier     NaN  0.731343\n",
       "1794        1794  2019      9      DecisionTreeClassifier     NaN  0.686567\n",
       "1795        1795  2019     10      DecisionTreeClassifier     NaN  0.671642\n",
       "1796        1796  2019     11      DecisionTreeClassifier     NaN  0.731343\n",
       "1797        1797  2019     12      DecisionTreeClassifier     NaN  0.791045\n",
       "1798        1798  2019     13      DecisionTreeClassifier     NaN  0.701493\n",
       "1799        1799  2019     14      DecisionTreeClassifier     NaN  0.761194\n",
       "1800        1800  2000      0        NaiveBayesClassifier     NaN  0.634921\n",
       "1801        1801  2000      1        NaiveBayesClassifier     NaN  0.634921\n",
       "1802        1802  2000      2        NaiveBayesClassifier     NaN  0.603175\n",
       "1803        1803  2000      3        NaiveBayesClassifier     NaN  0.666667\n",
       "1804        1804  2000      4        NaiveBayesClassifier     NaN  0.619048\n",
       "1805        1805  2000      5        NaiveBayesClassifier     NaN  0.619048\n",
       "1806        1806  2000      6        NaiveBayesClassifier     NaN  0.634921\n",
       "1807        1807  2000      7        NaiveBayesClassifier     NaN  0.587302\n",
       "1808        1808  2000      8        NaiveBayesClassifier     NaN  0.634921\n",
       "1809        1809  2000      9        NaiveBayesClassifier     NaN  0.666667\n",
       "1810        1810  2000     10        NaiveBayesClassifier     NaN  0.666667\n",
       "1811        1811  2000     11        NaiveBayesClassifier     NaN  0.793651\n",
       "1812        1812  2000     12        NaiveBayesClassifier     NaN  0.793651\n",
       "1813        1813  2000     13        NaiveBayesClassifier     NaN  0.714286\n",
       "1814        1814  2000     14        NaiveBayesClassifier     NaN  0.730159\n",
       "1815        1815  2001      0        NaiveBayesClassifier     NaN  0.633333\n",
       "1816        1816  2001      1        NaiveBayesClassifier     NaN  0.666667\n",
       "1817        1817  2001      2        NaiveBayesClassifier     NaN  0.550000\n",
       "1818        1818  2001      3        NaiveBayesClassifier     NaN  0.650000\n",
       "1819        1819  2001      4        NaiveBayesClassifier     NaN  0.666667\n",
       "1820        1820  2001      5        NaiveBayesClassifier     NaN  0.666667\n",
       "1821        1821  2001      6        NaiveBayesClassifier     NaN  0.716667\n",
       "1822        1822  2001      7        NaiveBayesClassifier     NaN  0.683333\n",
       "1823        1823  2001      8        NaiveBayesClassifier     NaN  0.650000\n",
       "1824        1824  2001      9        NaiveBayesClassifier     NaN  0.700000\n",
       "1825        1825  2001     10        NaiveBayesClassifier     NaN  0.783333\n",
       "1826        1826  2001     11        NaiveBayesClassifier     NaN  0.766667\n",
       "1827        1827  2001     12        NaiveBayesClassifier     NaN  0.733333\n",
       "1828        1828  2001     13        NaiveBayesClassifier     NaN  0.750000\n",
       "1829        1829  2001     14        NaiveBayesClassifier     NaN  0.766667\n",
       "1830        1830  2002      0        NaiveBayesClassifier     NaN  0.690141\n",
       "1831        1831  2002      1        NaiveBayesClassifier     NaN  0.619718\n",
       "1832        1832  2002      2        NaiveBayesClassifier     NaN  0.563380\n",
       "1833        1833  2002      3        NaiveBayesClassifier     NaN  0.605634\n",
       "1834        1834  2002      4        NaiveBayesClassifier     NaN  0.676056\n",
       "1835        1835  2002      5        NaiveBayesClassifier     NaN  0.605634\n",
       "1836        1836  2002      6        NaiveBayesClassifier     NaN  0.676056\n",
       "1837        1837  2002      7        NaiveBayesClassifier     NaN  0.676056\n",
       "1838        1838  2002      8        NaiveBayesClassifier     NaN  0.676056\n",
       "1839        1839  2002      9        NaiveBayesClassifier     NaN  0.605634\n",
       "1840        1840  2002     10        NaiveBayesClassifier     NaN  0.676056\n",
       "1841        1841  2002     11        NaiveBayesClassifier     NaN  0.718310\n",
       "1842        1842  2002     12        NaiveBayesClassifier     NaN  0.718310\n",
       "1843        1843  2002     13        NaiveBayesClassifier     NaN  0.661972\n",
       "1844        1844  2002     14        NaiveBayesClassifier     NaN  0.774648\n",
       "1845        1845  2003      0        NaiveBayesClassifier     NaN  0.656716\n",
       "1846        1846  2003      1        NaiveBayesClassifier     NaN  0.671642\n",
       "1847        1847  2003      2        NaiveBayesClassifier     NaN  0.641791\n",
       "1848        1848  2003      3        NaiveBayesClassifier     NaN  0.582090\n",
       "1849        1849  2003      4        NaiveBayesClassifier     NaN  0.761194\n",
       "1850        1850  2003      5        NaiveBayesClassifier     NaN  0.626866\n",
       "1851        1851  2003      6        NaiveBayesClassifier     NaN  0.686567\n",
       "1852        1852  2003      7        NaiveBayesClassifier     NaN  0.716418\n",
       "1853        1853  2003      8        NaiveBayesClassifier     NaN  0.701493\n",
       "1854        1854  2003      9        NaiveBayesClassifier     NaN  0.656716\n",
       "1855        1855  2003     10        NaiveBayesClassifier     NaN  0.731343\n",
       "1856        1856  2003     11        NaiveBayesClassifier     NaN  0.776119\n",
       "1857        1857  2003     12        NaiveBayesClassifier     NaN  0.776119\n",
       "1858        1858  2003     13        NaiveBayesClassifier     NaN  0.716418\n",
       "1859        1859  2003     14        NaiveBayesClassifier     NaN  0.835821\n",
       "1860        1860  2004      0        NaiveBayesClassifier     NaN  0.619048\n",
       "1861        1861  2004      1        NaiveBayesClassifier     NaN  0.539683\n",
       "1862        1862  2004      2        NaiveBayesClassifier     NaN  0.539683\n",
       "1863        1863  2004      3        NaiveBayesClassifier     NaN  0.650794\n",
       "1864        1864  2004      4        NaiveBayesClassifier     NaN  0.714286\n",
       "1865        1865  2004      5        NaiveBayesClassifier     NaN  0.650794\n",
       "1866        1866  2004      6        NaiveBayesClassifier     NaN  0.650794\n",
       "1867        1867  2004      7        NaiveBayesClassifier     NaN  0.746032\n",
       "1868        1868  2004      8        NaiveBayesClassifier     NaN  0.682540\n",
       "1869        1869  2004      9        NaiveBayesClassifier     NaN  0.698413\n",
       "1870        1870  2004     10        NaiveBayesClassifier     NaN  0.761905\n",
       "1871        1871  2004     11        NaiveBayesClassifier     NaN  0.793651\n",
       "1872        1872  2004     12        NaiveBayesClassifier     NaN  0.761905\n",
       "1873        1873  2004     13        NaiveBayesClassifier     NaN  0.698413\n",
       "1874        1874  2004     14        NaiveBayesClassifier     NaN  0.841270\n",
       "1875        1875  2005      0        NaiveBayesClassifier     NaN  0.617647\n",
       "1876        1876  2005      1        NaiveBayesClassifier     NaN  0.676471\n",
       "1877        1877  2005      2        NaiveBayesClassifier     NaN  0.661765\n",
       "1878        1878  2005      3        NaiveBayesClassifier     NaN  0.470588\n",
       "1879        1879  2005      4        NaiveBayesClassifier     NaN  0.720588\n",
       "1880        1880  2005      5        NaiveBayesClassifier     NaN  0.676471\n",
       "1881        1881  2005      6        NaiveBayesClassifier     NaN  0.661765\n",
       "1882        1882  2005      7        NaiveBayesClassifier     NaN  0.661765\n",
       "1883        1883  2005      8        NaiveBayesClassifier     NaN  0.632353\n",
       "1884        1884  2005      9        NaiveBayesClassifier     NaN  0.647059\n",
       "1885        1885  2005     10        NaiveBayesClassifier     NaN  0.691176\n",
       "1886        1886  2005     11        NaiveBayesClassifier     NaN  0.588235\n",
       "1887        1887  2005     12        NaiveBayesClassifier     NaN  0.676471\n",
       "1888        1888  2005     13        NaiveBayesClassifier     NaN  0.691176\n",
       "1889        1889  2005     14        NaiveBayesClassifier     NaN  0.720588\n",
       "1890        1890  2006      0        NaiveBayesClassifier     NaN  0.746479\n",
       "1891        1891  2006      1        NaiveBayesClassifier     NaN  0.774648\n",
       "1892        1892  2006      2        NaiveBayesClassifier     NaN  0.591549\n",
       "1893        1893  2006      3        NaiveBayesClassifier     NaN  0.647887\n",
       "1894        1894  2006      4        NaiveBayesClassifier     NaN  0.816901\n",
       "1895        1895  2006      5        NaiveBayesClassifier     NaN  0.676056\n",
       "1896        1896  2006      6        NaiveBayesClassifier     NaN  0.619718\n",
       "1897        1897  2006      7        NaiveBayesClassifier     NaN  0.676056\n",
       "1898        1898  2006      8        NaiveBayesClassifier     NaN  0.690141\n",
       "1899        1899  2006      9        NaiveBayesClassifier     NaN  0.732394\n",
       "1900        1900  2006     10        NaiveBayesClassifier     NaN  0.732394\n",
       "1901        1901  2006     11        NaiveBayesClassifier     NaN  0.690141\n",
       "1902        1902  2006     12        NaiveBayesClassifier     NaN  0.788732\n",
       "1903        1903  2006     13        NaiveBayesClassifier     NaN  0.760563\n",
       "1904        1904  2006     14        NaiveBayesClassifier     NaN  0.830986\n",
       "1905        1905  2007      0        NaiveBayesClassifier     NaN  0.582090\n",
       "1906        1906  2007      1        NaiveBayesClassifier     NaN  0.611940\n",
       "1907        1907  2007      2        NaiveBayesClassifier     NaN  0.582090\n",
       "1908        1908  2007      3        NaiveBayesClassifier     NaN  0.641791\n",
       "1909        1909  2007      4        NaiveBayesClassifier     NaN  0.626866\n",
       "1910        1910  2007      5        NaiveBayesClassifier     NaN  0.701493\n",
       "1911        1911  2007      6        NaiveBayesClassifier     NaN  0.656716\n",
       "1912        1912  2007      7        NaiveBayesClassifier     NaN  0.671642\n",
       "1913        1913  2007      8        NaiveBayesClassifier     NaN  0.731343\n",
       "1914        1914  2007      9        NaiveBayesClassifier     NaN  0.731343\n",
       "1915        1915  2007     10        NaiveBayesClassifier     NaN  0.671642\n",
       "1916        1916  2007     11        NaiveBayesClassifier     NaN  0.641791\n",
       "1917        1917  2007     12        NaiveBayesClassifier     NaN  0.776119\n",
       "1918        1918  2007     13        NaiveBayesClassifier     NaN  0.761194\n",
       "1919        1919  2007     14        NaiveBayesClassifier     NaN  0.850746\n",
       "1920        1920  2008      0        NaiveBayesClassifier     NaN  0.552239\n",
       "1921        1921  2008      1        NaiveBayesClassifier     NaN  0.611940\n",
       "1922        1922  2008      2        NaiveBayesClassifier     NaN  0.701493\n",
       "1923        1923  2008      3        NaiveBayesClassifier     NaN  0.656716\n",
       "1924        1924  2008      4        NaiveBayesClassifier     NaN  0.671642\n",
       "1925        1925  2008      5        NaiveBayesClassifier     NaN  0.686567\n",
       "1926        1926  2008      6        NaiveBayesClassifier     NaN  0.761194\n",
       "1927        1927  2008      7        NaiveBayesClassifier     NaN  0.701493\n",
       "1928        1928  2008      8        NaiveBayesClassifier     NaN  0.701493\n",
       "1929        1929  2008      9        NaiveBayesClassifier     NaN  0.701493\n",
       "1930        1930  2008     10        NaiveBayesClassifier     NaN  0.776119\n",
       "1931        1931  2008     11        NaiveBayesClassifier     NaN  0.746269\n",
       "1932        1932  2008     12        NaiveBayesClassifier     NaN  0.716418\n",
       "1933        1933  2008     13        NaiveBayesClassifier     NaN  0.776119\n",
       "1934        1934  2008     14        NaiveBayesClassifier     NaN  0.776119\n",
       "1935        1935  2009      0        NaiveBayesClassifier     NaN  0.650794\n",
       "1936        1936  2009      1        NaiveBayesClassifier     NaN  0.714286\n",
       "1937        1937  2009      2        NaiveBayesClassifier     NaN  0.682540\n",
       "1938        1938  2009      3        NaiveBayesClassifier     NaN  0.698413\n",
       "1939        1939  2009      4        NaiveBayesClassifier     NaN  0.698413\n",
       "1940        1940  2009      5        NaiveBayesClassifier     NaN  0.761905\n",
       "1941        1941  2009      6        NaiveBayesClassifier     NaN  0.746032\n",
       "1942        1942  2009      7        NaiveBayesClassifier     NaN  0.634921\n",
       "1943        1943  2009      8        NaiveBayesClassifier     NaN  0.682540\n",
       "1944        1944  2009      9        NaiveBayesClassifier     NaN  0.777778\n",
       "1945        1945  2009     10        NaiveBayesClassifier     NaN  0.777778\n",
       "1946        1946  2009     11        NaiveBayesClassifier     NaN  0.730159\n",
       "1947        1947  2009     12        NaiveBayesClassifier     NaN  0.793651\n",
       "1948        1948  2009     13        NaiveBayesClassifier     NaN  0.841270\n",
       "1949        1949  2009     14        NaiveBayesClassifier     NaN  0.857143\n",
       "1950        1950  2010      0        NaiveBayesClassifier     NaN  0.731343\n",
       "1951        1951  2010      1        NaiveBayesClassifier     NaN  0.731343\n",
       "1952        1952  2010      2        NaiveBayesClassifier     NaN  0.641791\n",
       "1953        1953  2010      3        NaiveBayesClassifier     NaN  0.671642\n",
       "1954        1954  2010      4        NaiveBayesClassifier     NaN  0.746269\n",
       "1955        1955  2010      5        NaiveBayesClassifier     NaN  0.731343\n",
       "1956        1956  2010      6        NaiveBayesClassifier     NaN  0.701493\n",
       "1957        1957  2010      7        NaiveBayesClassifier     NaN  0.686567\n",
       "1958        1958  2010      8        NaiveBayesClassifier     NaN  0.716418\n",
       "1959        1959  2010      9        NaiveBayesClassifier     NaN  0.716418\n",
       "1960        1960  2010     10        NaiveBayesClassifier     NaN  0.835821\n",
       "1961        1961  2010     11        NaiveBayesClassifier     NaN  0.746269\n",
       "1962        1962  2010     12        NaiveBayesClassifier     NaN  0.746269\n",
       "1963        1963  2010     13        NaiveBayesClassifier     NaN  0.716418\n",
       "1964        1964  2010     14        NaiveBayesClassifier     NaN  0.776119\n",
       "1965        1965  2011      0        NaiveBayesClassifier     NaN  0.552239\n",
       "1966        1966  2011      1        NaiveBayesClassifier     NaN  0.522388\n",
       "1967        1967  2011      2        NaiveBayesClassifier     NaN  0.716418\n",
       "1968        1968  2011      3        NaiveBayesClassifier     NaN  0.567164\n",
       "1969        1969  2011      4        NaiveBayesClassifier     NaN  0.626866\n",
       "1970        1970  2011      5        NaiveBayesClassifier     NaN  0.641791\n",
       "1971        1971  2011      6        NaiveBayesClassifier     NaN  0.716418\n",
       "1972        1972  2011      7        NaiveBayesClassifier     NaN  0.671642\n",
       "1973        1973  2011      8        NaiveBayesClassifier     NaN  0.671642\n",
       "1974        1974  2011      9        NaiveBayesClassifier     NaN  0.597015\n",
       "1975        1975  2011     10        NaiveBayesClassifier     NaN  0.671642\n",
       "1976        1976  2011     11        NaiveBayesClassifier     NaN  0.746269\n",
       "1977        1977  2011     12        NaiveBayesClassifier     NaN  0.641791\n",
       "1978        1978  2011     13        NaiveBayesClassifier     NaN  0.656716\n",
       "1979        1979  2011     14        NaiveBayesClassifier     NaN  0.731343\n",
       "1980        1980  2012      0        NaiveBayesClassifier     NaN  0.521127\n",
       "1981        1981  2012      1        NaiveBayesClassifier     NaN  0.661972\n",
       "1982        1982  2012      2        NaiveBayesClassifier     NaN  0.577465\n",
       "1983        1983  2012      3        NaiveBayesClassifier     NaN  0.690141\n",
       "1984        1984  2012      4        NaiveBayesClassifier     NaN  0.647887\n",
       "1985        1985  2012      5        NaiveBayesClassifier     NaN  0.704225\n",
       "1986        1986  2012      6        NaiveBayesClassifier     NaN  0.661972\n",
       "1987        1987  2012      7        NaiveBayesClassifier     NaN  0.661972\n",
       "1988        1988  2012      8        NaiveBayesClassifier     NaN  0.577465\n",
       "1989        1989  2012      9        NaiveBayesClassifier     NaN  0.690141\n",
       "1990        1990  2012     10        NaiveBayesClassifier     NaN  0.647887\n",
       "1991        1991  2012     11        NaiveBayesClassifier     NaN  0.676056\n",
       "1992        1992  2012     12        NaiveBayesClassifier     NaN  0.746479\n",
       "1993        1993  2012     13        NaiveBayesClassifier     NaN  0.704225\n",
       "1994        1994  2012     14        NaiveBayesClassifier     NaN  0.732394\n",
       "1995        1995  2013      0        NaiveBayesClassifier     NaN  0.507463\n",
       "1996        1996  2013      1        NaiveBayesClassifier     NaN  0.611940\n",
       "1997        1997  2013      2        NaiveBayesClassifier     NaN  0.552239\n",
       "1998        1998  2013      3        NaiveBayesClassifier     NaN  0.597015\n",
       "1999        1999  2013      4        NaiveBayesClassifier     NaN  0.641791\n",
       "2000        2000  2013      5        NaiveBayesClassifier     NaN  0.671642\n",
       "2001        2001  2013      6        NaiveBayesClassifier     NaN  0.716418\n",
       "2002        2002  2013      7        NaiveBayesClassifier     NaN  0.626866\n",
       "2003        2003  2013      8        NaiveBayesClassifier     NaN  0.656716\n",
       "2004        2004  2013      9        NaiveBayesClassifier     NaN  0.656716\n",
       "2005        2005  2013     10        NaiveBayesClassifier     NaN  0.671642\n",
       "2006        2006  2013     11        NaiveBayesClassifier     NaN  0.746269\n",
       "2007        2007  2013     12        NaiveBayesClassifier     NaN  0.686567\n",
       "2008        2008  2013     13        NaiveBayesClassifier     NaN  0.686567\n",
       "2009        2009  2013     14        NaiveBayesClassifier     NaN  0.731343\n",
       "2010        2010  2014      0        NaiveBayesClassifier     NaN  0.641791\n",
       "2011        2011  2014      1        NaiveBayesClassifier     NaN  0.611940\n",
       "2012        2012  2014      2        NaiveBayesClassifier     NaN  0.701493\n",
       "2013        2013  2014      3        NaiveBayesClassifier     NaN  0.671642\n",
       "2014        2014  2014      4        NaiveBayesClassifier     NaN  0.641791\n",
       "2015        2015  2014      5        NaiveBayesClassifier     NaN  0.746269\n",
       "2016        2016  2014      6        NaiveBayesClassifier     NaN  0.761194\n",
       "2017        2017  2014      7        NaiveBayesClassifier     NaN  0.716418\n",
       "2018        2018  2014      8        NaiveBayesClassifier     NaN  0.701493\n",
       "2019        2019  2014      9        NaiveBayesClassifier     NaN  0.701493\n",
       "2020        2020  2014     10        NaiveBayesClassifier     NaN  0.791045\n",
       "2021        2021  2014     11        NaiveBayesClassifier     NaN  0.835821\n",
       "2022        2022  2014     12        NaiveBayesClassifier     NaN  0.701493\n",
       "2023        2023  2014     13        NaiveBayesClassifier     NaN  0.805970\n",
       "2024        2024  2014     14        NaiveBayesClassifier     NaN  0.880597\n",
       "2025        2025  2015      0        NaiveBayesClassifier     NaN  0.628571\n",
       "2026        2026  2015      1        NaiveBayesClassifier     NaN  0.685714\n",
       "2027        2027  2015      2        NaiveBayesClassifier     NaN  0.614286\n",
       "2028        2028  2015      3        NaiveBayesClassifier     NaN  0.671429\n",
       "2029        2029  2015      4        NaiveBayesClassifier     NaN  0.714286\n",
       "2030        2030  2015      5        NaiveBayesClassifier     NaN  0.685714\n",
       "2031        2031  2015      6        NaiveBayesClassifier     NaN  0.642857\n",
       "2032        2032  2015      7        NaiveBayesClassifier     NaN  0.657143\n",
       "2033        2033  2015      8        NaiveBayesClassifier     NaN  0.728571\n",
       "2034        2034  2015      9        NaiveBayesClassifier     NaN  0.728571\n",
       "2035        2035  2015     10        NaiveBayesClassifier     NaN  0.728571\n",
       "2036        2036  2015     11        NaiveBayesClassifier     NaN  0.742857\n",
       "2037        2037  2015     12        NaiveBayesClassifier     NaN  0.757143\n",
       "2038        2038  2015     13        NaiveBayesClassifier     NaN  0.728571\n",
       "2039        2039  2015     14        NaiveBayesClassifier     NaN  0.828571\n",
       "2040        2040  2016      0        NaiveBayesClassifier     NaN  0.641791\n",
       "2041        2041  2016      1        NaiveBayesClassifier     NaN  0.746269\n",
       "2042        2042  2016      2        NaiveBayesClassifier     NaN  0.641791\n",
       "2043        2043  2016      3        NaiveBayesClassifier     NaN  0.611940\n",
       "2044        2044  2016      4        NaiveBayesClassifier     NaN  0.761194\n",
       "2045        2045  2016      5        NaiveBayesClassifier     NaN  0.746269\n",
       "2046        2046  2016      6        NaiveBayesClassifier     NaN  0.626866\n",
       "2047        2047  2016      7        NaiveBayesClassifier     NaN  0.701493\n",
       "2048        2048  2016      8        NaiveBayesClassifier     NaN  0.701493\n",
       "2049        2049  2016      9        NaiveBayesClassifier     NaN  0.746269\n",
       "2050        2050  2016     10        NaiveBayesClassifier     NaN  0.805970\n",
       "2051        2051  2016     11        NaiveBayesClassifier     NaN  0.716418\n",
       "2052        2052  2016     12        NaiveBayesClassifier     NaN  0.805970\n",
       "2053        2053  2016     13        NaiveBayesClassifier     NaN  0.761194\n",
       "2054        2054  2016     14        NaiveBayesClassifier     NaN  0.820896\n",
       "2055        2055  2017      0        NaiveBayesClassifier     NaN  0.671642\n",
       "2056        2056  2017      1        NaiveBayesClassifier     NaN  0.701493\n",
       "2057        2057  2017      2        NaiveBayesClassifier     NaN  0.701493\n",
       "2058        2058  2017      3        NaiveBayesClassifier     NaN  0.641791\n",
       "2059        2059  2017      4        NaiveBayesClassifier     NaN  0.656716\n",
       "2060        2060  2017      5        NaiveBayesClassifier     NaN  0.686567\n",
       "2061        2061  2017      6        NaiveBayesClassifier     NaN  0.701493\n",
       "2062        2062  2017      7        NaiveBayesClassifier     NaN  0.716418\n",
       "2063        2063  2017      8        NaiveBayesClassifier     NaN  0.716418\n",
       "2064        2064  2017      9        NaiveBayesClassifier     NaN  0.731343\n",
       "2065        2065  2017     10        NaiveBayesClassifier     NaN  0.731343\n",
       "2066        2066  2017     11        NaiveBayesClassifier     NaN  0.805970\n",
       "2067        2067  2017     12        NaiveBayesClassifier     NaN  0.791045\n",
       "2068        2068  2017     13        NaiveBayesClassifier     NaN  0.805970\n",
       "2069        2069  2017     14        NaiveBayesClassifier     NaN  0.820896\n",
       "2070        2070  2018      0        NaiveBayesClassifier     NaN  0.537313\n",
       "2071        2071  2018      1        NaiveBayesClassifier     NaN  0.641791\n",
       "2072        2072  2018      2        NaiveBayesClassifier     NaN  0.477612\n",
       "2073        2073  2018      3        NaiveBayesClassifier     NaN  0.537313\n",
       "2074        2074  2018      4        NaiveBayesClassifier     NaN  0.626866\n",
       "2075        2075  2018      5        NaiveBayesClassifier     NaN  0.671642\n",
       "2076        2076  2018      6        NaiveBayesClassifier     NaN  0.552239\n",
       "2077        2077  2018      7        NaiveBayesClassifier     NaN  0.552239\n",
       "2078        2078  2018      8        NaiveBayesClassifier     NaN  0.582090\n",
       "2079        2079  2018      9        NaiveBayesClassifier     NaN  0.656716\n",
       "2080        2080  2018     10        NaiveBayesClassifier     NaN  0.641791\n",
       "2081        2081  2018     11        NaiveBayesClassifier     NaN  0.582090\n",
       "2082        2082  2018     12        NaiveBayesClassifier     NaN  0.671642\n",
       "2083        2083  2018     13        NaiveBayesClassifier     NaN  0.701493\n",
       "2084        2084  2018     14        NaiveBayesClassifier     NaN  0.671642\n",
       "2085        2085  2019      0        NaiveBayesClassifier     NaN  0.597015\n",
       "2086        2086  2019      1        NaiveBayesClassifier     NaN  0.686567\n",
       "2087        2087  2019      2        NaiveBayesClassifier     NaN  0.597015\n",
       "2088        2088  2019      3        NaiveBayesClassifier     NaN  0.701493\n",
       "2089        2089  2019      4        NaiveBayesClassifier     NaN  0.701493\n",
       "2090        2090  2019      5        NaiveBayesClassifier     NaN  0.701493\n",
       "2091        2091  2019      6        NaiveBayesClassifier     NaN  0.731343\n",
       "2092        2092  2019      7        NaiveBayesClassifier     NaN  0.701493\n",
       "2093        2093  2019      8        NaiveBayesClassifier     NaN  0.731343\n",
       "2094        2094  2019      9        NaiveBayesClassifier     NaN  0.761194\n",
       "2095        2095  2019     10        NaiveBayesClassifier     NaN  0.686567\n",
       "2096        2096  2019     11        NaiveBayesClassifier     NaN  0.716418\n",
       "2097        2097  2019     12        NaiveBayesClassifier     NaN  0.791045\n",
       "2098        2098  2019     13        NaiveBayesClassifier     NaN  0.746269\n",
       "2099        2099  2019     14        NaiveBayesClassifier     NaN  0.776119\n",
       "2100        2100  2000      0          AdaBoostClassifier     NaN  0.634921\n",
       "2101        2101  2000      1          AdaBoostClassifier     NaN  0.634921\n",
       "2102        2102  2000      2          AdaBoostClassifier     NaN  0.603175\n",
       "2103        2103  2000      3          AdaBoostClassifier     NaN  0.666667\n",
       "2104        2104  2000      4          AdaBoostClassifier     NaN  0.682540\n",
       "2105        2105  2000      5          AdaBoostClassifier     NaN  0.650794\n",
       "2106        2106  2000      6          AdaBoostClassifier     NaN  0.634921\n",
       "2107        2107  2000      7          AdaBoostClassifier     NaN  0.619048\n",
       "2108        2108  2000      8          AdaBoostClassifier     NaN  0.666667\n",
       "2109        2109  2000      9          AdaBoostClassifier     NaN  0.730159\n",
       "2110        2110  2000     10          AdaBoostClassifier     NaN  0.698413\n",
       "2111        2111  2000     11          AdaBoostClassifier     NaN  0.666667\n",
       "2112        2112  2000     12          AdaBoostClassifier     NaN  0.777778\n",
       "2113        2113  2000     13          AdaBoostClassifier     NaN  0.698413\n",
       "2114        2114  2000     14          AdaBoostClassifier     NaN  0.730159\n",
       "2115        2115  2001      0          AdaBoostClassifier     NaN  0.633333\n",
       "2116        2116  2001      1          AdaBoostClassifier     NaN  0.666667\n",
       "2117        2117  2001      2          AdaBoostClassifier     NaN  0.550000\n",
       "2118        2118  2001      3          AdaBoostClassifier     NaN  0.650000\n",
       "2119        2119  2001      4          AdaBoostClassifier     NaN  0.650000\n",
       "2120        2120  2001      5          AdaBoostClassifier     NaN  0.683333\n",
       "2121        2121  2001      6          AdaBoostClassifier     NaN  0.733333\n",
       "2122        2122  2001      7          AdaBoostClassifier     NaN  0.666667\n",
       "2123        2123  2001      8          AdaBoostClassifier     NaN  0.650000\n",
       "2124        2124  2001      9          AdaBoostClassifier     NaN  0.683333\n",
       "2125        2125  2001     10          AdaBoostClassifier     NaN  0.750000\n",
       "2126        2126  2001     11          AdaBoostClassifier     NaN  0.766667\n",
       "2127        2127  2001     12          AdaBoostClassifier     NaN  0.700000\n",
       "2128        2128  2001     13          AdaBoostClassifier     NaN  0.683333\n",
       "2129        2129  2001     14          AdaBoostClassifier     NaN  0.733333\n",
       "2130        2130  2002      0          AdaBoostClassifier     NaN  0.690141\n",
       "2131        2131  2002      1          AdaBoostClassifier     NaN  0.619718\n",
       "2132        2132  2002      2          AdaBoostClassifier     NaN  0.563380\n",
       "2133        2133  2002      3          AdaBoostClassifier     NaN  0.605634\n",
       "2134        2134  2002      4          AdaBoostClassifier     NaN  0.661972\n",
       "2135        2135  2002      5          AdaBoostClassifier     NaN  0.619718\n",
       "2136        2136  2002      6          AdaBoostClassifier     NaN  0.661972\n",
       "2137        2137  2002      7          AdaBoostClassifier     NaN  0.704225\n",
       "2138        2138  2002      8          AdaBoostClassifier     NaN  0.633803\n",
       "2139        2139  2002      9          AdaBoostClassifier     NaN  0.492958\n",
       "2140        2140  2002     10          AdaBoostClassifier     NaN  0.676056\n",
       "2141        2141  2002     11          AdaBoostClassifier     NaN  0.619718\n",
       "2142        2142  2002     12          AdaBoostClassifier     NaN  0.507042\n",
       "2143        2143  2002     13          AdaBoostClassifier     NaN  0.647887\n",
       "2144        2144  2002     14          AdaBoostClassifier     NaN  0.633803\n",
       "2145        2145  2003      0          AdaBoostClassifier     NaN  0.656716\n",
       "2146        2146  2003      1          AdaBoostClassifier     NaN  0.671642\n",
       "2147        2147  2003      2          AdaBoostClassifier     NaN  0.641791\n",
       "2148        2148  2003      3          AdaBoostClassifier     NaN  0.626866\n",
       "2149        2149  2003      4          AdaBoostClassifier     NaN  0.716418\n",
       "2150        2150  2003      5          AdaBoostClassifier     NaN  0.626866\n",
       "2151        2151  2003      6          AdaBoostClassifier     NaN  0.686567\n",
       "2152        2152  2003      7          AdaBoostClassifier     NaN  0.716418\n",
       "2153        2153  2003      8          AdaBoostClassifier     NaN  0.746269\n",
       "2154        2154  2003      9          AdaBoostClassifier     NaN  0.731343\n",
       "2155        2155  2003     10          AdaBoostClassifier     NaN  0.671642\n",
       "2156        2156  2003     11          AdaBoostClassifier     NaN  0.671642\n",
       "2157        2157  2003     12          AdaBoostClassifier     NaN  0.776119\n",
       "2158        2158  2003     13          AdaBoostClassifier     NaN  0.701493\n",
       "2159        2159  2003     14          AdaBoostClassifier     NaN  0.701493\n",
       "2160        2160  2004      0          AdaBoostClassifier     NaN  0.619048\n",
       "2161        2161  2004      1          AdaBoostClassifier     NaN  0.539683\n",
       "2162        2162  2004      2          AdaBoostClassifier     NaN  0.555556\n",
       "2163        2163  2004      3          AdaBoostClassifier     NaN  0.650794\n",
       "2164        2164  2004      4          AdaBoostClassifier     NaN  0.730159\n",
       "2165        2165  2004      5          AdaBoostClassifier     NaN  0.634921\n",
       "2166        2166  2004      6          AdaBoostClassifier     NaN  0.650794\n",
       "2167        2167  2004      7          AdaBoostClassifier     NaN  0.619048\n",
       "2168        2168  2004      8          AdaBoostClassifier     NaN  0.714286\n",
       "2169        2169  2004      9          AdaBoostClassifier     NaN  0.698413\n",
       "2170        2170  2004     10          AdaBoostClassifier     NaN  0.650794\n",
       "2171        2171  2004     11          AdaBoostClassifier     NaN  0.730159\n",
       "2172        2172  2004     12          AdaBoostClassifier     NaN  0.761905\n",
       "2173        2173  2004     13          AdaBoostClassifier     NaN  0.571429\n",
       "2174        2174  2004     14          AdaBoostClassifier     NaN  0.761905\n",
       "2175        2175  2005      0          AdaBoostClassifier     NaN  0.617647\n",
       "2176        2176  2005      1          AdaBoostClassifier     NaN  0.676471\n",
       "2177        2177  2005      2          AdaBoostClassifier     NaN  0.661765\n",
       "2178        2178  2005      3          AdaBoostClassifier     NaN  0.470588\n",
       "2179        2179  2005      4          AdaBoostClassifier     NaN  0.691176\n",
       "2180        2180  2005      5          AdaBoostClassifier     NaN  0.720588\n",
       "2181        2181  2005      6          AdaBoostClassifier     NaN  0.647059\n",
       "2182        2182  2005      7          AdaBoostClassifier     NaN  0.617647\n",
       "2183        2183  2005      8          AdaBoostClassifier     NaN  0.529412\n",
       "2184        2184  2005      9          AdaBoostClassifier     NaN  0.647059\n",
       "2185        2185  2005     10          AdaBoostClassifier     NaN  0.720588\n",
       "2186        2186  2005     11          AdaBoostClassifier     NaN  0.661765\n",
       "2187        2187  2005     12          AdaBoostClassifier     NaN  0.661765\n",
       "2188        2188  2005     13          AdaBoostClassifier     NaN  0.647059\n",
       "2189        2189  2005     14          AdaBoostClassifier     NaN  0.691176\n",
       "2190        2190  2006      0          AdaBoostClassifier     NaN  0.746479\n",
       "2191        2191  2006      1          AdaBoostClassifier     NaN  0.774648\n",
       "2192        2192  2006      2          AdaBoostClassifier     NaN  0.591549\n",
       "2193        2193  2006      3          AdaBoostClassifier     NaN  0.647887\n",
       "2194        2194  2006      4          AdaBoostClassifier     NaN  0.816901\n",
       "2195        2195  2006      5          AdaBoostClassifier     NaN  0.676056\n",
       "2196        2196  2006      6          AdaBoostClassifier     NaN  0.633803\n",
       "2197        2197  2006      7          AdaBoostClassifier     NaN  0.732394\n",
       "2198        2198  2006      8          AdaBoostClassifier     NaN  0.704225\n",
       "2199        2199  2006      9          AdaBoostClassifier     NaN  0.732394\n",
       "2200        2200  2006     10          AdaBoostClassifier     NaN  0.802817\n",
       "2201        2201  2006     11          AdaBoostClassifier     NaN  0.760563\n",
       "2202        2202  2006     12          AdaBoostClassifier     NaN  0.732394\n",
       "2203        2203  2006     13          AdaBoostClassifier     NaN  0.760563\n",
       "2204        2204  2006     14          AdaBoostClassifier     NaN  0.802817\n",
       "2205        2205  2007      0          AdaBoostClassifier     NaN  0.582090\n",
       "2206        2206  2007      1          AdaBoostClassifier     NaN  0.611940\n",
       "2207        2207  2007      2          AdaBoostClassifier     NaN  0.582090\n",
       "2208        2208  2007      3          AdaBoostClassifier     NaN  0.641791\n",
       "2209        2209  2007      4          AdaBoostClassifier     NaN  0.656716\n",
       "2210        2210  2007      5          AdaBoostClassifier     NaN  0.626866\n",
       "2211        2211  2007      6          AdaBoostClassifier     NaN  0.656716\n",
       "2212        2212  2007      7          AdaBoostClassifier     NaN  0.686567\n",
       "2213        2213  2007      8          AdaBoostClassifier     NaN  0.701493\n",
       "2214        2214  2007      9          AdaBoostClassifier     NaN  0.716418\n",
       "2215        2215  2007     10          AdaBoostClassifier     NaN  0.701493\n",
       "2216        2216  2007     11          AdaBoostClassifier     NaN  0.626866\n",
       "2217        2217  2007     12          AdaBoostClassifier     NaN  0.716418\n",
       "2218        2218  2007     13          AdaBoostClassifier     NaN  0.761194\n",
       "2219        2219  2007     14          AdaBoostClassifier     NaN  0.791045\n",
       "2220        2220  2008      0          AdaBoostClassifier     NaN  0.552239\n",
       "2221        2221  2008      1          AdaBoostClassifier     NaN  0.611940\n",
       "2222        2222  2008      2          AdaBoostClassifier     NaN  0.701493\n",
       "2223        2223  2008      3          AdaBoostClassifier     NaN  0.656716\n",
       "2224        2224  2008      4          AdaBoostClassifier     NaN  0.641791\n",
       "2225        2225  2008      5          AdaBoostClassifier     NaN  0.716418\n",
       "2226        2226  2008      6          AdaBoostClassifier     NaN  0.701493\n",
       "2227        2227  2008      7          AdaBoostClassifier     NaN  0.686567\n",
       "2228        2228  2008      8          AdaBoostClassifier     NaN  0.656716\n",
       "2229        2229  2008      9          AdaBoostClassifier     NaN  0.716418\n",
       "2230        2230  2008     10          AdaBoostClassifier     NaN  0.701493\n",
       "2231        2231  2008     11          AdaBoostClassifier     NaN  0.701493\n",
       "2232        2232  2008     12          AdaBoostClassifier     NaN  0.716418\n",
       "2233        2233  2008     13          AdaBoostClassifier     NaN  0.761194\n",
       "2234        2234  2008     14          AdaBoostClassifier     NaN  0.776119\n",
       "2235        2235  2009      0          AdaBoostClassifier     NaN  0.650794\n",
       "2236        2236  2009      1          AdaBoostClassifier     NaN  0.714286\n",
       "2237        2237  2009      2          AdaBoostClassifier     NaN  0.682540\n",
       "2238        2238  2009      3          AdaBoostClassifier     NaN  0.698413\n",
       "2239        2239  2009      4          AdaBoostClassifier     NaN  0.603175\n",
       "2240        2240  2009      5          AdaBoostClassifier     NaN  0.761905\n",
       "2241        2241  2009      6          AdaBoostClassifier     NaN  0.761905\n",
       "2242        2242  2009      7          AdaBoostClassifier     NaN  0.634921\n",
       "2243        2243  2009      8          AdaBoostClassifier     NaN  0.650794\n",
       "2244        2244  2009      9          AdaBoostClassifier     NaN  0.793651\n",
       "2245        2245  2009     10          AdaBoostClassifier     NaN  0.619048\n",
       "2246        2246  2009     11          AdaBoostClassifier     NaN  0.682540\n",
       "2247        2247  2009     12          AdaBoostClassifier     NaN  0.650794\n",
       "2248        2248  2009     13          AdaBoostClassifier     NaN  0.809524\n",
       "2249        2249  2009     14          AdaBoostClassifier     NaN  0.666667\n",
       "2250        2250  2010      0          AdaBoostClassifier     NaN  0.731343\n",
       "2251        2251  2010      1          AdaBoostClassifier     NaN  0.731343\n",
       "2252        2252  2010      2          AdaBoostClassifier     NaN  0.641791\n",
       "2253        2253  2010      3          AdaBoostClassifier     NaN  0.671642\n",
       "2254        2254  2010      4          AdaBoostClassifier     NaN  0.761194\n",
       "2255        2255  2010      5          AdaBoostClassifier     NaN  0.776119\n",
       "2256        2256  2010      6          AdaBoostClassifier     NaN  0.671642\n",
       "2257        2257  2010      7          AdaBoostClassifier     NaN  0.731343\n",
       "2258        2258  2010      8          AdaBoostClassifier     NaN  0.731343\n",
       "2259        2259  2010      9          AdaBoostClassifier     NaN  0.701493\n",
       "2260        2260  2010     10          AdaBoostClassifier     NaN  0.731343\n",
       "2261        2261  2010     11          AdaBoostClassifier     NaN  0.716418\n",
       "2262        2262  2010     12          AdaBoostClassifier     NaN  0.731343\n",
       "2263        2263  2010     13          AdaBoostClassifier     NaN  0.746269\n",
       "2264        2264  2010     14          AdaBoostClassifier     NaN  0.686567\n",
       "2265        2265  2011      0          AdaBoostClassifier     NaN  0.552239\n",
       "2266        2266  2011      1          AdaBoostClassifier     NaN  0.522388\n",
       "2267        2267  2011      2          AdaBoostClassifier     NaN  0.716418\n",
       "2268        2268  2011      3          AdaBoostClassifier     NaN  0.567164\n",
       "2269        2269  2011      4          AdaBoostClassifier     NaN  0.582090\n",
       "2270        2270  2011      5          AdaBoostClassifier     NaN  0.582090\n",
       "2271        2271  2011      6          AdaBoostClassifier     NaN  0.716418\n",
       "2272        2272  2011      7          AdaBoostClassifier     NaN  0.686567\n",
       "2273        2273  2011      8          AdaBoostClassifier     NaN  0.671642\n",
       "2274        2274  2011      9          AdaBoostClassifier     NaN  0.597015\n",
       "2275        2275  2011     10          AdaBoostClassifier     NaN  0.656716\n",
       "2276        2276  2011     11          AdaBoostClassifier     NaN  0.746269\n",
       "2277        2277  2011     12          AdaBoostClassifier     NaN  0.641791\n",
       "2278        2278  2011     13          AdaBoostClassifier     NaN  0.656716\n",
       "2279        2279  2011     14          AdaBoostClassifier     NaN  0.641791\n",
       "2280        2280  2012      0          AdaBoostClassifier     NaN  0.521127\n",
       "2281        2281  2012      1          AdaBoostClassifier     NaN  0.661972\n",
       "2282        2282  2012      2          AdaBoostClassifier     NaN  0.577465\n",
       "2283        2283  2012      3          AdaBoostClassifier     NaN  0.690141\n",
       "2284        2284  2012      4          AdaBoostClassifier     NaN  0.676056\n",
       "2285        2285  2012      5          AdaBoostClassifier     NaN  0.704225\n",
       "2286        2286  2012      6          AdaBoostClassifier     NaN  0.690141\n",
       "2287        2287  2012      7          AdaBoostClassifier     NaN  0.661972\n",
       "2288        2288  2012      8          AdaBoostClassifier     NaN  0.661972\n",
       "2289        2289  2012      9          AdaBoostClassifier     NaN  0.690141\n",
       "2290        2290  2012     10          AdaBoostClassifier     NaN  0.676056\n",
       "2291        2291  2012     11          AdaBoostClassifier     NaN  0.788732\n",
       "2292        2292  2012     12          AdaBoostClassifier     NaN  0.732394\n",
       "2293        2293  2012     13          AdaBoostClassifier     NaN  0.718310\n",
       "2294        2294  2012     14          AdaBoostClassifier     NaN  0.718310\n",
       "2295        2295  2013      0          AdaBoostClassifier     NaN  0.477612\n",
       "2296        2296  2013      1          AdaBoostClassifier     NaN  0.611940\n",
       "2297        2297  2013      2          AdaBoostClassifier     NaN  0.552239\n",
       "2298        2298  2013      3          AdaBoostClassifier     NaN  0.597015\n",
       "2299        2299  2013      4          AdaBoostClassifier     NaN  0.656716\n",
       "2300        2300  2013      5          AdaBoostClassifier     NaN  0.671642\n",
       "2301        2301  2013      6          AdaBoostClassifier     NaN  0.731343\n",
       "2302        2302  2013      7          AdaBoostClassifier     NaN  0.641791\n",
       "2303        2303  2013      8          AdaBoostClassifier     NaN  0.641791\n",
       "2304        2304  2013      9          AdaBoostClassifier     NaN  0.626866\n",
       "2305        2305  2013     10          AdaBoostClassifier     NaN  0.626866\n",
       "2306        2306  2013     11          AdaBoostClassifier     NaN  0.746269\n",
       "2307        2307  2013     12          AdaBoostClassifier     NaN  0.701493\n",
       "2308        2308  2013     13          AdaBoostClassifier     NaN  0.701493\n",
       "2309        2309  2013     14          AdaBoostClassifier     NaN  0.791045\n",
       "2310        2310  2014      0          AdaBoostClassifier     NaN  0.641791\n",
       "2311        2311  2014      1          AdaBoostClassifier     NaN  0.611940\n",
       "2312        2312  2014      2          AdaBoostClassifier     NaN  0.701493\n",
       "2313        2313  2014      3          AdaBoostClassifier     NaN  0.671642\n",
       "2314        2314  2014      4          AdaBoostClassifier     NaN  0.626866\n",
       "2315        2315  2014      5          AdaBoostClassifier     NaN  0.776119\n",
       "2316        2316  2014      6          AdaBoostClassifier     NaN  0.791045\n",
       "2317        2317  2014      7          AdaBoostClassifier     NaN  0.776119\n",
       "2318        2318  2014      8          AdaBoostClassifier     NaN  0.701493\n",
       "2319        2319  2014      9          AdaBoostClassifier     NaN  0.567164\n",
       "2320        2320  2014     10          AdaBoostClassifier     NaN  0.671642\n",
       "2321        2321  2014     11          AdaBoostClassifier     NaN  0.761194\n",
       "2322        2322  2014     12          AdaBoostClassifier     NaN  0.686567\n",
       "2323        2323  2014     13          AdaBoostClassifier     NaN  0.686567\n",
       "2324        2324  2014     14          AdaBoostClassifier     NaN  0.820896\n",
       "2325        2325  2015      0          AdaBoostClassifier     NaN  0.628571\n",
       "2326        2326  2015      1          AdaBoostClassifier     NaN  0.685714\n",
       "2327        2327  2015      2          AdaBoostClassifier     NaN  0.585714\n",
       "2328        2328  2015      3          AdaBoostClassifier     NaN  0.671429\n",
       "2329        2329  2015      4          AdaBoostClassifier     NaN  0.685714\n",
       "2330        2330  2015      5          AdaBoostClassifier     NaN  0.700000\n",
       "2331        2331  2015      6          AdaBoostClassifier     NaN  0.700000\n",
       "2332        2332  2015      7          AdaBoostClassifier     NaN  0.700000\n",
       "2333        2333  2015      8          AdaBoostClassifier     NaN  0.742857\n",
       "2334        2334  2015      9          AdaBoostClassifier     NaN  0.714286\n",
       "2335        2335  2015     10          AdaBoostClassifier     NaN  0.771429\n",
       "2336        2336  2015     11          AdaBoostClassifier     NaN  0.728571\n",
       "2337        2337  2015     12          AdaBoostClassifier     NaN  0.771429\n",
       "2338        2338  2015     13          AdaBoostClassifier     NaN  0.685714\n",
       "2339        2339  2015     14          AdaBoostClassifier     NaN  0.785714\n",
       "2340        2340  2016      0          AdaBoostClassifier     NaN  0.641791\n",
       "2341        2341  2016      1          AdaBoostClassifier     NaN  0.746269\n",
       "2342        2342  2016      2          AdaBoostClassifier     NaN  0.641791\n",
       "2343        2343  2016      3          AdaBoostClassifier     NaN  0.611940\n",
       "2344        2344  2016      4          AdaBoostClassifier     NaN  0.761194\n",
       "2345        2345  2016      5          AdaBoostClassifier     NaN  0.731343\n",
       "2346        2346  2016      6          AdaBoostClassifier     NaN  0.656716\n",
       "2347        2347  2016      7          AdaBoostClassifier     NaN  0.746269\n",
       "2348        2348  2016      8          AdaBoostClassifier     NaN  0.656716\n",
       "2349        2349  2016      9          AdaBoostClassifier     NaN  0.761194\n",
       "2350        2350  2016     10          AdaBoostClassifier     NaN  0.746269\n",
       "2351        2351  2016     11          AdaBoostClassifier     NaN  0.701493\n",
       "2352        2352  2016     12          AdaBoostClassifier     NaN  0.776119\n",
       "2353        2353  2016     13          AdaBoostClassifier     NaN  0.776119\n",
       "2354        2354  2016     14          AdaBoostClassifier     NaN  0.746269\n",
       "2355        2355  2017      0          AdaBoostClassifier     NaN  0.671642\n",
       "2356        2356  2017      1          AdaBoostClassifier     NaN  0.701493\n",
       "2357        2357  2017      2          AdaBoostClassifier     NaN  0.701493\n",
       "2358        2358  2017      3          AdaBoostClassifier     NaN  0.641791\n",
       "2359        2359  2017      4          AdaBoostClassifier     NaN  0.671642\n",
       "2360        2360  2017      5          AdaBoostClassifier     NaN  0.746269\n",
       "2361        2361  2017      6          AdaBoostClassifier     NaN  0.686567\n",
       "2362        2362  2017      7          AdaBoostClassifier     NaN  0.701493\n",
       "2363        2363  2017      8          AdaBoostClassifier     NaN  0.776119\n",
       "2364        2364  2017      9          AdaBoostClassifier     NaN  0.656716\n",
       "2365        2365  2017     10          AdaBoostClassifier     NaN  0.776119\n",
       "2366        2366  2017     11          AdaBoostClassifier     NaN  0.746269\n",
       "2367        2367  2017     12          AdaBoostClassifier     NaN  0.761194\n",
       "2368        2368  2017     13          AdaBoostClassifier     NaN  0.716418\n",
       "2369        2369  2017     14          AdaBoostClassifier     NaN  0.805970\n",
       "2370        2370  2018      0          AdaBoostClassifier     NaN  0.537313\n",
       "2371        2371  2018      1          AdaBoostClassifier     NaN  0.641791\n",
       "2372        2372  2018      2          AdaBoostClassifier     NaN  0.477612\n",
       "2373        2373  2018      3          AdaBoostClassifier     NaN  0.537313\n",
       "2374        2374  2018      4          AdaBoostClassifier     NaN  0.626866\n",
       "2375        2375  2018      5          AdaBoostClassifier     NaN  0.671642\n",
       "2376        2376  2018      6          AdaBoostClassifier     NaN  0.537313\n",
       "2377        2377  2018      7          AdaBoostClassifier     NaN  0.671642\n",
       "2378        2378  2018      8          AdaBoostClassifier     NaN  0.552239\n",
       "2379        2379  2018      9          AdaBoostClassifier     NaN  0.686567\n",
       "2380        2380  2018     10          AdaBoostClassifier     NaN  0.641791\n",
       "2381        2381  2018     11          AdaBoostClassifier     NaN  0.582090\n",
       "2382        2382  2018     12          AdaBoostClassifier     NaN  0.731343\n",
       "2383        2383  2018     13          AdaBoostClassifier     NaN  0.671642\n",
       "2384        2384  2018     14          AdaBoostClassifier     NaN  0.791045\n",
       "2385        2385  2019      0          AdaBoostClassifier     NaN  0.626866\n",
       "2386        2386  2019      1          AdaBoostClassifier     NaN  0.686567\n",
       "2387        2387  2019      2          AdaBoostClassifier     NaN  0.597015\n",
       "2388        2388  2019      3          AdaBoostClassifier     NaN  0.701493\n",
       "2389        2389  2019      4          AdaBoostClassifier     NaN  0.671642\n",
       "2390        2390  2019      5          AdaBoostClassifier     NaN  0.701493\n",
       "2391        2391  2019      6          AdaBoostClassifier     NaN  0.611940\n",
       "2392        2392  2019      7          AdaBoostClassifier     NaN  0.701493\n",
       "2393        2393  2019      8          AdaBoostClassifier     NaN  0.731343\n",
       "2394        2394  2019      9          AdaBoostClassifier     NaN  0.656716\n",
       "2395        2395  2019     10          AdaBoostClassifier     NaN  0.761194\n",
       "2396        2396  2019     11          AdaBoostClassifier     NaN  0.716418\n",
       "2397        2397  2019     12          AdaBoostClassifier     NaN  0.731343\n",
       "2398        2398  2019     13          AdaBoostClassifier     NaN  0.731343\n",
       "2399        2399  2019     14          AdaBoostClassifier     NaN  0.761194\n",
       "2400        2400  2000      0  GradientBoostingClassifier     NaN  0.634921\n",
       "2401        2401  2000      1  GradientBoostingClassifier     NaN  0.634921\n",
       "2402        2402  2000      2  GradientBoostingClassifier     NaN  0.603175\n",
       "2403        2403  2000      3  GradientBoostingClassifier     NaN  0.666667\n",
       "2404        2404  2000      4  GradientBoostingClassifier     NaN  0.634921\n",
       "2405        2405  2000      5  GradientBoostingClassifier     NaN  0.650794\n",
       "2406        2406  2000      6  GradientBoostingClassifier     NaN  0.634921\n",
       "2407        2407  2000      7  GradientBoostingClassifier     NaN  0.666667\n",
       "2408        2408  2000      8  GradientBoostingClassifier     NaN  0.714286\n",
       "2409        2409  2000      9  GradientBoostingClassifier     NaN  0.714286\n",
       "2410        2410  2000     10  GradientBoostingClassifier     NaN  0.730159\n",
       "2411        2411  2000     11  GradientBoostingClassifier     NaN  0.761905\n",
       "2412        2412  2000     12  GradientBoostingClassifier     NaN  0.777778\n",
       "2413        2413  2000     13  GradientBoostingClassifier     NaN  0.730159\n",
       "2414        2414  2000     14  GradientBoostingClassifier     NaN  0.777778\n",
       "2415        2415  2001      0  GradientBoostingClassifier     NaN  0.633333\n",
       "2416        2416  2001      1  GradientBoostingClassifier     NaN  0.666667\n",
       "2417        2417  2001      2  GradientBoostingClassifier     NaN  0.550000\n",
       "2418        2418  2001      3  GradientBoostingClassifier     NaN  0.650000\n",
       "2419        2419  2001      4  GradientBoostingClassifier     NaN  0.683333\n",
       "2420        2420  2001      5  GradientBoostingClassifier     NaN  0.666667\n",
       "2421        2421  2001      6  GradientBoostingClassifier     NaN  0.516667\n",
       "2422        2422  2001      7  GradientBoostingClassifier     NaN  0.650000\n",
       "2423        2423  2001      8  GradientBoostingClassifier     NaN  0.666667\n",
       "2424        2424  2001      9  GradientBoostingClassifier     NaN  0.716667\n",
       "2425        2425  2001     10  GradientBoostingClassifier     NaN  0.750000\n",
       "2426        2426  2001     11  GradientBoostingClassifier     NaN  0.666667\n",
       "2427        2427  2001     12  GradientBoostingClassifier     NaN  0.716667\n",
       "2428        2428  2001     13  GradientBoostingClassifier     NaN  0.666667\n",
       "2429        2429  2001     14  GradientBoostingClassifier     NaN  0.800000\n",
       "2430        2430  2002      0  GradientBoostingClassifier     NaN  0.690141\n",
       "2431        2431  2002      1  GradientBoostingClassifier     NaN  0.619718\n",
       "2432        2432  2002      2  GradientBoostingClassifier     NaN  0.563380\n",
       "2433        2433  2002      3  GradientBoostingClassifier     NaN  0.605634\n",
       "2434        2434  2002      4  GradientBoostingClassifier     NaN  0.647887\n",
       "2435        2435  2002      5  GradientBoostingClassifier     NaN  0.633803\n",
       "2436        2436  2002      6  GradientBoostingClassifier     NaN  0.591549\n",
       "2437        2437  2002      7  GradientBoostingClassifier     NaN  0.676056\n",
       "2438        2438  2002      8  GradientBoostingClassifier     NaN  0.704225\n",
       "2439        2439  2002      9  GradientBoostingClassifier     NaN  0.605634\n",
       "2440        2440  2002     10  GradientBoostingClassifier     NaN  0.732394\n",
       "2441        2441  2002     11  GradientBoostingClassifier     NaN  0.647887\n",
       "2442        2442  2002     12  GradientBoostingClassifier     NaN  0.718310\n",
       "2443        2443  2002     13  GradientBoostingClassifier     NaN  0.563380\n",
       "2444        2444  2002     14  GradientBoostingClassifier     NaN  0.718310\n",
       "2445        2445  2003      0  GradientBoostingClassifier     NaN  0.656716\n",
       "2446        2446  2003      1  GradientBoostingClassifier     NaN  0.671642\n",
       "2447        2447  2003      2  GradientBoostingClassifier     NaN  0.641791\n",
       "2448        2448  2003      3  GradientBoostingClassifier     NaN  0.582090\n",
       "2449        2449  2003      4  GradientBoostingClassifier     NaN  0.731343\n",
       "2450        2450  2003      5  GradientBoostingClassifier     NaN  0.656716\n",
       "2451        2451  2003      6  GradientBoostingClassifier     NaN  0.611940\n",
       "2452        2452  2003      7  GradientBoostingClassifier     NaN  0.701493\n",
       "2453        2453  2003      8  GradientBoostingClassifier     NaN  0.701493\n",
       "2454        2454  2003      9  GradientBoostingClassifier     NaN  0.656716\n",
       "2455        2455  2003     10  GradientBoostingClassifier     NaN  0.731343\n",
       "2456        2456  2003     11  GradientBoostingClassifier     NaN  0.746269\n",
       "2457        2457  2003     12  GradientBoostingClassifier     NaN  0.731343\n",
       "2458        2458  2003     13  GradientBoostingClassifier     NaN  0.701493\n",
       "2459        2459  2003     14  GradientBoostingClassifier     NaN  0.791045\n",
       "2460        2460  2004      0  GradientBoostingClassifier     NaN  0.619048\n",
       "2461        2461  2004      1  GradientBoostingClassifier     NaN  0.539683\n",
       "2462        2462  2004      2  GradientBoostingClassifier     NaN  0.539683\n",
       "2463        2463  2004      3  GradientBoostingClassifier     NaN  0.650794\n",
       "2464        2464  2004      4  GradientBoostingClassifier     NaN  0.682540\n",
       "2465        2465  2004      5  GradientBoostingClassifier     NaN  0.650794\n",
       "2466        2466  2004      6  GradientBoostingClassifier     NaN  0.714286\n",
       "2467        2467  2004      7  GradientBoostingClassifier     NaN  0.539683\n",
       "2468        2468  2004      8  GradientBoostingClassifier     NaN  0.746032\n",
       "2469        2469  2004      9  GradientBoostingClassifier     NaN  0.634921\n",
       "2470        2470  2004     10  GradientBoostingClassifier     NaN  0.777778\n",
       "2471        2471  2004     11  GradientBoostingClassifier     NaN  0.666667\n",
       "2472        2472  2004     12  GradientBoostingClassifier     NaN  0.746032\n",
       "2473        2473  2004     13  GradientBoostingClassifier     NaN  0.698413\n",
       "2474        2474  2004     14  GradientBoostingClassifier     NaN  0.793651\n",
       "2475        2475  2005      0  GradientBoostingClassifier     NaN  0.617647\n",
       "2476        2476  2005      1  GradientBoostingClassifier     NaN  0.676471\n",
       "2477        2477  2005      2  GradientBoostingClassifier     NaN  0.661765\n",
       "2478        2478  2005      3  GradientBoostingClassifier     NaN  0.470588\n",
       "2479        2479  2005      4  GradientBoostingClassifier     NaN  0.691176\n",
       "2480        2480  2005      5  GradientBoostingClassifier     NaN  0.661765\n",
       "2481        2481  2005      6  GradientBoostingClassifier     NaN  0.661765\n",
       "2482        2482  2005      7  GradientBoostingClassifier     NaN  0.617647\n",
       "2483        2483  2005      8  GradientBoostingClassifier     NaN  0.558824\n",
       "2484        2484  2005      9  GradientBoostingClassifier     NaN  0.676471\n",
       "2485        2485  2005     10  GradientBoostingClassifier     NaN  0.676471\n",
       "2486        2486  2005     11  GradientBoostingClassifier     NaN  0.602941\n",
       "2487        2487  2005     12  GradientBoostingClassifier     NaN  0.661765\n",
       "2488        2488  2005     13  GradientBoostingClassifier     NaN  0.705882\n",
       "2489        2489  2005     14  GradientBoostingClassifier     NaN  0.779412\n",
       "2490        2490  2006      0  GradientBoostingClassifier     NaN  0.746479\n",
       "2491        2491  2006      1  GradientBoostingClassifier     NaN  0.774648\n",
       "2492        2492  2006      2  GradientBoostingClassifier     NaN  0.591549\n",
       "2493        2493  2006      3  GradientBoostingClassifier     NaN  0.647887\n",
       "2494        2494  2006      4  GradientBoostingClassifier     NaN  0.788732\n",
       "2495        2495  2006      5  GradientBoostingClassifier     NaN  0.661972\n",
       "2496        2496  2006      6  GradientBoostingClassifier     NaN  0.647887\n",
       "2497        2497  2006      7  GradientBoostingClassifier     NaN  0.704225\n",
       "2498        2498  2006      8  GradientBoostingClassifier     NaN  0.704225\n",
       "2499        2499  2006      9  GradientBoostingClassifier     NaN  0.746479\n",
       "2500        2500  2006     10  GradientBoostingClassifier     NaN  0.802817\n",
       "2501        2501  2006     11  GradientBoostingClassifier     NaN  0.676056\n",
       "2502        2502  2006     12  GradientBoostingClassifier     NaN  0.760563\n",
       "2503        2503  2006     13  GradientBoostingClassifier     NaN  0.704225\n",
       "2504        2504  2006     14  GradientBoostingClassifier     NaN  0.845070\n",
       "2505        2505  2007      0  GradientBoostingClassifier     NaN  0.582090\n",
       "2506        2506  2007      1  GradientBoostingClassifier     NaN  0.611940\n",
       "2507        2507  2007      2  GradientBoostingClassifier     NaN  0.582090\n",
       "2508        2508  2007      3  GradientBoostingClassifier     NaN  0.641791\n",
       "2509        2509  2007      4  GradientBoostingClassifier     NaN  0.641791\n",
       "2510        2510  2007      5  GradientBoostingClassifier     NaN  0.656716\n",
       "2511        2511  2007      6  GradientBoostingClassifier     NaN  0.582090\n",
       "2512        2512  2007      7  GradientBoostingClassifier     NaN  0.686567\n",
       "2513        2513  2007      8  GradientBoostingClassifier     NaN  0.746269\n",
       "2514        2514  2007      9  GradientBoostingClassifier     NaN  0.701493\n",
       "2515        2515  2007     10  GradientBoostingClassifier     NaN  0.641791\n",
       "2516        2516  2007     11  GradientBoostingClassifier     NaN  0.686567\n",
       "2517        2517  2007     12  GradientBoostingClassifier     NaN  0.731343\n",
       "2518        2518  2007     13  GradientBoostingClassifier     NaN  0.731343\n",
       "2519        2519  2007     14  GradientBoostingClassifier     NaN  0.820896\n",
       "2520        2520  2008      0  GradientBoostingClassifier     NaN  0.552239\n",
       "2521        2521  2008      1  GradientBoostingClassifier     NaN  0.611940\n",
       "2522        2522  2008      2  GradientBoostingClassifier     NaN  0.701493\n",
       "2523        2523  2008      3  GradientBoostingClassifier     NaN  0.656716\n",
       "2524        2524  2008      4  GradientBoostingClassifier     NaN  0.671642\n",
       "2525        2525  2008      5  GradientBoostingClassifier     NaN  0.656716\n",
       "2526        2526  2008      6  GradientBoostingClassifier     NaN  0.686567\n",
       "2527        2527  2008      7  GradientBoostingClassifier     NaN  0.641791\n",
       "2528        2528  2008      8  GradientBoostingClassifier     NaN  0.626866\n",
       "2529        2529  2008      9  GradientBoostingClassifier     NaN  0.641791\n",
       "2530        2530  2008     10  GradientBoostingClassifier     NaN  0.776119\n",
       "2531        2531  2008     11  GradientBoostingClassifier     NaN  0.731343\n",
       "2532        2532  2008     12  GradientBoostingClassifier     NaN  0.671642\n",
       "2533        2533  2008     13  GradientBoostingClassifier     NaN  0.731343\n",
       "2534        2534  2008     14  GradientBoostingClassifier     NaN  0.791045\n",
       "2535        2535  2009      0  GradientBoostingClassifier     NaN  0.650794\n",
       "2536        2536  2009      1  GradientBoostingClassifier     NaN  0.714286\n",
       "2537        2537  2009      2  GradientBoostingClassifier     NaN  0.682540\n",
       "2538        2538  2009      3  GradientBoostingClassifier     NaN  0.698413\n",
       "2539        2539  2009      4  GradientBoostingClassifier     NaN  0.603175\n",
       "2540        2540  2009      5  GradientBoostingClassifier     NaN  0.746032\n",
       "2541        2541  2009      6  GradientBoostingClassifier     NaN  0.714286\n",
       "2542        2542  2009      7  GradientBoostingClassifier     NaN  0.619048\n",
       "2543        2543  2009      8  GradientBoostingClassifier     NaN  0.619048\n",
       "2544        2544  2009      9  GradientBoostingClassifier     NaN  0.761905\n",
       "2545        2545  2009     10  GradientBoostingClassifier     NaN  0.682540\n",
       "2546        2546  2009     11  GradientBoostingClassifier     NaN  0.634921\n",
       "2547        2547  2009     12  GradientBoostingClassifier     NaN  0.761905\n",
       "2548        2548  2009     13  GradientBoostingClassifier     NaN  0.761905\n",
       "2549        2549  2009     14  GradientBoostingClassifier     NaN  0.746032\n",
       "2550        2550  2010      0  GradientBoostingClassifier     NaN  0.731343\n",
       "2551        2551  2010      1  GradientBoostingClassifier     NaN  0.731343\n",
       "2552        2552  2010      2  GradientBoostingClassifier     NaN  0.641791\n",
       "2553        2553  2010      3  GradientBoostingClassifier     NaN  0.671642\n",
       "2554        2554  2010      4  GradientBoostingClassifier     NaN  0.716418\n",
       "2555        2555  2010      5  GradientBoostingClassifier     NaN  0.701493\n",
       "2556        2556  2010      6  GradientBoostingClassifier     NaN  0.656716\n",
       "2557        2557  2010      7  GradientBoostingClassifier     NaN  0.671642\n",
       "2558        2558  2010      8  GradientBoostingClassifier     NaN  0.701493\n",
       "2559        2559  2010      9  GradientBoostingClassifier     NaN  0.686567\n",
       "2560        2560  2010     10  GradientBoostingClassifier     NaN  0.820896\n",
       "2561        2561  2010     11  GradientBoostingClassifier     NaN  0.686567\n",
       "2562        2562  2010     12  GradientBoostingClassifier     NaN  0.731343\n",
       "2563        2563  2010     13  GradientBoostingClassifier     NaN  0.701493\n",
       "2564        2564  2010     14  GradientBoostingClassifier     NaN  0.761194\n",
       "2565        2565  2011      0  GradientBoostingClassifier     NaN  0.552239\n",
       "2566        2566  2011      1  GradientBoostingClassifier     NaN  0.522388\n",
       "2567        2567  2011      2  GradientBoostingClassifier     NaN  0.716418\n",
       "2568        2568  2011      3  GradientBoostingClassifier     NaN  0.567164\n",
       "2569        2569  2011      4  GradientBoostingClassifier     NaN  0.626866\n",
       "2570        2570  2011      5  GradientBoostingClassifier     NaN  0.597015\n",
       "2571        2571  2011      6  GradientBoostingClassifier     NaN  0.716418\n",
       "2572        2572  2011      7  GradientBoostingClassifier     NaN  0.701493\n",
       "2573        2573  2011      8  GradientBoostingClassifier     NaN  0.626866\n",
       "2574        2574  2011      9  GradientBoostingClassifier     NaN  0.597015\n",
       "2575        2575  2011     10  GradientBoostingClassifier     NaN  0.716418\n",
       "2576        2576  2011     11  GradientBoostingClassifier     NaN  0.701493\n",
       "2577        2577  2011     12  GradientBoostingClassifier     NaN  0.626866\n",
       "2578        2578  2011     13  GradientBoostingClassifier     NaN  0.671642\n",
       "2579        2579  2011     14  GradientBoostingClassifier     NaN  0.716418\n",
       "2580        2580  2012      0  GradientBoostingClassifier     NaN  0.521127\n",
       "2581        2581  2012      1  GradientBoostingClassifier     NaN  0.661972\n",
       "2582        2582  2012      2  GradientBoostingClassifier     NaN  0.577465\n",
       "2583        2583  2012      3  GradientBoostingClassifier     NaN  0.690141\n",
       "2584        2584  2012      4  GradientBoostingClassifier     NaN  0.647887\n",
       "2585        2585  2012      5  GradientBoostingClassifier     NaN  0.661972\n",
       "2586        2586  2012      6  GradientBoostingClassifier     NaN  0.690141\n",
       "2587        2587  2012      7  GradientBoostingClassifier     NaN  0.676056\n",
       "2588        2588  2012      8  GradientBoostingClassifier     NaN  0.619718\n",
       "2589        2589  2012      9  GradientBoostingClassifier     NaN  0.704225\n",
       "2590        2590  2012     10  GradientBoostingClassifier     NaN  0.647887\n",
       "2591        2591  2012     11  GradientBoostingClassifier     NaN  0.718310\n",
       "2592        2592  2012     12  GradientBoostingClassifier     NaN  0.704225\n",
       "2593        2593  2012     13  GradientBoostingClassifier     NaN  0.732394\n",
       "2594        2594  2012     14  GradientBoostingClassifier     NaN  0.746479\n",
       "2595        2595  2013      0  GradientBoostingClassifier     NaN  0.507463\n",
       "2596        2596  2013      1  GradientBoostingClassifier     NaN  0.611940\n",
       "2597        2597  2013      2  GradientBoostingClassifier     NaN  0.552239\n",
       "2598        2598  2013      3  GradientBoostingClassifier     NaN  0.671642\n",
       "2599        2599  2013      4  GradientBoostingClassifier     NaN  0.641791\n",
       "2600        2600  2013      5  GradientBoostingClassifier     NaN  0.641791\n",
       "2601        2601  2013      6  GradientBoostingClassifier     NaN  0.731343\n",
       "2602        2602  2013      7  GradientBoostingClassifier     NaN  0.582090\n",
       "2603        2603  2013      8  GradientBoostingClassifier     NaN  0.552239\n",
       "2604        2604  2013      9  GradientBoostingClassifier     NaN  0.626866\n",
       "2605        2605  2013     10  GradientBoostingClassifier     NaN  0.611940\n",
       "2606        2606  2013     11  GradientBoostingClassifier     NaN  0.731343\n",
       "2607        2607  2013     12  GradientBoostingClassifier     NaN  0.656716\n",
       "2608        2608  2013     13  GradientBoostingClassifier     NaN  0.731343\n",
       "2609        2609  2013     14  GradientBoostingClassifier     NaN  0.731343\n",
       "2610        2610  2014      0  GradientBoostingClassifier     NaN  0.641791\n",
       "2611        2611  2014      1  GradientBoostingClassifier     NaN  0.611940\n",
       "2612        2612  2014      2  GradientBoostingClassifier     NaN  0.701493\n",
       "2613        2613  2014      3  GradientBoostingClassifier     NaN  0.671642\n",
       "2614        2614  2014      4  GradientBoostingClassifier     NaN  0.671642\n",
       "2615        2615  2014      5  GradientBoostingClassifier     NaN  0.761194\n",
       "2616        2616  2014      6  GradientBoostingClassifier     NaN  0.791045\n",
       "2617        2617  2014      7  GradientBoostingClassifier     NaN  0.731343\n",
       "2618        2618  2014      8  GradientBoostingClassifier     NaN  0.671642\n",
       "2619        2619  2014      9  GradientBoostingClassifier     NaN  0.701493\n",
       "2620        2620  2014     10  GradientBoostingClassifier     NaN  0.791045\n",
       "2621        2621  2014     11  GradientBoostingClassifier     NaN  0.791045\n",
       "2622        2622  2014     12  GradientBoostingClassifier     NaN  0.671642\n",
       "2623        2623  2014     13  GradientBoostingClassifier     NaN  0.761194\n",
       "2624        2624  2014     14  GradientBoostingClassifier     NaN  0.820896\n",
       "2625        2625  2015      0  GradientBoostingClassifier     NaN  0.628571\n",
       "2626        2626  2015      1  GradientBoostingClassifier     NaN  0.685714\n",
       "2627        2627  2015      2  GradientBoostingClassifier     NaN  0.628571\n",
       "2628        2628  2015      3  GradientBoostingClassifier     NaN  0.671429\n",
       "2629        2629  2015      4  GradientBoostingClassifier     NaN  0.714286\n",
       "2630        2630  2015      5  GradientBoostingClassifier     NaN  0.700000\n",
       "2631        2631  2015      6  GradientBoostingClassifier     NaN  0.671429\n",
       "2632        2632  2015      7  GradientBoostingClassifier     NaN  0.685714\n",
       "2633        2633  2015      8  GradientBoostingClassifier     NaN  0.657143\n",
       "2634        2634  2015      9  GradientBoostingClassifier     NaN  0.700000\n",
       "2635        2635  2015     10  GradientBoostingClassifier     NaN  0.714286\n",
       "2636        2636  2015     11  GradientBoostingClassifier     NaN  0.700000\n",
       "2637        2637  2015     12  GradientBoostingClassifier     NaN  0.757143\n",
       "2638        2638  2015     13  GradientBoostingClassifier     NaN  0.785714\n",
       "2639        2639  2015     14  GradientBoostingClassifier     NaN  0.800000\n",
       "2640        2640  2016      0  GradientBoostingClassifier     NaN  0.641791\n",
       "2641        2641  2016      1  GradientBoostingClassifier     NaN  0.746269\n",
       "2642        2642  2016      2  GradientBoostingClassifier     NaN  0.641791\n",
       "2643        2643  2016      3  GradientBoostingClassifier     NaN  0.611940\n",
       "2644        2644  2016      4  GradientBoostingClassifier     NaN  0.761194\n",
       "2645        2645  2016      5  GradientBoostingClassifier     NaN  0.746269\n",
       "2646        2646  2016      6  GradientBoostingClassifier     NaN  0.671642\n",
       "2647        2647  2016      7  GradientBoostingClassifier     NaN  0.716418\n",
       "2648        2648  2016      8  GradientBoostingClassifier     NaN  0.641791\n",
       "2649        2649  2016      9  GradientBoostingClassifier     NaN  0.776119\n",
       "2650        2650  2016     10  GradientBoostingClassifier     NaN  0.776119\n",
       "2651        2651  2016     11  GradientBoostingClassifier     NaN  0.731343\n",
       "2652        2652  2016     12  GradientBoostingClassifier     NaN  0.746269\n",
       "2653        2653  2016     13  GradientBoostingClassifier     NaN  0.761194\n",
       "2654        2654  2016     14  GradientBoostingClassifier     NaN  0.805970\n",
       "2655        2655  2017      0  GradientBoostingClassifier     NaN  0.671642\n",
       "2656        2656  2017      1  GradientBoostingClassifier     NaN  0.701493\n",
       "2657        2657  2017      2  GradientBoostingClassifier     NaN  0.701493\n",
       "2658        2658  2017      3  GradientBoostingClassifier     NaN  0.641791\n",
       "2659        2659  2017      4  GradientBoostingClassifier     NaN  0.671642\n",
       "2660        2660  2017      5  GradientBoostingClassifier     NaN  0.731343\n",
       "2661        2661  2017      6  GradientBoostingClassifier     NaN  0.716418\n",
       "2662        2662  2017      7  GradientBoostingClassifier     NaN  0.701493\n",
       "2663        2663  2017      8  GradientBoostingClassifier     NaN  0.761194\n",
       "2664        2664  2017      9  GradientBoostingClassifier     NaN  0.716418\n",
       "2665        2665  2017     10  GradientBoostingClassifier     NaN  0.776119\n",
       "2666        2666  2017     11  GradientBoostingClassifier     NaN  0.761194\n",
       "2667        2667  2017     12  GradientBoostingClassifier     NaN  0.791045\n",
       "2668        2668  2017     13  GradientBoostingClassifier     NaN  0.776119\n",
       "2669        2669  2017     14  GradientBoostingClassifier     NaN  0.835821\n",
       "2670        2670  2018      0  GradientBoostingClassifier     NaN  0.537313\n",
       "2671        2671  2018      1  GradientBoostingClassifier     NaN  0.641791\n",
       "2672        2672  2018      2  GradientBoostingClassifier     NaN  0.477612\n",
       "2673        2673  2018      3  GradientBoostingClassifier     NaN  0.537313\n",
       "2674        2674  2018      4  GradientBoostingClassifier     NaN  0.641791\n",
       "2675        2675  2018      5  GradientBoostingClassifier     NaN  0.671642\n",
       "2676        2676  2018      6  GradientBoostingClassifier     NaN  0.641791\n",
       "2677        2677  2018      7  GradientBoostingClassifier     NaN  0.597015\n",
       "2678        2678  2018      8  GradientBoostingClassifier     NaN  0.597015\n",
       "2679        2679  2018      9  GradientBoostingClassifier     NaN  0.641791\n",
       "2680        2680  2018     10  GradientBoostingClassifier     NaN  0.656716\n",
       "2681        2681  2018     11  GradientBoostingClassifier     NaN  0.611940\n",
       "2682        2682  2018     12  GradientBoostingClassifier     NaN  0.731343\n",
       "2683        2683  2018     13  GradientBoostingClassifier     NaN  0.686567\n",
       "2684        2684  2018     14  GradientBoostingClassifier     NaN  0.746269\n",
       "2685        2685  2019      0  GradientBoostingClassifier     NaN  0.626866\n",
       "2686        2686  2019      1  GradientBoostingClassifier     NaN  0.686567\n",
       "2687        2687  2019      2  GradientBoostingClassifier     NaN  0.597015\n",
       "2688        2688  2019      3  GradientBoostingClassifier     NaN  0.671642\n",
       "2689        2689  2019      4  GradientBoostingClassifier     NaN  0.656716\n",
       "2690        2690  2019      5  GradientBoostingClassifier     NaN  0.611940\n",
       "2691        2691  2019      6  GradientBoostingClassifier     NaN  0.731343\n",
       "2692        2692  2019      7  GradientBoostingClassifier     NaN  0.686567\n",
       "2693        2693  2019      8  GradientBoostingClassifier     NaN  0.746269\n",
       "2694        2694  2019      9  GradientBoostingClassifier     NaN  0.746269\n",
       "2695        2695  2019     10  GradientBoostingClassifier     NaN  0.716418\n",
       "2696        2696  2019     11  GradientBoostingClassifier     NaN  0.731343\n",
       "2697        2697  2019     12  GradientBoostingClassifier     NaN  0.776119\n",
       "2698        2698  2019     13  GradientBoostingClassifier     NaN  0.746269\n",
       "2699        2699  2019     14  GradientBoostingClassifier     NaN  0.776119"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly = pd.read_csv('data/Yearly_Quarter_Combos_Modeling_Results.csv')\n",
    "yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b2fd3c9-9a2a-4ca8-aa13-a2173957f444",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-62f289c28203>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  yearly.groupby(['Year'])['accuracy','Estimator'].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.672663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.659012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.639750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.676285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.663139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.634641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.658154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.678275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.691593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.704809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.629851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.654877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.626755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.714981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.689841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.708126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.717081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.616915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.695080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy\n",
       "Year          \n",
       "2000  0.672663\n",
       "2001  0.659012\n",
       "2002  0.639750\n",
       "2003  0.676285\n",
       "2004  0.663139\n",
       "2005  0.634641\n",
       "2006  0.718310\n",
       "2007  0.658154\n",
       "2008  0.678275\n",
       "2009  0.691593\n",
       "2010  0.704809\n",
       "2011  0.629851\n",
       "2012  0.654877\n",
       "2013  0.626755\n",
       "2014  0.714981\n",
       "2015  0.689841\n",
       "2016  0.708126\n",
       "2017  0.717081\n",
       "2018  0.616915\n",
       "2019  0.695080"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly.groupby(['Year'])['accuracy','Estimator'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71b1bd08-8e45-473d-b78b-e4a40c6d4a4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Clump</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>630</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>660</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>690</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>720</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>735</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>765</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>780</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>825</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1035</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>1050</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1080</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1170</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1185</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1230</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1275</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1290</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1305</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>1320</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1335</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1350</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1365</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>1380</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>1425</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1455</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1470</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1485</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1515</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1545</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1575</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1590</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>1605</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1635</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1650</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1680</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1710</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1725</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1740</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1755</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1770</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1785</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1800</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1815</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>1830</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>1845</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1860</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1875</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1890</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1905</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1920</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>1950</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1965</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1980</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2040</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2070</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2100</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2115</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2130</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2145</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2175</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2205</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2220</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2235</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>2250</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2265</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>2280</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2295</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>2310</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2325</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2340</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>2355</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>2370</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2385</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2415</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2430</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>2445</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>2460</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2475</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2490</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>2505</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2520</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2535</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>2565</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>2580</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2595</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2610</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2640</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2655</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2670</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>2685</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Year  Clump                   Estimator  params  accuracy\n",
       "0              0  2000      0          LogisticRegression     NaN  0.634921\n",
       "15            15  2001      0          LogisticRegression     NaN  0.633333\n",
       "30            30  2002      0          LogisticRegression     NaN  0.690141\n",
       "45            45  2003      0          LogisticRegression     NaN  0.656716\n",
       "60            60  2004      0          LogisticRegression     NaN  0.619048\n",
       "75            75  2005      0          LogisticRegression     NaN  0.617647\n",
       "90            90  2006      0          LogisticRegression     NaN  0.746479\n",
       "105          105  2007      0          LogisticRegression     NaN  0.582090\n",
       "120          120  2008      0          LogisticRegression     NaN  0.552239\n",
       "135          135  2009      0          LogisticRegression     NaN  0.650794\n",
       "150          150  2010      0          LogisticRegression     NaN  0.731343\n",
       "165          165  2011      0          LogisticRegression     NaN  0.552239\n",
       "180          180  2012      0          LogisticRegression     NaN  0.521127\n",
       "195          195  2013      0          LogisticRegression     NaN  0.507463\n",
       "210          210  2014      0          LogisticRegression     NaN  0.641791\n",
       "225          225  2015      0          LogisticRegression     NaN  0.628571\n",
       "240          240  2016      0          LogisticRegression     NaN  0.641791\n",
       "255          255  2017      0          LogisticRegression     NaN  0.671642\n",
       "270          270  2018      0          LogisticRegression     NaN  0.537313\n",
       "285          285  2019      0          LogisticRegression     NaN  0.597015\n",
       "300          300  2000      0           BaggingClassifier     NaN  0.634921\n",
       "315          315  2001      0           BaggingClassifier     NaN  0.633333\n",
       "330          330  2002      0           BaggingClassifier     NaN  0.690141\n",
       "345          345  2003      0           BaggingClassifier     NaN  0.656716\n",
       "360          360  2004      0           BaggingClassifier     NaN  0.619048\n",
       "375          375  2005      0           BaggingClassifier     NaN  0.617647\n",
       "390          390  2006      0           BaggingClassifier     NaN  0.746479\n",
       "405          405  2007      0           BaggingClassifier     NaN  0.582090\n",
       "420          420  2008      0           BaggingClassifier     NaN  0.552239\n",
       "435          435  2009      0           BaggingClassifier     NaN  0.523810\n",
       "450          450  2010      0           BaggingClassifier     NaN  0.731343\n",
       "465          465  2011      0           BaggingClassifier     NaN  0.552239\n",
       "480          480  2012      0           BaggingClassifier     NaN  0.521127\n",
       "495          495  2013      0           BaggingClassifier     NaN  0.507463\n",
       "510          510  2014      0           BaggingClassifier     NaN  0.641791\n",
       "525          525  2015      0           BaggingClassifier     NaN  0.628571\n",
       "540          540  2016      0           BaggingClassifier     NaN  0.641791\n",
       "555          555  2017      0           BaggingClassifier     NaN  0.671642\n",
       "570          570  2018      0           BaggingClassifier     NaN  0.537313\n",
       "585          585  2019      0           BaggingClassifier     NaN  0.597015\n",
       "600          600  2000      0      RandomForestClassifier     NaN  0.634921\n",
       "615          615  2001      0      RandomForestClassifier     NaN  0.633333\n",
       "630          630  2002      0      RandomForestClassifier     NaN  0.690141\n",
       "645          645  2003      0      RandomForestClassifier     NaN  0.656716\n",
       "660          660  2004      0      RandomForestClassifier     NaN  0.619048\n",
       "675          675  2005      0      RandomForestClassifier     NaN  0.617647\n",
       "690          690  2006      0      RandomForestClassifier     NaN  0.746479\n",
       "705          705  2007      0      RandomForestClassifier     NaN  0.582090\n",
       "720          720  2008      0      RandomForestClassifier     NaN  0.552239\n",
       "735          735  2009      0      RandomForestClassifier     NaN  0.650794\n",
       "750          750  2010      0      RandomForestClassifier     NaN  0.731343\n",
       "765          765  2011      0      RandomForestClassifier     NaN  0.552239\n",
       "780          780  2012      0      RandomForestClassifier     NaN  0.521127\n",
       "795          795  2013      0      RandomForestClassifier     NaN  0.477612\n",
       "810          810  2014      0      RandomForestClassifier     NaN  0.641791\n",
       "825          825  2015      0      RandomForestClassifier     NaN  0.628571\n",
       "840          840  2016      0      RandomForestClassifier     NaN  0.641791\n",
       "855          855  2017      0      RandomForestClassifier     NaN  0.671642\n",
       "870          870  2018      0      RandomForestClassifier     NaN  0.537313\n",
       "885          885  2019      0      RandomForestClassifier     NaN  0.597015\n",
       "900          900  2000      0        ExtraTreesClassifier     NaN  0.634921\n",
       "915          915  2001      0        ExtraTreesClassifier     NaN  0.633333\n",
       "930          930  2002      0        ExtraTreesClassifier     NaN  0.690141\n",
       "945          945  2003      0        ExtraTreesClassifier     NaN  0.656716\n",
       "960          960  2004      0        ExtraTreesClassifier     NaN  0.619048\n",
       "975          975  2005      0        ExtraTreesClassifier     NaN  0.617647\n",
       "990          990  2006      0        ExtraTreesClassifier     NaN  0.746479\n",
       "1005        1005  2007      0        ExtraTreesClassifier     NaN  0.582090\n",
       "1020        1020  2008      0        ExtraTreesClassifier     NaN  0.552239\n",
       "1035        1035  2009      0        ExtraTreesClassifier     NaN  0.650794\n",
       "1050        1050  2010      0        ExtraTreesClassifier     NaN  0.731343\n",
       "1065        1065  2011      0        ExtraTreesClassifier     NaN  0.552239\n",
       "1080        1080  2012      0        ExtraTreesClassifier     NaN  0.521127\n",
       "1095        1095  2013      0        ExtraTreesClassifier     NaN  0.507463\n",
       "1110        1110  2014      0        ExtraTreesClassifier     NaN  0.641791\n",
       "1125        1125  2015      0        ExtraTreesClassifier     NaN  0.628571\n",
       "1140        1140  2016      0        ExtraTreesClassifier     NaN  0.641791\n",
       "1155        1155  2017      0        ExtraTreesClassifier     NaN  0.671642\n",
       "1170        1170  2018      0        ExtraTreesClassifier     NaN  0.537313\n",
       "1185        1185  2019      0        ExtraTreesClassifier     NaN  0.597015\n",
       "1200        1200  2000      0        KNeighborsClassifier     NaN  0.634921\n",
       "1215        1215  2001      0        KNeighborsClassifier     NaN  0.633333\n",
       "1230        1230  2002      0        KNeighborsClassifier     NaN  0.605634\n",
       "1245        1245  2003      0        KNeighborsClassifier     NaN  0.552239\n",
       "1260        1260  2004      0        KNeighborsClassifier     NaN  0.571429\n",
       "1275        1275  2005      0        KNeighborsClassifier     NaN  0.470588\n",
       "1290        1290  2006      0        KNeighborsClassifier     NaN  0.718310\n",
       "1305        1305  2007      0        KNeighborsClassifier     NaN  0.552239\n",
       "1320        1320  2008      0        KNeighborsClassifier     NaN  0.582090\n",
       "1335        1335  2009      0        KNeighborsClassifier     NaN  0.650794\n",
       "1350        1350  2010      0        KNeighborsClassifier     NaN  0.671642\n",
       "1365        1365  2011      0        KNeighborsClassifier     NaN  0.582090\n",
       "1380        1380  2012      0        KNeighborsClassifier     NaN  0.549296\n",
       "1395        1395  2013      0        KNeighborsClassifier     NaN  0.477612\n",
       "1410        1410  2014      0        KNeighborsClassifier     NaN  0.641791\n",
       "1425        1425  2015      0        KNeighborsClassifier     NaN  0.500000\n",
       "1440        1440  2016      0        KNeighborsClassifier     NaN  0.641791\n",
       "1455        1455  2017      0        KNeighborsClassifier     NaN  0.656716\n",
       "1470        1470  2018      0        KNeighborsClassifier     NaN  0.447761\n",
       "1485        1485  2019      0        KNeighborsClassifier     NaN  0.477612\n",
       "1500        1500  2000      0      DecisionTreeClassifier     NaN  0.634921\n",
       "1515        1515  2001      0      DecisionTreeClassifier     NaN  0.633333\n",
       "1530        1530  2002      0      DecisionTreeClassifier     NaN  0.690141\n",
       "1545        1545  2003      0      DecisionTreeClassifier     NaN  0.656716\n",
       "1560        1560  2004      0      DecisionTreeClassifier     NaN  0.619048\n",
       "1575        1575  2005      0      DecisionTreeClassifier     NaN  0.617647\n",
       "1590        1590  2006      0      DecisionTreeClassifier     NaN  0.746479\n",
       "1605        1605  2007      0      DecisionTreeClassifier     NaN  0.582090\n",
       "1620        1620  2008      0      DecisionTreeClassifier     NaN  0.552239\n",
       "1635        1635  2009      0      DecisionTreeClassifier     NaN  0.650794\n",
       "1650        1650  2010      0      DecisionTreeClassifier     NaN  0.731343\n",
       "1665        1665  2011      0      DecisionTreeClassifier     NaN  0.552239\n",
       "1680        1680  2012      0      DecisionTreeClassifier     NaN  0.521127\n",
       "1695        1695  2013      0      DecisionTreeClassifier     NaN  0.507463\n",
       "1710        1710  2014      0      DecisionTreeClassifier     NaN  0.641791\n",
       "1725        1725  2015      0      DecisionTreeClassifier     NaN  0.628571\n",
       "1740        1740  2016      0      DecisionTreeClassifier     NaN  0.641791\n",
       "1755        1755  2017      0      DecisionTreeClassifier     NaN  0.671642\n",
       "1770        1770  2018      0      DecisionTreeClassifier     NaN  0.537313\n",
       "1785        1785  2019      0      DecisionTreeClassifier     NaN  0.597015\n",
       "1800        1800  2000      0        NaiveBayesClassifier     NaN  0.634921\n",
       "1815        1815  2001      0        NaiveBayesClassifier     NaN  0.633333\n",
       "1830        1830  2002      0        NaiveBayesClassifier     NaN  0.690141\n",
       "1845        1845  2003      0        NaiveBayesClassifier     NaN  0.656716\n",
       "1860        1860  2004      0        NaiveBayesClassifier     NaN  0.619048\n",
       "1875        1875  2005      0        NaiveBayesClassifier     NaN  0.617647\n",
       "1890        1890  2006      0        NaiveBayesClassifier     NaN  0.746479\n",
       "1905        1905  2007      0        NaiveBayesClassifier     NaN  0.582090\n",
       "1920        1920  2008      0        NaiveBayesClassifier     NaN  0.552239\n",
       "1935        1935  2009      0        NaiveBayesClassifier     NaN  0.650794\n",
       "1950        1950  2010      0        NaiveBayesClassifier     NaN  0.731343\n",
       "1965        1965  2011      0        NaiveBayesClassifier     NaN  0.552239\n",
       "1980        1980  2012      0        NaiveBayesClassifier     NaN  0.521127\n",
       "1995        1995  2013      0        NaiveBayesClassifier     NaN  0.507463\n",
       "2010        2010  2014      0        NaiveBayesClassifier     NaN  0.641791\n",
       "2025        2025  2015      0        NaiveBayesClassifier     NaN  0.628571\n",
       "2040        2040  2016      0        NaiveBayesClassifier     NaN  0.641791\n",
       "2055        2055  2017      0        NaiveBayesClassifier     NaN  0.671642\n",
       "2070        2070  2018      0        NaiveBayesClassifier     NaN  0.537313\n",
       "2085        2085  2019      0        NaiveBayesClassifier     NaN  0.597015\n",
       "2100        2100  2000      0          AdaBoostClassifier     NaN  0.634921\n",
       "2115        2115  2001      0          AdaBoostClassifier     NaN  0.633333\n",
       "2130        2130  2002      0          AdaBoostClassifier     NaN  0.690141\n",
       "2145        2145  2003      0          AdaBoostClassifier     NaN  0.656716\n",
       "2160        2160  2004      0          AdaBoostClassifier     NaN  0.619048\n",
       "2175        2175  2005      0          AdaBoostClassifier     NaN  0.617647\n",
       "2190        2190  2006      0          AdaBoostClassifier     NaN  0.746479\n",
       "2205        2205  2007      0          AdaBoostClassifier     NaN  0.582090\n",
       "2220        2220  2008      0          AdaBoostClassifier     NaN  0.552239\n",
       "2235        2235  2009      0          AdaBoostClassifier     NaN  0.650794\n",
       "2250        2250  2010      0          AdaBoostClassifier     NaN  0.731343\n",
       "2265        2265  2011      0          AdaBoostClassifier     NaN  0.552239\n",
       "2280        2280  2012      0          AdaBoostClassifier     NaN  0.521127\n",
       "2295        2295  2013      0          AdaBoostClassifier     NaN  0.477612\n",
       "2310        2310  2014      0          AdaBoostClassifier     NaN  0.641791\n",
       "2325        2325  2015      0          AdaBoostClassifier     NaN  0.628571\n",
       "2340        2340  2016      0          AdaBoostClassifier     NaN  0.641791\n",
       "2355        2355  2017      0          AdaBoostClassifier     NaN  0.671642\n",
       "2370        2370  2018      0          AdaBoostClassifier     NaN  0.537313\n",
       "2385        2385  2019      0          AdaBoostClassifier     NaN  0.626866\n",
       "2400        2400  2000      0  GradientBoostingClassifier     NaN  0.634921\n",
       "2415        2415  2001      0  GradientBoostingClassifier     NaN  0.633333\n",
       "2430        2430  2002      0  GradientBoostingClassifier     NaN  0.690141\n",
       "2445        2445  2003      0  GradientBoostingClassifier     NaN  0.656716\n",
       "2460        2460  2004      0  GradientBoostingClassifier     NaN  0.619048\n",
       "2475        2475  2005      0  GradientBoostingClassifier     NaN  0.617647\n",
       "2490        2490  2006      0  GradientBoostingClassifier     NaN  0.746479\n",
       "2505        2505  2007      0  GradientBoostingClassifier     NaN  0.582090\n",
       "2520        2520  2008      0  GradientBoostingClassifier     NaN  0.552239\n",
       "2535        2535  2009      0  GradientBoostingClassifier     NaN  0.650794\n",
       "2550        2550  2010      0  GradientBoostingClassifier     NaN  0.731343\n",
       "2565        2565  2011      0  GradientBoostingClassifier     NaN  0.552239\n",
       "2580        2580  2012      0  GradientBoostingClassifier     NaN  0.521127\n",
       "2595        2595  2013      0  GradientBoostingClassifier     NaN  0.507463\n",
       "2610        2610  2014      0  GradientBoostingClassifier     NaN  0.641791\n",
       "2625        2625  2015      0  GradientBoostingClassifier     NaN  0.628571\n",
       "2640        2640  2016      0  GradientBoostingClassifier     NaN  0.641791\n",
       "2655        2655  2017      0  GradientBoostingClassifier     NaN  0.671642\n",
       "2670        2670  2018      0  GradientBoostingClassifier     NaN  0.537313\n",
       "2685        2685  2019      0  GradientBoostingClassifier     NaN  0.626866"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_C0 = yearly[yearly['Clump'] == 0]\n",
    "yearly_C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e01cd20-8b8d-44b9-80b4-de0a85fff280",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_C1 = yearly[yearly['Clump'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e7429de-741c-4a65-9ef3-2726581966ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_C2 = yearly[yearly['Clump'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3c75742-d213-4560-905e-3f2705ac0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_C3 = yearly[yearly['Clump'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cca4181-bf1a-4d1a-9e15-03084c87df6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251],\n",
       "       [0.536251]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((1,20))\n",
    "null = x + 0.536251\n",
    "null.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19a9f076-8121-42a5-b7b8-c3e5409bda0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ecfc5e8af0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(yearly_C0['Year'].unique(), yearly_C0.groupby(['Year'])['accuracy'].mean(), label = \"Qtr 1 Mean accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.plot(yearly_C1['Year'].unique(), yearly_C1.groupby(['Year'])['accuracy'].mean(), label = \"Qtr 2 Mean accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.plot(yearly_C2['Year'].unique(), yearly_C2.groupby(['Year'])['accuracy'].mean(), label = \"Qtr 3 Mean accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.plot(yearly_C3['Year'].unique(), yearly_C3.groupby(['Year'])['accuracy'].mean(), label = \"Qtr 4 Mean accuracy\", marker='^',\n",
    "        markersize=10)\n",
    "plt.plot(yearly_C2['Year'].unique(), null.T, linewidth=5, label=\"Null model\")\n",
    "plt.xlabel(\"Years of NFL Seasons\", fontsize=40)\n",
    "plt.xticks(np.arange(2000, 2020, step=1), rotation = 45)\n",
    "plt.ylabel(\"Accuracy in percentage\", fontsize=40)\n",
    "plt.grid()\n",
    "fig.patch.set_facecolor('aqua')\n",
    "ax.set_facecolor('palegreen')\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "        #https://www.pauldesalvo.com/convert-y-axis-labels-to-a-percentage-in-python-matplotlib/\n",
    "plt.legend(loc=2, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc984cc0-0c33-4688-9163-6f25385b9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-28fae5fdd774>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  x = yearly.groupby(['Year','Clump'])['accuracy','Estimator'].max()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['RandomForestClassifier'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = yearly.groupby(['Year','Clump'])['accuracy','Estimator'].max()\n",
    "x['Estimator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a94781c-ce51-42e6-a934-71c7baedf94c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-422403f369e8>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  yearly.groupby(['Year','Clump'])['accuracy','Estimator'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Clump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2000</th>\n",
       "      <th>0</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.587302</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.698413</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.650794</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2001</th>\n",
       "      <th>0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2002</th>\n",
       "      <th>0</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436620</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521127</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647887</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.492958</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.535211</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.633803</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.492958</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.633803</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.535211</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.507042</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2003</th>\n",
       "      <th>0</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2004</th>\n",
       "      <th>0</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460317</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539683</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.492063</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.682540</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.650794</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.698413</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2005</th>\n",
       "      <th>0</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676471</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.632353</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.632353</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.661765</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2006</th>\n",
       "      <th>0</th>\n",
       "      <td>0.718310</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.591549</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.633803</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.760563</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.591549</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.718310</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.647887</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.704225</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.704225</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2007</th>\n",
       "      <th>0</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343284</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268657</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2008</th>\n",
       "      <th>0</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.746269</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2009</th>\n",
       "      <th>0</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682540</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.650794</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587302</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.587302</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.730159</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.603175</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.682540</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.634921</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2010</th>\n",
       "      <th>0</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388060</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2011</th>\n",
       "      <th>0</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2012</th>\n",
       "      <th>0</th>\n",
       "      <td>0.521127</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.633803</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.507042</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.605634</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.661972</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.619718</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2013</th>\n",
       "      <th>0</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.522388</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2014</th>\n",
       "      <th>0</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.746269</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.776119</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2015</th>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.628571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2016</th>\n",
       "      <th>0</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.746269</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731343</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.731343</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2017</th>\n",
       "      <th>0</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.746269</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.731343</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2018</th>\n",
       "      <th>0</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417910</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2019</th>\n",
       "      <th>0</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.626866</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.686567</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.761194</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy           Estimator\n",
       "Year Clump                              \n",
       "2000 0      0.634921  AdaBoostClassifier\n",
       "     1      0.571429  AdaBoostClassifier\n",
       "     2      0.603175  AdaBoostClassifier\n",
       "     3      0.666667  AdaBoostClassifier\n",
       "     4      0.619048  AdaBoostClassifier\n",
       "     5      0.603175  AdaBoostClassifier\n",
       "     6      0.619048  AdaBoostClassifier\n",
       "     7      0.587302  AdaBoostClassifier\n",
       "     8      0.634921  AdaBoostClassifier\n",
       "     9      0.666667  AdaBoostClassifier\n",
       "     10     0.603175  AdaBoostClassifier\n",
       "     11     0.666667  AdaBoostClassifier\n",
       "     12     0.698413  AdaBoostClassifier\n",
       "     13     0.666667  AdaBoostClassifier\n",
       "     14     0.650794  AdaBoostClassifier\n",
       "2001 0      0.633333  AdaBoostClassifier\n",
       "     1      0.666667  AdaBoostClassifier\n",
       "     2      0.550000  AdaBoostClassifier\n",
       "     3      0.483333  AdaBoostClassifier\n",
       "     4      0.650000  AdaBoostClassifier\n",
       "     5      0.516667  AdaBoostClassifier\n",
       "     6      0.500000  AdaBoostClassifier\n",
       "     7      0.650000  AdaBoostClassifier\n",
       "     8      0.533333  AdaBoostClassifier\n",
       "     9      0.616667  AdaBoostClassifier\n",
       "     10     0.666667  AdaBoostClassifier\n",
       "     11     0.650000  AdaBoostClassifier\n",
       "     12     0.616667  AdaBoostClassifier\n",
       "     13     0.516667  AdaBoostClassifier\n",
       "     14     0.566667  AdaBoostClassifier\n",
       "2002 0      0.605634  AdaBoostClassifier\n",
       "     1      0.436620  AdaBoostClassifier\n",
       "     2      0.521127  AdaBoostClassifier\n",
       "     3      0.605634  AdaBoostClassifier\n",
       "     4      0.647887  AdaBoostClassifier\n",
       "     5      0.605634  AdaBoostClassifier\n",
       "     6      0.492958  AdaBoostClassifier\n",
       "     7      0.535211  AdaBoostClassifier\n",
       "     8      0.633803  AdaBoostClassifier\n",
       "     9      0.492958  AdaBoostClassifier\n",
       "     10     0.633803  AdaBoostClassifier\n",
       "     11     0.535211  AdaBoostClassifier\n",
       "     12     0.507042  AdaBoostClassifier\n",
       "     13     0.549296  AdaBoostClassifier\n",
       "     14     0.619718  AdaBoostClassifier\n",
       "2003 0      0.552239  AdaBoostClassifier\n",
       "     1      0.552239  AdaBoostClassifier\n",
       "     2      0.597015  AdaBoostClassifier\n",
       "     3      0.582090  AdaBoostClassifier\n",
       "     4      0.716418  AdaBoostClassifier\n",
       "     5      0.582090  AdaBoostClassifier\n",
       "     6      0.552239  AdaBoostClassifier\n",
       "     7      0.656716  AdaBoostClassifier\n",
       "     8      0.656716  AdaBoostClassifier\n",
       "     9      0.597015  AdaBoostClassifier\n",
       "     10     0.611940  AdaBoostClassifier\n",
       "     11     0.671642  AdaBoostClassifier\n",
       "     12     0.641791  AdaBoostClassifier\n",
       "     13     0.641791  AdaBoostClassifier\n",
       "     14     0.671642  AdaBoostClassifier\n",
       "2004 0      0.571429  AdaBoostClassifier\n",
       "     1      0.460317  AdaBoostClassifier\n",
       "     2      0.539683  AdaBoostClassifier\n",
       "     3      0.603175  AdaBoostClassifier\n",
       "     4      0.603175  AdaBoostClassifier\n",
       "     5      0.619048  AdaBoostClassifier\n",
       "     6      0.619048  AdaBoostClassifier\n",
       "     7      0.492063  AdaBoostClassifier\n",
       "     8      0.682540  AdaBoostClassifier\n",
       "     9      0.619048  AdaBoostClassifier\n",
       "     10     0.650794  AdaBoostClassifier\n",
       "     11     0.666667  AdaBoostClassifier\n",
       "     12     0.666667  AdaBoostClassifier\n",
       "     13     0.571429  AdaBoostClassifier\n",
       "     14     0.698413  AdaBoostClassifier\n",
       "2005 0      0.470588  AdaBoostClassifier\n",
       "     1      0.676471  AdaBoostClassifier\n",
       "     2      0.661765  AdaBoostClassifier\n",
       "     3      0.470588  AdaBoostClassifier\n",
       "     4      0.632353  AdaBoostClassifier\n",
       "     5      0.617647  AdaBoostClassifier\n",
       "     6      0.588235  AdaBoostClassifier\n",
       "     7      0.558824  AdaBoostClassifier\n",
       "     8      0.529412  AdaBoostClassifier\n",
       "     9      0.632353  AdaBoostClassifier\n",
       "     10     0.588235  AdaBoostClassifier\n",
       "     11     0.514706  AdaBoostClassifier\n",
       "     12     0.558824  AdaBoostClassifier\n",
       "     13     0.647059  AdaBoostClassifier\n",
       "     14     0.661765  AdaBoostClassifier\n",
       "2006 0      0.718310  AdaBoostClassifier\n",
       "     1      0.690141  AdaBoostClassifier\n",
       "     2      0.591549  AdaBoostClassifier\n",
       "     3      0.633803  AdaBoostClassifier\n",
       "     4      0.760563  AdaBoostClassifier\n",
       "     5      0.591549  AdaBoostClassifier\n",
       "     6      0.619718  AdaBoostClassifier\n",
       "     7      0.676056  AdaBoostClassifier\n",
       "     8      0.690141  AdaBoostClassifier\n",
       "     9      0.661972  AdaBoostClassifier\n",
       "     10     0.718310  AdaBoostClassifier\n",
       "     11     0.647887  AdaBoostClassifier\n",
       "     12     0.732394  AdaBoostClassifier\n",
       "     13     0.704225  AdaBoostClassifier\n",
       "     14     0.704225  AdaBoostClassifier\n",
       "2007 0      0.552239  AdaBoostClassifier\n",
       "     1      0.343284  AdaBoostClassifier\n",
       "     2      0.268657  AdaBoostClassifier\n",
       "     3      0.641791  AdaBoostClassifier\n",
       "     4      0.567164  AdaBoostClassifier\n",
       "     5      0.567164  AdaBoostClassifier\n",
       "     6      0.582090  AdaBoostClassifier\n",
       "     7      0.656716  AdaBoostClassifier\n",
       "     8      0.686567  AdaBoostClassifier\n",
       "     9      0.597015  AdaBoostClassifier\n",
       "     10     0.611940  AdaBoostClassifier\n",
       "     11     0.611940  AdaBoostClassifier\n",
       "     12     0.656716  AdaBoostClassifier\n",
       "     13     0.701493  AdaBoostClassifier\n",
       "     14     0.686567  AdaBoostClassifier\n",
       "2008 0      0.552239  AdaBoostClassifier\n",
       "     1      0.552239  AdaBoostClassifier\n",
       "     2      0.701493  AdaBoostClassifier\n",
       "     3      0.582090  AdaBoostClassifier\n",
       "     4      0.641791  AdaBoostClassifier\n",
       "     5      0.582090  AdaBoostClassifier\n",
       "     6      0.686567  AdaBoostClassifier\n",
       "     7      0.626866  AdaBoostClassifier\n",
       "     8      0.597015  AdaBoostClassifier\n",
       "     9      0.626866  AdaBoostClassifier\n",
       "     10     0.686567  AdaBoostClassifier\n",
       "     11     0.641791  AdaBoostClassifier\n",
       "     12     0.611940  AdaBoostClassifier\n",
       "     13     0.686567  AdaBoostClassifier\n",
       "     14     0.746269  AdaBoostClassifier\n",
       "2009 0      0.523810  AdaBoostClassifier\n",
       "     1      0.619048  AdaBoostClassifier\n",
       "     2      0.682540  AdaBoostClassifier\n",
       "     3      0.650794  AdaBoostClassifier\n",
       "     4      0.587302  AdaBoostClassifier\n",
       "     5      0.666667  AdaBoostClassifier\n",
       "     6      0.666667  AdaBoostClassifier\n",
       "     7      0.619048  AdaBoostClassifier\n",
       "     8      0.587302  AdaBoostClassifier\n",
       "     9      0.730159  AdaBoostClassifier\n",
       "     10     0.603175  AdaBoostClassifier\n",
       "     11     0.603175  AdaBoostClassifier\n",
       "     12     0.634921  AdaBoostClassifier\n",
       "     13     0.682540  AdaBoostClassifier\n",
       "     14     0.634921  AdaBoostClassifier\n",
       "2010 0      0.671642  AdaBoostClassifier\n",
       "     1      0.641791  AdaBoostClassifier\n",
       "     2      0.641791  AdaBoostClassifier\n",
       "     3      0.388060  AdaBoostClassifier\n",
       "     4      0.686567  AdaBoostClassifier\n",
       "     5      0.656716  AdaBoostClassifier\n",
       "     6      0.597015  AdaBoostClassifier\n",
       "     7      0.552239  AdaBoostClassifier\n",
       "     8      0.686567  AdaBoostClassifier\n",
       "     9      0.671642  AdaBoostClassifier\n",
       "     10     0.671642  AdaBoostClassifier\n",
       "     11     0.686567  AdaBoostClassifier\n",
       "     12     0.686567  AdaBoostClassifier\n",
       "     13     0.671642  AdaBoostClassifier\n",
       "     14     0.656716  AdaBoostClassifier\n",
       "2011 0      0.552239  AdaBoostClassifier\n",
       "     1      0.507463  AdaBoostClassifier\n",
       "     2      0.552239  AdaBoostClassifier\n",
       "     3      0.537313  AdaBoostClassifier\n",
       "     4      0.582090  AdaBoostClassifier\n",
       "     5      0.552239  AdaBoostClassifier\n",
       "     6      0.567164  AdaBoostClassifier\n",
       "     7      0.626866  AdaBoostClassifier\n",
       "     8      0.582090  AdaBoostClassifier\n",
       "     9      0.507463  AdaBoostClassifier\n",
       "     10     0.656716  AdaBoostClassifier\n",
       "     11     0.641791  AdaBoostClassifier\n",
       "     12     0.597015  AdaBoostClassifier\n",
       "     13     0.597015  AdaBoostClassifier\n",
       "     14     0.641791  AdaBoostClassifier\n",
       "2012 0      0.521127  AdaBoostClassifier\n",
       "     1      0.661972  AdaBoostClassifier\n",
       "     2      0.577465  AdaBoostClassifier\n",
       "     3      0.619718  AdaBoostClassifier\n",
       "     4      0.605634  AdaBoostClassifier\n",
       "     5      0.633803  AdaBoostClassifier\n",
       "     6      0.661972  AdaBoostClassifier\n",
       "     7      0.619718  AdaBoostClassifier\n",
       "     8      0.507042  AdaBoostClassifier\n",
       "     9      0.676056  AdaBoostClassifier\n",
       "     10     0.577465  AdaBoostClassifier\n",
       "     11     0.577465  AdaBoostClassifier\n",
       "     12     0.605634  AdaBoostClassifier\n",
       "     13     0.661972  AdaBoostClassifier\n",
       "     14     0.619718  AdaBoostClassifier\n",
       "2013 0      0.477612  AdaBoostClassifier\n",
       "     1      0.507463  AdaBoostClassifier\n",
       "     2      0.522388  AdaBoostClassifier\n",
       "     3      0.597015  AdaBoostClassifier\n",
       "     4      0.507463  AdaBoostClassifier\n",
       "     5      0.582090  AdaBoostClassifier\n",
       "     6      0.671642  AdaBoostClassifier\n",
       "     7      0.552239  AdaBoostClassifier\n",
       "     8      0.552239  AdaBoostClassifier\n",
       "     9      0.597015  AdaBoostClassifier\n",
       "     10     0.507463  AdaBoostClassifier\n",
       "     11     0.641791  AdaBoostClassifier\n",
       "     12     0.597015  AdaBoostClassifier\n",
       "     13     0.597015  AdaBoostClassifier\n",
       "     14     0.611940  AdaBoostClassifier\n",
       "2014 0      0.641791  AdaBoostClassifier\n",
       "     1      0.611940  AdaBoostClassifier\n",
       "     2      0.626866  AdaBoostClassifier\n",
       "     3      0.641791  AdaBoostClassifier\n",
       "     4      0.582090  AdaBoostClassifier\n",
       "     5      0.746269  AdaBoostClassifier\n",
       "     6      0.716418  AdaBoostClassifier\n",
       "     7      0.656716  AdaBoostClassifier\n",
       "     8      0.671642  AdaBoostClassifier\n",
       "     9      0.567164  AdaBoostClassifier\n",
       "     10     0.671642  AdaBoostClassifier\n",
       "     11     0.716418  AdaBoostClassifier\n",
       "     12     0.671642  AdaBoostClassifier\n",
       "     13     0.686567  AdaBoostClassifier\n",
       "     14     0.776119  AdaBoostClassifier\n",
       "2015 0      0.500000  AdaBoostClassifier\n",
       "     1      0.542857  AdaBoostClassifier\n",
       "     2      0.585714  AdaBoostClassifier\n",
       "     3      0.585714  AdaBoostClassifier\n",
       "     4      0.642857  AdaBoostClassifier\n",
       "     5      0.642857  AdaBoostClassifier\n",
       "     6      0.642857  AdaBoostClassifier\n",
       "     7      0.628571  AdaBoostClassifier\n",
       "     8      0.628571  AdaBoostClassifier\n",
       "     9      0.671429  AdaBoostClassifier\n",
       "     10     0.685714  AdaBoostClassifier\n",
       "     11     0.642857  AdaBoostClassifier\n",
       "     12     0.671429  AdaBoostClassifier\n",
       "     13     0.685714  AdaBoostClassifier\n",
       "     14     0.714286  AdaBoostClassifier\n",
       "2016 0      0.641791  AdaBoostClassifier\n",
       "     1      0.746269  AdaBoostClassifier\n",
       "     2      0.537313  AdaBoostClassifier\n",
       "     3      0.447761  AdaBoostClassifier\n",
       "     4      0.731343  AdaBoostClassifier\n",
       "     5      0.686567  AdaBoostClassifier\n",
       "     6      0.611940  AdaBoostClassifier\n",
       "     7      0.701493  AdaBoostClassifier\n",
       "     8      0.611940  AdaBoostClassifier\n",
       "     9      0.701493  AdaBoostClassifier\n",
       "     10     0.731343  AdaBoostClassifier\n",
       "     11     0.671642  AdaBoostClassifier\n",
       "     12     0.716418  AdaBoostClassifier\n",
       "     13     0.671642  AdaBoostClassifier\n",
       "     14     0.701493  AdaBoostClassifier\n",
       "2017 0      0.656716  AdaBoostClassifier\n",
       "     1      0.477612  AdaBoostClassifier\n",
       "     2      0.701493  AdaBoostClassifier\n",
       "     3      0.611940  AdaBoostClassifier\n",
       "     4      0.626866  AdaBoostClassifier\n",
       "     5      0.656716  AdaBoostClassifier\n",
       "     6      0.641791  AdaBoostClassifier\n",
       "     7      0.656716  AdaBoostClassifier\n",
       "     8      0.716418  AdaBoostClassifier\n",
       "     9      0.656716  AdaBoostClassifier\n",
       "     10     0.656716  AdaBoostClassifier\n",
       "     11     0.701493  AdaBoostClassifier\n",
       "     12     0.746269  AdaBoostClassifier\n",
       "     13     0.716418  AdaBoostClassifier\n",
       "     14     0.731343  AdaBoostClassifier\n",
       "2018 0      0.447761  AdaBoostClassifier\n",
       "     1      0.611940  AdaBoostClassifier\n",
       "     2      0.417910  AdaBoostClassifier\n",
       "     3      0.537313  AdaBoostClassifier\n",
       "     4      0.626866  AdaBoostClassifier\n",
       "     5      0.656716  AdaBoostClassifier\n",
       "     6      0.537313  AdaBoostClassifier\n",
       "     7      0.507463  AdaBoostClassifier\n",
       "     8      0.552239  AdaBoostClassifier\n",
       "     9      0.611940  AdaBoostClassifier\n",
       "     10     0.641791  AdaBoostClassifier\n",
       "     11     0.537313  AdaBoostClassifier\n",
       "     12     0.611940  AdaBoostClassifier\n",
       "     13     0.641791  AdaBoostClassifier\n",
       "     14     0.671642  AdaBoostClassifier\n",
       "2019 0      0.477612  AdaBoostClassifier\n",
       "     1      0.686567  AdaBoostClassifier\n",
       "     2      0.552239  AdaBoostClassifier\n",
       "     3      0.552239  AdaBoostClassifier\n",
       "     4      0.626866  AdaBoostClassifier\n",
       "     5      0.611940  AdaBoostClassifier\n",
       "     6      0.597015  AdaBoostClassifier\n",
       "     7      0.671642  AdaBoostClassifier\n",
       "     8      0.701493  AdaBoostClassifier\n",
       "     9      0.626866  AdaBoostClassifier\n",
       "     10     0.671642  AdaBoostClassifier\n",
       "     11     0.686567  AdaBoostClassifier\n",
       "     12     0.701493  AdaBoostClassifier\n",
       "     13     0.686567  AdaBoostClassifier\n",
       "     14     0.761194  AdaBoostClassifier"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly.groupby(['Year','Clump'])['accuracy','Estimator'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b985ed-a8dc-4f14-8dae-4b24bee5231b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
